{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "14525fd7",
      "metadata": {
        "id": "14525fd7"
      },
      "source": [
        "# 0.0 Import Libraries\n",
        "* Updated Normalisation Method for Fused MASKING\n",
        "* LIDAR Feature + HSI Feature, Atrention , AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vuX4sZpytah9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuX4sZpytah9",
        "outputId": "e29733e9-9898-46b5-9900-ab9b34431946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spectral\n",
            "  Downloading spectral-0.23.1-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mat73\n",
            "  Downloading mat73-0.63-py3-none-any.whl (19 kB)\n",
            "Collecting einops\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spectral) (1.25.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from mat73) (3.9.0)\n",
            "Installing collected packages: spectral, einops, mat73\n",
            "Successfully installed einops-0.8.0 mat73-0.63 spectral-0.23.1\n"
          ]
        }
      ],
      "source": [
        "pip install spectral mat73  einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12826627",
      "metadata": {
        "id": "12826627"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import os\n",
        "import math\n",
        "\n",
        "from einops import rearrange\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from scipy import io\n",
        "import torch.utils.data\n",
        "import scipy.io as sio\n",
        "import mat73\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dRG3WratmCN",
      "metadata": {
        "id": "6dRG3WratmCN"
      },
      "source": [
        "# 1.0 Upload Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vpwq4Yi-tgjs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpwq4Yi-tgjs",
        "outputId": "cfaadf1d-b387-4da6-f921-1d33860f0f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vMin2GFJtorP",
      "metadata": {
        "id": "vMin2GFJtorP"
      },
      "outputs": [],
      "source": [
        "! ls '/content/drive/MyDrive/A02_RemoteSensingData/UHS_2013_DFTC/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4NMT_vf3t3Bg",
      "metadata": {
        "id": "4NMT_vf3t3Bg"
      },
      "outputs": [],
      "source": [
        "# # Define the path\n",
        "path='/content/drive/MyDrive/A02_RemoteSensingData/UHS_2013_DFTC/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d23b73f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d23b73f",
        "outputId": "03c7529a-cb80-461a-aa46-8d344e8287ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hsi_2013_data shape: (349, 1905, 144)\n",
            "Lidar_2013_data shape: (349, 1905, 1)\n",
            "gt_2013_data.shape: (349, 1905)\n"
          ]
        }
      ],
      "source": [
        "# 2.1 Loads Data\n",
        "# Load hyperpsectral data\n",
        "hsi_2013_data=sio.loadmat(path+'2013_IEEE_GRSS_DF_Contest_CASI_349_1905_144.mat')['ans']\n",
        "print('hsi_2013_data shape:', hsi_2013_data.shape)\n",
        "\n",
        "# Loader Lidar  data\n",
        "import mat73\n",
        "lidar_2013_data = sio.loadmat(path+'2013_IEEE_GRSS_DF_Contest_LiDAR.mat')['LiDAR_data']\n",
        "\n",
        "print('Lidar_2013_data shape:', lidar_2013_data.shape)\n",
        "\n",
        "#Load ground truth labels\n",
        "gt_2013_data=sio.loadmat(path+'GRSS2013.mat')['name']\n",
        "print('gt_2013_data.shape:', gt_2013_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oKmyEAtSK4YZ",
      "metadata": {
        "id": "oKmyEAtSK4YZ"
      },
      "source": [
        "#1.1 Extract HSI and LiDAR smaple patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZPgDkZitPgsy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPgDkZitPgsy",
        "outputId": "53f86063-d7f0-43ae-c7ab-36cd53b1ae6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HSI Patches shape: (20000, 3, 3, 144)\n",
            "LiDAR Patches shape: (20000, 3, 3, 1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "\n",
        "# Function to extract a patch centered at (row, col)\n",
        "def extract_patch(data, row, col, size, depth):\n",
        "    half_size = size // 2\n",
        "    return data[row-half_size:row+half_size+1, col-half_size:col+half_size+1, :depth]\n",
        "\n",
        "# Function to randomly generate patch locations\n",
        "def generate_patch_locations(num_samples, rows, cols, patch_size):\n",
        "    half_size = patch_size // 2\n",
        "    locations = []\n",
        "    for _ in range(num_samples):\n",
        "        row = np.random.randint(half_size, rows - half_size)\n",
        "        col = np.random.randint(half_size, cols - half_size)\n",
        "        locations.append((row, col))\n",
        "    return locations\n",
        "\n",
        "# Define parameters\n",
        "num_samples = 20000\n",
        "hsi_patch_size = 3 # 9x9 patch\n",
        "hsi_depth = 144     # Assuming depth is 144 as per your data\n",
        "lidar_patch_size = 3\n",
        "lidar_depth = 1\n",
        "\n",
        "# Assuming hsi_2013_data and lidar_2013_data are already loaded\n",
        "rows, cols, _ = hsi_2013_data.shape\n",
        "\n",
        "# Generate random patch locations\n",
        "patch_locations = generate_patch_locations(num_samples, rows, cols, hsi_patch_size)\n",
        "\n",
        "# Extract patches\n",
        "hsi_patches = np.array([extract_patch(hsi_2013_data, row, col, hsi_patch_size, hsi_depth) for row, col in patch_locations])\n",
        "lidar_patches = np.array([extract_patch(lidar_2013_data, row, col, lidar_patch_size, lidar_depth) for row, col in patch_locations])\n",
        "\n",
        "print('HSI Patches shape:', hsi_patches.shape)\n",
        "print('LiDAR Patches shape:', lidar_patches.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u9JEKVofr1ox",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9JEKVofr1ox",
        "outputId": "c4c46436-2c49-4e81-d651-b3c76eb371fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LiDAR Patches shape after repeating channels: (20000, 3, 3, 144)\n"
          ]
        }
      ],
      "source": [
        "# Assuming lidar_2013_data is already loaded and has shape (rows, cols, 1)\n",
        "# After extracting the LiDAR patches, repeat them across the depth dimension to match HSI's depth\n",
        "# Extract LiDAR patches\n",
        "lidar_patches_single_channel = np.array([\n",
        "    extract_patch(lidar_2013_data, row, col, lidar_patch_size, lidar_depth)\n",
        "    for row, col in patch_locations\n",
        "])\n",
        "\n",
        "# Repeat the single LiDAR channel to match the number of HSI channels\n",
        "lidar_patches = np.repeat(lidar_patches_single_channel, hsi_depth, axis=-1)\n",
        "\n",
        "print('LiDAR Patches shape after repeating channels:', lidar_patches.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ryDb6A42QSIa",
      "metadata": {
        "id": "ryDb6A42QSIa"
      },
      "source": [
        "##1.2 Normalisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hhUS_ughHb1k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhUS_ughHb1k",
        "outputId": "73ad80d3-cd3f-448b-b9c7-47745da29388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normalized_hsi_patches shape: (20000, 3, 3, 144)\n"
          ]
        }
      ],
      "source": [
        "def normalize_hsi_patches(hsi_patches):\n",
        "    # Initialize an array to store the normalized patches\n",
        "    normalized_patches = np.zeros_like(hsi_patches, dtype=np.float32)\n",
        "\n",
        "    # Iterate over each band\n",
        "    for band in range(hsi_patches.shape[-1]):\n",
        "        band_data = hsi_patches[:, :, :, band]\n",
        "        min_val = np.min(band_data)\n",
        "        max_val = np.max(band_data)\n",
        "\n",
        "        # Normalize this band\n",
        "        normalized_patches[:, :, :, band] = (band_data - min_val) / (max_val - min_val) if max_val > min_val else band_data\n",
        "\n",
        "    return normalized_patches\n",
        "\n",
        "normalized_hsi_patches = normalize_hsi_patches(hsi_patches)\n",
        "print('normalized_hsi_patches shape:',normalized_hsi_patches.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rdHSL7QMH5TR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdHSL7QMH5TR",
        "outputId": "c56c5b0a-7477-42e2-dbb4-c11ed11708d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normalized_lidar_patches.shape: (20000, 3, 3, 144)\n"
          ]
        }
      ],
      "source": [
        "def normalize_lidar_patches(lidar_patches):\n",
        "    min_val = np.min(lidar_patches)\n",
        "    max_val = np.max(lidar_patches)\n",
        "\n",
        "    return (lidar_patches - min_val) / (max_val - min_val) if max_val > min_val else lidar_patches\n",
        "\n",
        "normalized_lidar_patches = normalize_lidar_patches(lidar_patches)\n",
        "print('normalized_lidar_patches.shape:',normalized_lidar_patches.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J7Ko9uYgIf2D",
      "metadata": {
        "id": "J7Ko9uYgIf2D"
      },
      "source": [
        "#2.0 Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u1rQcEYmVP_W",
      "metadata": {
        "id": "u1rQcEYmVP_W"
      },
      "source": [
        "### 2.1 Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35qAdvCxIPJ8",
      "metadata": {
        "id": "35qAdvCxIPJ8"
      },
      "outputs": [],
      "source": [
        "# 2.1 Configuration\n",
        "class Config:\n",
        "    def __init__(self,in_channels,num_patches,kernel_size,patch_size,emb_size,heads,dim_head,output_dim, dropout,pos_emb_size,stride ):\n",
        "        self.in_channels = in_channels\n",
        "        self.num_patches = num_patches\n",
        "        self.kernel_size = kernel_size\n",
        "        self.patch_size = patch_size\n",
        "        self.emb_size = emb_size\n",
        "        self.heads = heads\n",
        "        self.dim_head = dim_head\n",
        "        #self.input_dim = input_dim\n",
        "        self.output_dim=output_dim\n",
        "        self.dropout = dropout\n",
        "        self.pos_emb_size = pos_emb_size\n",
        "        self.stride = stride\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8pEAxo2jpE3R",
      "metadata": {
        "id": "8pEAxo2jpE3R"
      },
      "source": [
        "### 2.2 Patch Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FZFf_RKI7NPI",
      "metadata": {
        "id": "FZFf_RKI7NPI"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "            self.proj = nn.Conv2d(\n",
        "            in_channels=config.in_channels,   # Number of spatial size w*h (e.g.,9*9)\n",
        "            out_channels=config.emb_size,     # Number of output channels (embedding size)\n",
        "            kernel_size=config.kernel_size,    # Size of the kernel (patch size)\n",
        "            stride=config.stride,             # Stride for the convolution\n",
        "        )\n",
        "        # Positional embeddings\n",
        "        self.pos_embedding = nn.Parameter(torch.zeros(1, config.num_patches + 1, config.emb_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        # Apply the convolution layer to get patch embeddings\n",
        "        x = self.proj(x)\n",
        "        # Flatten and transpose to get the correct shape\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        # Add position embeddings to the patch embeddings\n",
        "        x = x + self.pos_embedding[:, :x.size(1)]\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KNuOzZNzpPMz",
      "metadata": {
        "id": "KNuOzZNzpPMz"
      },
      "source": [
        "### 2.3 Attention Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "up7oNZpJDGZQ",
      "metadata": {
        "id": "up7oNZpJDGZQ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class AttentionModule(nn.Module):\n",
        "    def __init__(self, in_channels, emb_size, num_heads, dropout_rate, num_patches):\n",
        "        super(AttentionModule, self).__init__()\n",
        "        #self.device = device\n",
        "\n",
        "        # Project input to emb_size\n",
        "        self.input_projection = nn.Linear(emb_size, emb_size)\n",
        "\n",
        "        # Normalization layers\n",
        "        self.norm1 = nn.LayerNorm(emb_size)\n",
        "        self.norm2 = nn.LayerNorm(emb_size)\n",
        "\n",
        "        # Multi-head attention\n",
        "        self.multihead_attn = nn.MultiheadAttention(embed_dim=emb_size, num_heads=num_heads, dropout=dropout_rate)\n",
        "\n",
        "        # Linear layers followed by ELU activation\n",
        "        self.linear1 = nn.Linear(emb_size, emb_size)\n",
        "        self.elu1 = nn.ELU()\n",
        "        self.linear2 = nn.Linear(emb_size, emb_size)\n",
        "        self.elu2 = nn.ELU()\n",
        "        self.linear3 = nn.Linear(emb_size, num_patches)\n",
        "        self.elu3 = nn.ELU()\n",
        "\n",
        "        # Final Linear layer, projecting back to the original channel size\n",
        "        self.final_linear = nn.Linear(num_patches, in_channels)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Ensure input is on the correct device\n",
        "        #x = x.to(self.device)\n",
        "\n",
        "        # Apply input projection and normalization\n",
        "        x = self.input_projection(x)\n",
        "        x_norm = self.norm1(x)\n",
        "\n",
        "        # Multi-head attention\n",
        "        attn_output, _ = self.multihead_attn(x_norm, x_norm, x_norm)\n",
        "        attn_output_norm = self.norm2(attn_output + x)\n",
        "\n",
        "        # Sequential linear layers and activations\n",
        "        x = self.elu1(self.linear1(attn_output_norm))\n",
        "        x = self.elu2(self.linear2(x))\n",
        "        x = self.elu3(self.linear3(x))\n",
        "\n",
        "        # Final linear transformation and sigmoid activation\n",
        "        x = self.sigmoid(self.final_linear(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NbmMSu40p9GJ",
      "metadata": {
        "id": "NbmMSu40p9GJ"
      },
      "source": [
        "### 2.4 CNNAutoEncoder-AVGPooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZLmY5vFvDaXR",
      "metadata": {
        "id": "ZLmY5vFvDaXR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNAutoEncoder(nn.Module):\n",
        "    def __init__(self, config, ):\n",
        "        super(CNNAutoEncoder, self).__init__()\n",
        "\n",
        "        self.patch_size = config.patch_size\n",
        "       # self.device = device  # Storing the device information\n",
        "\n",
        "        # Encoder\n",
        "        self.conv1 = nn.Conv2d(in_channels=config.in_channels, out_channels=config.emb_size,\n",
        "                               kernel_size=config.kernel_size, stride=config.stride, padding=1)\n",
        "        self.elu1 = nn.ELU()\n",
        "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=config.emb_size, out_channels=config.output_dim,\n",
        "                               kernel_size=config.kernel_size, stride=config.stride, padding=1)\n",
        "        self.elu2 = nn.ELU()\n",
        "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Decoder\n",
        "        self.deconv1 = nn.ConvTranspose2d(in_channels=config.output_dim, out_channels=config.emb_size,\n",
        "                                          kernel_size=config.kernel_size, stride=2, padding=1, output_padding=1)\n",
        "        self.elu3 = nn.ELU()\n",
        "\n",
        "        self.deconv2 = nn.ConvTranspose2d(in_channels=config.emb_size, out_channels=config.in_channels,\n",
        "                                          kernel_size=config.kernel_size, stride=2, padding=1, output_padding=1)\n",
        "        self.elu4 = nn.ELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoding\n",
        "        x = self.elu1(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.elu2(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # Decoding\n",
        "        x = self.elu3(self.deconv1(x))\n",
        "        x = self.elu4(self.deconv2(x))\n",
        "\n",
        "        # Resize to the original size to match the input dimensions\n",
        "        x = F.interpolate(x, size=(self.patch_size, self.patch_size), mode='nearest')\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GhD9G0ZPqaqH",
      "metadata": {
        "id": "GhD9G0ZPqaqH"
      },
      "source": [
        "### 2.5 HSIAttentionSubmodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FLu9Aa8KDt6P",
      "metadata": {
        "id": "FLu9Aa8KDt6P"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class HSIAttentionSubmodel(nn.Module):\n",
        "    def __init__(self, hsi_config):\n",
        "        super(HSIAttentionSubmodel, self).__init__()\n",
        "        #self.device = device  # Store the device to use\n",
        "\n",
        "        # Initialize PatchEmbedding and AttentionModule with device handling\n",
        "        self.patch_embedding = PatchEmbedding(hsi_config)\n",
        "        self.attention_module = AttentionModule(\n",
        "            in_channels=hsi_config.in_channels,\n",
        "            emb_size=hsi_config.emb_size,\n",
        "            num_heads=hsi_config.heads,\n",
        "            dropout_rate=hsi_config.dropout,\n",
        "            num_patches=hsi_config.num_patches,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "       # x = x.to(self.device)  # Ensure input is on the correct device\n",
        "\n",
        "        # Process through patch embedding and attention module\n",
        "        x = self.patch_embedding(x)\n",
        "        x = self.attention_module(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41JIetPDqgEv",
      "metadata": {
        "id": "41JIetPDqgEv"
      },
      "source": [
        "### 2.6 LiDARAttentionSubmodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z6eBm7H9EFjQ",
      "metadata": {
        "id": "z6eBm7H9EFjQ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LiDARAttentionSubmodel(nn.Module):\n",
        "    def __init__(self, lidar_config):\n",
        "        super(LiDARAttentionSubmodel, self).__init__()\n",
        "       # self.device = device  # Store the device to use\n",
        "\n",
        "        # Initialize PatchEmbedding and AttentionModule with device handling\n",
        "        self.patch_embedding = PatchEmbedding(lidar_config)\n",
        "        self.attention_module = AttentionModule(\n",
        "            in_channels=lidar_config.in_channels,\n",
        "            emb_size=lidar_config.emb_size,\n",
        "            num_heads=lidar_config.heads,\n",
        "            dropout_rate=lidar_config.dropout,\n",
        "            num_patches=lidar_config.num_patches,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "       # x = x.to(self.device)  # Ensure input is on the correct device\n",
        "\n",
        "        # Process through patch embedding and attention module\n",
        "        x = self.patch_embedding(x)\n",
        "        x = self.attention_module(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Qyt-g8ugrUfS",
      "metadata": {
        "id": "Qyt-g8ugrUfS"
      },
      "source": [
        "### 2.7 Integrated Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Tz3x4ce-NiGC",
      "metadata": {
        "id": "Tz3x4ce-NiGC"
      },
      "outputs": [],
      "source": [
        "class IntegratedModel(nn.Module):\n",
        "    def __init__(self, hsi_config, lidar_config):\n",
        "        super(IntegratedModel, self).__init__()\n",
        "       # self.device = device\n",
        "\n",
        "        # Pass the device to each submodel\n",
        "        self.hsi_attention_submodel = HSIAttentionSubmodel(hsi_config)\n",
        "        self.lidar_attention_submodel = LiDARAttentionSubmodel(lidar_config)\n",
        "        self.autoencoder = CNNAutoEncoder(hsi_config)  # Make sure CNNAutoEncoder also handles device correctly\n",
        "        # Make sure to initialize positional embeddings here\n",
        "        #self.pos_embedding = torch.rand(1, max_length, embedding_dim).to(device)  # Example initialization\n",
        "\n",
        "    def forward(self, hsi_sample, lidar_sample):\n",
        "        # Process through attention submodels\n",
        "        hsi_attention_output = self.hsi_attention_submodel(hsi_sample)\n",
        "        lidar_attention_output = self.lidar_attention_submodel(lidar_sample)\n",
        "\n",
        "        #Add Lidar to HSI sample To assure the autoencoder input to have lidar also\n",
        "        hsi_sample=hsi_sample+lidar_sample # Input and output 144 >145  # Temporarily removed\n",
        "\n",
        "        # Flatten and transpose the HSI and LiDAR sample to match the attention mask shape\n",
        "        hsi_sample_flattened = hsi_sample.view(hsi_sample.shape[0], hsi_sample.shape[1], -1)\n",
        "\n",
        "        # Fuse the HSI and LiDAR attention outputs\n",
        "        fused_attention_output = hsi_attention_output + lidar_attention_output\n",
        "        fused_attention_output_transposed = fused_attention_output.transpose(1, 2)\n",
        "\n",
        "        # Element-wise multiplication\n",
        "        elementwise_result = hsi_sample_flattened * fused_attention_output_transposed\n",
        "\n",
        "        num_samples, num_channels, height, width = hsi_sample.shape\n",
        "        # This needs to be consistent with the actual size of elementwise_result\n",
        "        new_height, new_width = height, width  # adjust as needed\n",
        "\n",
        "        # Reshape for input into the autoencoder\n",
        "        autoencoder_input = elementwise_result.view(num_samples, num_channels, new_height, new_width)  # Hsi\n",
        "\n",
        "        # Access one channe from lidar and concatenare with autoncoder_input, 145 channek\n",
        "        # Select one LiDAR channel to concatenate (assuming channel index 0 for example)\n",
        "        #lidar_channel = lidar_sample[:, 0, :, :].unsqueeze(1)  # Add a channel dimension\n",
        "        # Concatenate along the channel dimension\n",
        "        #autoencoder_input = torch.cat((autoencoder_input, lidar_channel), dim=1)\n",
        "\n",
        "        # Pass through the autoencoder\n",
        "        autoencoder_output = self.autoencoder(autoencoder_input)  #output 145\n",
        "\n",
        "        return fused_attention_output, autoencoder_output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aEaKwERnrdfI",
      "metadata": {
        "id": "aEaKwERnrdfI"
      },
      "source": [
        "# 3.0 LossFuntion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ftztXseS7qkc",
      "metadata": {
        "id": "ftztXseS7qkc"
      },
      "outputs": [],
      "source": [
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self, lambda1):\n",
        "        super(CustomLoss, self).__init__()\n",
        "        self.lambda1 = lambda1\n",
        "\n",
        "    def forward(self, autoencoder_output, hsi_sample, lidar_sample, fused_mask):\n",
        "\n",
        "\n",
        "        # Concatenate along the channel dimension\n",
        "        hsi_sample_combined=hsi_sample+lidar_sample\n",
        "\n",
        "        # Calculate the reconstruction loss between the autoencoder's output and the target input\n",
        "        recon_loss = F.mse_loss(autoencoder_output, hsi_sample_combined)\n",
        "\n",
        "        #Calculate the sparsity loss based on the fused_mask\n",
        "        sparsity_loss = torch.sum(torch.sqrt(torch.sum(fused_mask ** 2, dim=2))) * self.lambda1\n",
        "\n",
        "       # Combine the losses\n",
        "        total_loss = 0.5 * recon_loss + sparsity_loss\n",
        "        return total_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ztqwuNo0tOMv",
      "metadata": {
        "id": "ztqwuNo0tOMv"
      },
      "source": [
        "### 3.5 configuration and Integrated Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GtL57YT1TvLQ",
      "metadata": {
        "id": "GtL57YT1TvLQ"
      },
      "outputs": [],
      "source": [
        "# Hsi configuration\n",
        "hsi_config = Config(\n",
        "    in_channels=144,  # Each sample covers 144 bands\n",
        "    num_patches=144,  # Channeles to patch number\n",
        "    kernel_size=(1,1),\n",
        "    patch_size=3,  # Adjusted to match new patch size (5*5, 144/24=6)\n",
        "    emb_size=256,  # Embedding size, this can be changed\n",
        "    heads=8,  # Number of attention heads, this can be changed\n",
        "    dim_head=64,  # Dimension of each attention head, this can be changed\n",
        "    #input_dim=144,  # Dimension of the MLP layer, this can be changed\n",
        "    output_dim=256,\n",
        "    dropout=0.2,  # Dropout rate, this can be changed\n",
        "    pos_emb_size=256,  # Position embedding size, this can be changed\n",
        "    stride=1  # Stride for the convolution, this can be changed\n",
        ")\n",
        "\n",
        "\n",
        "# Lidara configuration\n",
        "lidar_config = Config(\n",
        "    in_channels=144,  # lidar group has 1 channels\n",
        "    num_patches=144,  # 1 band for Lidar\n",
        "    kernel_size=(1,1),  # Adjusted to match new patch size\n",
        "    patch_size=3, # Adjusted to match new patch size\n",
        "    emb_size=256,  # Embedding size, this can be changed\n",
        "    heads=8,  # Number of attention heads, this can be changed\n",
        "    dim_head=64,  # Dimension of each attention head, this can be changed\n",
        "    #input_dim=1,  # Dimension of the MLP layer, this can be changed\n",
        "    output_dim=256,\n",
        "    dropout=0.2,  # Dropout rate, this can be changed\n",
        "    pos_emb_size=256,  # Position embedding size, this can be changed\n",
        "    stride=1 # Stride for the convolution, this can be changed\n",
        ")\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FrP4Awrgs3mm",
      "metadata": {
        "id": "FrP4Awrgs3mm"
      },
      "source": [
        "# 4.0 Training Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ei1LFGarqJtX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei1LFGarqJtX",
        "outputId": "21f46693-5188-43c9-e382-e01687f44caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_hsi_patch shape: (20000, 3, 3, 144)\n",
            "sample_lidar_patch shape: (20000, 3, 3, 144)\n",
            "sample_hsi_patch_transpose shape: (20000, 144, 3, 3)\n",
            "sample_lidar_patch_transpose shape: (20000, 144, 3, 3)\n",
            "sample_hsi_patch_tensorshape: torch.Size([20000, 144, 3, 3])\n",
            "sample_lidar_patch_tensoshape: torch.Size([20000, 144, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Select one sample patch\n",
        "sample_hsi_patch = normalized_hsi_patches # First patch for demonstration\n",
        "sample_lidar_patch = normalized_lidar_patches\n",
        "\n",
        "# Convert patches to float32\n",
        "sample_hsi_patch = sample_hsi_patch.astype(np.float32)\n",
        "sample_lidar_patch = sample_lidar_patch.astype(np.float32)\n",
        "\n",
        "print('sample_hsi_patch shape:', sample_hsi_patch.shape)\n",
        "print('sample_lidar_patch shape:', sample_lidar_patch.shape)\n",
        "\n",
        "# Reshape patches to match the input shape expected by the model\n",
        "# (Batch size, Channels, Height, Width)\n",
        "sample_hsi_patch = np.transpose(sample_hsi_patch, (0, 3, 1, 2))  # Rearrange dimensions to (5000, 144, 9, 9)\n",
        "sample_lidar_patch = np.transpose(sample_lidar_patch, (0, 3, 1, 2))  # Rearrange dimensions to (5000, 144, 9, 9)\n",
        "print('sample_hsi_patch_transpose shape:', sample_hsi_patch.shape)\n",
        "print('sample_lidar_patch_transpose shape:', sample_lidar_patch.shape)\n",
        "\n",
        "# Convert numpy arrays to tensors and immediately transfer them to the device\n",
        "sample_hsi_patch_tensor = torch.tensor(sample_hsi_patch)\n",
        "sample_lidar_patch_tensor = torch.tensor(sample_lidar_patch)\n",
        "print('sample_hsi_patch_tensorshape:', sample_hsi_patch_tensor.shape)\n",
        "print('sample_lidar_patch_tensoshape:', sample_lidar_patch_tensor.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZBQZVWXr7ub4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBQZVWXr7ub4",
        "outputId": "7586c3f2-9c20-40fe-b2ca-4b591aa5586b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_hsi_patch shape: (20000, 3, 3, 144)\n",
            "sample_lidar_patch shape: (20000, 3, 3, 144)\n",
            "sample_hsi_patch_tensorshape: torch.Size([20000, 3, 3, 144])\n",
            "sample_lidar_patch_tensoshape: torch.Size([20000, 3, 3, 144])\n",
            "hsi_batch_flat shape: torch.Size([20000, 144, 9, 1])\n",
            "lidar_batch_flat shape: torch.Size([20000, 144, 9, 1])\n",
            "hsi_train shape: torch.Size([14400, 3, 3, 144])\n",
            "hsi_val shape: torch.Size([3600, 3, 3, 144])\n",
            "hsi_train shape after permuted: torch.Size([14400, 144, 3, 3])\n",
            "hsi_val shape after permuted: torch.Size([3600, 144, 3, 3])\n",
            "hsi_test shape after permuted: torch.Size([2000, 144, 3, 3])\n",
            "lidar_train shape after permuted: torch.Size([14400, 144, 3, 3])\n",
            "lidar_val shape after permuted: torch.Size([3600, 144, 3, 3])\n",
            "lidar_test shape after permuted: torch.Size([2000, 144, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Select one sample patch\n",
        "sample_hsi_patch = normalized_hsi_patches # First patch for demonstration\n",
        "sample_lidar_patch = normalized_lidar_patches\n",
        "# sample_hsi_patch = hsi_patches # First patch for demonstration\n",
        "# sample_lidar_patch = lidar_patches\n",
        "\n",
        "# Convert patches to float32\n",
        "sample_hsi_patch = sample_hsi_patch.astype(np.float32)\n",
        "sample_lidar_patch = sample_lidar_patch.astype(np.float32)\n",
        "print('sample_hsi_patch shape:', sample_hsi_patch.shape)\n",
        "print('sample_lidar_patch shape:', sample_lidar_patch.shape)\n",
        "\n",
        "\n",
        "# Convert patches to PyTorch tensors\n",
        "sample_hsi_patch_tensor = torch.tensor(sample_hsi_patch)\n",
        "sample_lidar_patch_tensor = torch.tensor(sample_lidar_patch)\n",
        "print('sample_hsi_patch_tensorshape:', sample_hsi_patch_tensor.shape)\n",
        "print('sample_lidar_patch_tensoshape:', sample_lidar_patch_tensor.shape)\n",
        "\n",
        "# Now reshape HSI data such that spatial dimensions (9x9) are flattened and treated as channels\n",
        "hsi_batch_flat = torch.from_numpy(sample_hsi_patch.astype(np.float32).reshape(sample_hsi_patch_tensor.shape[0], hsi_config.in_channels, hsi_config.patch_size*hsi_config.patch_size, 1)).to(device)\n",
        "lidar_batch_flat = torch.from_numpy(sample_lidar_patch.astype(np.float32).reshape(sample_lidar_patch_tensor.shape[0], lidar_config.in_channels, lidar_config.patch_size*lidar_config.patch_size, 1)).to(device)\n",
        "print('hsi_batch_flat shape:', hsi_batch_flat.shape)\n",
        "print('lidar_batch_flat shape:', lidar_batch_flat.shape)\n",
        "\n",
        "hsi_batch_flat = hsi_batch_flat.to(device)  # Move the tensor to GPU\n",
        "lidar_batch_flat = lidar_batch_flat.to(device)  # Move the tensor to GPU\n",
        "\n",
        "# Calculate the number of samples for training and testing\n",
        "num_train_samples = int(0.9 * num_samples)\n",
        "num_test_samples = num_samples - num_train_samples\n",
        "\n",
        "# First, split into initial train and test sets\n",
        "hsi_initial_train, hsi_test, lidar_initial_train, lidar_test = train_test_split(\n",
        "    sample_hsi_patch_tensor, sample_lidar_patch_tensor, test_size=num_test_samples, random_state=42)\n",
        "\n",
        "# Further split the initial training set into actual training and validation sets\n",
        "hsi_train, hsi_val, lidar_train, lidar_val = train_test_split(\n",
        "    hsi_initial_train, lidar_initial_train, test_size=0.20, random_state=42)  # 0.25 x 0.8 = 0.2 of the original dataset\n",
        "\n",
        "print('hsi_train shape:', hsi_train.shape)\n",
        "print('hsi_val shape:', hsi_val.shape)\n",
        "\n",
        "# Reshape and transpose the training, validation, and testing sets\n",
        "hsi_train = hsi_train.permute(0, 3, 1, 2)  # Reshape to [3000, 144, 9, 9]\n",
        "hsi_val = hsi_val.permute(0, 3, 1, 2)      # Reshape to [1000, 144, 9, 9]\n",
        "hsi_test = hsi_test.permute(0, 3, 1, 2)    # Apply similar transformation to test set\n",
        "print('hsi_train shape after permuted:', hsi_train.shape)\n",
        "print('hsi_val shape after permuted:', hsi_val.shape)\n",
        "print('hsi_test shape after permuted:', hsi_test.shape)\n",
        "\n",
        "lidar_train = lidar_train.permute(0, 3, 1, 2)  # Apply similar transformation\n",
        "lidar_val = lidar_val.permute(0, 3, 1, 2)      # Apply similar transformation\n",
        "lidar_test = lidar_test.permute(0, 3, 1, 2)    # Apply similar transformation\n",
        "print('lidar_train shape after permuted:', lidar_train.shape)\n",
        "print('lidar_val shape after permuted:', lidar_val.shape)\n",
        "print('lidar_test shape after permuted:', lidar_test.shape)\n",
        "\n",
        "# Create TensorDatasets for training, validation, and testing sets\n",
        "hsi_train_dataset = TensorDataset(hsi_train)\n",
        "hsi_val_dataset = TensorDataset(hsi_val)\n",
        "hsi_test_dataset = TensorDataset(hsi_test)\n",
        "\n",
        "lidar_train_dataset = TensorDataset(lidar_train)\n",
        "lidar_val_dataset = TensorDataset(lidar_val)\n",
        "lidar_test_dataset = TensorDataset(lidar_test)\n",
        "\n",
        "# Create DataLoaders for each set\n",
        "hsi_train_dataloader = DataLoader(hsi_train_dataset, batch_size=32, shuffle=True)\n",
        "hsi_val_dataloader = DataLoader(hsi_val_dataset, batch_size=32, shuffle=False)\n",
        "hsi_test_dataloader = DataLoader(hsi_test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "lidar_train_dataloader = DataLoader(lidar_train_dataset, batch_size=32, shuffle=True)\n",
        "lidar_val_dataloader = DataLoader(lidar_val_dataset, batch_size=32, shuffle=False)\n",
        "lidar_test_dataloader = DataLoader(lidar_test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Now we have separate dataloaders for train, val, and test datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F9s493F_v8u2",
      "metadata": {
        "id": "F9s493F_v8u2"
      },
      "source": [
        "# 5.0 Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ZeWU0_Ll2LN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZeWU0_Ll2LN",
        "outputId": "854c5e15-3607-461f-ddb6-1bfbbf341af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Train Loss: 1666.9031, Val Loss: 1588.4380\n",
            "Epoch [2/30], Train Loss: 1501.8365, Val Loss: 1384.6672\n",
            "Epoch [3/30], Train Loss: 1249.5630, Val Loss: 1084.9724\n",
            "Epoch [4/30], Train Loss: 909.9157, Val Loss: 716.4207\n",
            "Epoch [5/30], Train Loss: 536.9001, Val Loss: 357.3492\n",
            "Epoch [6/30], Train Loss: 220.8053, Val Loss: 106.4811\n",
            "Epoch [7/30], Train Loss: 51.7332, Val Loss: 16.4216\n",
            "Epoch [8/30], Train Loss: 6.3690, Val Loss: 1.2395\n",
            "Epoch [9/30], Train Loss: 0.4088, Val Loss: 0.0922\n",
            "Epoch [10/30], Train Loss: 0.0692, Val Loss: 0.0579\n",
            "Epoch [11/30], Train Loss: 0.0530, Val Loss: 0.0507\n",
            "Epoch [12/30], Train Loss: 0.0481, Val Loss: 0.0475\n",
            "Epoch [13/30], Train Loss: 0.0456, Val Loss: 0.0457\n",
            "Epoch [14/30], Train Loss: 0.0440, Val Loss: 0.0445\n",
            "Epoch [15/30], Train Loss: 0.0430, Val Loss: 0.0436\n",
            "Epoch [16/30], Train Loss: 0.0422, Val Loss: 0.0429\n",
            "Epoch [17/30], Train Loss: 0.0415, Val Loss: 0.0423\n",
            "Epoch [18/30], Train Loss: 0.0410, Val Loss: 0.0418\n",
            "Epoch [19/30], Train Loss: 0.0405, Val Loss: 0.0414\n",
            "Epoch [20/30], Train Loss: 0.0402, Val Loss: 0.0410\n",
            "Epoch [21/30], Train Loss: 0.0397, Val Loss: 0.0406\n",
            "Epoch [22/30], Train Loss: 0.0394, Val Loss: 0.0403\n",
            "Epoch [23/30], Train Loss: 0.0391, Val Loss: 0.0400\n",
            "Epoch [24/30], Train Loss: 0.0388, Val Loss: 0.0397\n",
            "Epoch [25/30], Train Loss: 0.0385, Val Loss: 0.0394\n",
            "Epoch [26/30], Train Loss: 0.0382, Val Loss: 0.0392\n",
            "Epoch [27/30], Train Loss: 0.0379, Val Loss: 0.0389\n",
            "Epoch [28/30], Train Loss: 0.0376, Val Loss: 0.0386\n",
            "Epoch [29/30], Train Loss: 0.0374, Val Loss: 0.0384\n",
            "Epoch [30/30], Train Loss: 0.0371, Val Loss: 0.0382\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "model = IntegratedModel(hsi_config, lidar_config)\n",
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 30\n",
        "learning_rate = 0.0001\n",
        "batch_size = 32\n",
        "lambda1_value = 0.5 # Custom loss lambda value\n",
        "\n",
        "# Initialize the custom loss function\n",
        "# Instantiate CustomLoss with the submodels and lambda value\n",
        "custom_loss_function = CustomLoss(lambda1_value)\n",
        "criterion = CustomLoss(lambda1_value)\n",
        "\n",
        "# Optimizer\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # optimizer 1\n",
        "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)  # optimizer 2\n",
        "#optimizer=torch.optim.RMSprop(model.parameters(), lr=learning_rate) #optimizer 3\n",
        "#optimizer=torch.optim.AdamW(model.parameters(), lr=learning_rate) #optimizer 4\n",
        "\n",
        "def train_model(model, criterion, optimizer, num_epochs, hsi_train_dataloader, lidar_train_dataloader, device, early_stopping_patience):\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for (hsi_patches,), (lidar_patches,) in zip(hsi_train_dataloader, lidar_train_dataloader):\n",
        "            hsi_patches, lidar_patches = hsi_patches, lidar_patches\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "           # fused_attention_output, autoencoder_input, autoencoder_output = model(hsi_patches, lidar_patches)\n",
        "            # Perform forward pass\n",
        "            fused_attention_output,  autoencoder_output = model(hsi_patches, lidar_patches)\n",
        "\n",
        "            loss = custom_loss_function(autoencoder_output, hsi_patches, lidar_patches, fused_attention_output)\n",
        "            #loss = criterion(autoencoder_output, hsi_patches)  # Adjust the loss function as needed\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        train_loss /= len(hsi_train_dataloader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for (hsi_patches,), (lidar_patches,) in zip(hsi_val_dataloader, lidar_val_dataloader):\n",
        "                hsi_patches, lidar_patches = hsi_patches.to(device), lidar_patches.to(device)\n",
        "                fused_attention_output,  autoencoder_output = model(hsi_patches, lidar_patches)\n",
        "                loss = custom_loss_function(autoencoder_output, hsi_patches, lidar_patches, fused_attention_output)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(hsi_val_dataloader)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "        # Early stopping logic\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == early_stopping_patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "# Example usage\n",
        "early_stopping_patience = 10\n",
        "train_model(model, custom_loss_function, optimizer, num_epochs, hsi_train_dataloader, lidar_train_dataloader, device, early_stopping_patience)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fJCJKhZLO2ZI",
      "metadata": {
        "id": "fJCJKhZLO2ZI"
      },
      "outputs": [],
      "source": [
        "path='/content/drive/MyDrive/A02_RemoteSensingData/UHS_2013_DFTC/'\n",
        "def save_model(model, optimizer, path):\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, path)\n",
        "\n",
        "# Example usage:\n",
        "model_path = path+'Autoencodermodel_uh2013_sgdp3nfuseddata_20Ksample.pth'  # Adjust path as needed\n",
        "save_model(model, optimizer, model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TXuQVtJ7EPiT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXuQVtJ7EPiT",
        "outputId": "8fe69385-ed09-4e1e-853c-52514a467773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hsi_attention_submodel.patch_embedding.pos_embedding torch.Size([1, 145, 256])\n",
            "hsi_attention_submodel.patch_embedding.proj.weight torch.Size([256, 144, 1, 1])\n",
            "hsi_attention_submodel.patch_embedding.proj.bias torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.input_projection.weight torch.Size([256, 256])\n",
            "hsi_attention_submodel.attention_module.input_projection.bias torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.norm1.weight torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.norm1.bias torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.norm2.weight torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.norm2.bias torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.multihead_attn.in_proj_weight torch.Size([768, 256])\n",
            "hsi_attention_submodel.attention_module.multihead_attn.in_proj_bias torch.Size([768])\n",
            "hsi_attention_submodel.attention_module.multihead_attn.out_proj.weight torch.Size([256, 256])\n",
            "hsi_attention_submodel.attention_module.multihead_attn.out_proj.bias torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.linear1.weight torch.Size([256, 256])\n",
            "hsi_attention_submodel.attention_module.linear1.bias torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.linear2.weight torch.Size([256, 256])\n",
            "hsi_attention_submodel.attention_module.linear2.bias torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.linear3.weight torch.Size([144, 256])\n",
            "hsi_attention_submodel.attention_module.linear3.bias torch.Size([144])\n",
            "hsi_attention_submodel.attention_module.final_linear.weight torch.Size([144, 144])\n",
            "hsi_attention_submodel.attention_module.final_linear.bias torch.Size([144])\n",
            "lidar_attention_submodel.patch_embedding.pos_embedding torch.Size([1, 145, 256])\n",
            "lidar_attention_submodel.patch_embedding.proj.weight torch.Size([256, 144, 1, 1])\n",
            "lidar_attention_submodel.patch_embedding.proj.bias torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.input_projection.weight torch.Size([256, 256])\n",
            "lidar_attention_submodel.attention_module.input_projection.bias torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.norm1.weight torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.norm1.bias torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.norm2.weight torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.norm2.bias torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.multihead_attn.in_proj_weight torch.Size([768, 256])\n",
            "lidar_attention_submodel.attention_module.multihead_attn.in_proj_bias torch.Size([768])\n",
            "lidar_attention_submodel.attention_module.multihead_attn.out_proj.weight torch.Size([256, 256])\n",
            "lidar_attention_submodel.attention_module.multihead_attn.out_proj.bias torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.linear1.weight torch.Size([256, 256])\n",
            "lidar_attention_submodel.attention_module.linear1.bias torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.linear2.weight torch.Size([256, 256])\n",
            "lidar_attention_submodel.attention_module.linear2.bias torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.linear3.weight torch.Size([144, 256])\n",
            "lidar_attention_submodel.attention_module.linear3.bias torch.Size([144])\n",
            "lidar_attention_submodel.attention_module.final_linear.weight torch.Size([144, 144])\n",
            "lidar_attention_submodel.attention_module.final_linear.bias torch.Size([144])\n",
            "autoencoder.conv1.weight torch.Size([256, 144, 1, 1])\n",
            "autoencoder.conv1.bias torch.Size([256])\n",
            "autoencoder.conv2.weight torch.Size([256, 256, 1, 1])\n",
            "autoencoder.conv2.bias torch.Size([256])\n",
            "autoencoder.deconv1.weight torch.Size([256, 256, 1, 1])\n",
            "autoencoder.deconv1.bias torch.Size([256])\n",
            "autoencoder.deconv2.weight torch.Size([256, 144, 1, 1])\n",
            "autoencoder.deconv2.bias torch.Size([144])\n",
            "Full state dict:\n",
            "OrderedDict([('hsi_attention_submodel.patch_embedding.pos_embedding', tensor([[[-0.0006, -0.0004, -0.0002,  ..., -0.0002, -0.0007, -0.0005],\n",
            "         [-0.0006, -0.0004, -0.0002,  ..., -0.0002, -0.0007, -0.0005],\n",
            "         [-0.0006, -0.0005, -0.0003,  ..., -0.0002, -0.0007, -0.0005],\n",
            "         ...,\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])), ('hsi_attention_submodel.patch_embedding.proj.weight', tensor([[[[-0.0041]],\n",
            "\n",
            "         [[ 0.0618]],\n",
            "\n",
            "         [[-0.0372]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0448]],\n",
            "\n",
            "         [[-0.0753]],\n",
            "\n",
            "         [[ 0.0052]]],\n",
            "\n",
            "\n",
            "        [[[-0.0696]],\n",
            "\n",
            "         [[ 0.0365]],\n",
            "\n",
            "         [[-0.0337]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0575]],\n",
            "\n",
            "         [[-0.0244]],\n",
            "\n",
            "         [[ 0.0203]]],\n",
            "\n",
            "\n",
            "        [[[-0.0449]],\n",
            "\n",
            "         [[-0.0261]],\n",
            "\n",
            "         [[-0.0630]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0376]],\n",
            "\n",
            "         [[-0.0127]],\n",
            "\n",
            "         [[-0.0791]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0288]],\n",
            "\n",
            "         [[-0.0113]],\n",
            "\n",
            "         [[ 0.0278]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0018]],\n",
            "\n",
            "         [[ 0.0229]],\n",
            "\n",
            "         [[ 0.0492]]],\n",
            "\n",
            "\n",
            "        [[[-0.0827]],\n",
            "\n",
            "         [[-0.0118]],\n",
            "\n",
            "         [[-0.0198]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0640]],\n",
            "\n",
            "         [[-0.0759]],\n",
            "\n",
            "         [[ 0.0474]]],\n",
            "\n",
            "\n",
            "        [[[-0.0573]],\n",
            "\n",
            "         [[-0.0610]],\n",
            "\n",
            "         [[-0.0535]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0624]],\n",
            "\n",
            "         [[ 0.0342]],\n",
            "\n",
            "         [[-0.0714]]]])), ('hsi_attention_submodel.patch_embedding.proj.bias', tensor([-3.5638e-02,  4.5373e-02, -1.5626e-02, -2.1494e-02, -2.6151e-02,\n",
            "        -6.0453e-02,  2.8551e-02, -5.1874e-02,  2.2173e-03,  5.7714e-02,\n",
            "        -4.5155e-02,  3.9167e-02, -5.0167e-02,  1.4392e-02, -1.2501e-02,\n",
            "        -2.1541e-02, -1.4575e-02,  7.1345e-02,  3.5383e-02,  1.8832e-02,\n",
            "         4.0226e-02, -6.9540e-02,  5.6272e-02,  1.1357e-02,  6.7721e-02,\n",
            "         5.3198e-02,  8.0857e-02, -6.2142e-03,  3.1440e-02,  4.5585e-02,\n",
            "        -1.5377e-02, -1.4233e-02, -5.8480e-02, -2.9168e-03, -4.0286e-02,\n",
            "        -2.4042e-03,  4.8464e-02, -6.5152e-02,  1.9814e-02, -7.9965e-02,\n",
            "        -1.9937e-02,  1.8550e-02,  1.2300e-02, -2.4643e-03, -8.4882e-03,\n",
            "         6.9837e-02,  7.1921e-02,  3.2615e-02, -4.5156e-02, -7.0137e-02,\n",
            "        -5.3524e-03, -4.0300e-02, -6.2015e-02, -6.1446e-03,  3.6851e-02,\n",
            "         5.5110e-02,  4.0071e-02,  2.9075e-03,  7.5489e-02, -2.2349e-02,\n",
            "         4.1214e-02,  3.9085e-02,  6.7435e-02, -3.5694e-02,  4.2773e-02,\n",
            "        -4.8630e-02,  2.0552e-02,  1.7514e-02,  4.6618e-02,  4.1056e-02,\n",
            "         1.0462e-02, -7.5360e-02, -6.3962e-02,  5.7988e-02,  8.4496e-02,\n",
            "         6.8247e-02, -6.1865e-02, -4.1424e-02, -2.4231e-02, -1.0788e-02,\n",
            "         4.2704e-02,  8.5476e-02, -2.6332e-02, -2.6862e-02, -5.2451e-02,\n",
            "        -2.7872e-02,  5.2329e-02,  3.6336e-02,  6.0709e-02, -5.6379e-02,\n",
            "        -6.9525e-02,  5.0343e-02, -8.4180e-03, -3.1961e-02, -1.0181e-02,\n",
            "        -6.6288e-02, -5.2924e-02, -5.6705e-02, -5.2141e-02, -7.9438e-02,\n",
            "        -7.7402e-02,  2.1213e-02, -1.3381e-03,  3.1503e-02,  4.5581e-02,\n",
            "        -1.5635e-03, -7.3118e-02,  6.6190e-02,  1.1447e-02,  4.9710e-02,\n",
            "        -6.5966e-02, -2.9518e-02,  2.3481e-02,  7.2782e-02,  1.4826e-02,\n",
            "         5.3446e-02, -4.5364e-02,  7.7603e-02,  3.2515e-05,  6.5012e-02,\n",
            "        -4.4134e-02,  3.6972e-04,  3.2535e-03, -6.6497e-02,  2.0082e-02,\n",
            "        -4.8162e-02,  3.3661e-02, -9.8669e-03, -4.3280e-02, -7.0083e-02,\n",
            "        -5.2945e-02,  3.3526e-03, -6.1305e-02,  5.0328e-02, -1.1715e-02,\n",
            "        -5.3743e-02, -4.2238e-02, -4.9032e-02, -7.3726e-02,  6.8691e-02,\n",
            "         4.2968e-02, -8.4300e-03,  2.5635e-02,  3.8609e-02,  5.9026e-02,\n",
            "         6.5483e-02,  6.4624e-02, -3.4928e-02,  2.6451e-02, -5.8236e-02,\n",
            "        -1.8907e-02, -5.6844e-02,  3.6031e-02,  3.7666e-02,  8.4445e-02,\n",
            "         8.1748e-02,  4.1267e-02, -3.8534e-03,  2.8843e-02, -4.8475e-02,\n",
            "        -4.0186e-03,  5.1387e-02, -6.8638e-02,  1.0070e-03, -8.3121e-02,\n",
            "         1.5596e-02, -2.7254e-02,  8.1060e-02,  5.7156e-02,  6.0894e-02,\n",
            "         4.0518e-02,  3.4296e-02, -4.7700e-02,  6.6605e-03, -6.0951e-02,\n",
            "         8.7844e-02, -4.7604e-02,  3.3912e-02,  3.4372e-03, -4.2475e-02,\n",
            "        -3.5504e-02, -1.2351e-03,  4.7401e-02, -4.0473e-02, -8.4207e-02,\n",
            "         5.8838e-02,  8.2316e-02,  8.0413e-02, -5.7154e-02,  4.4518e-02,\n",
            "         4.9956e-02, -2.2550e-02,  8.1570e-02,  5.0054e-02, -8.1426e-03,\n",
            "         3.9825e-02, -6.3546e-03, -4.4126e-02, -3.8995e-02, -3.2227e-02,\n",
            "        -1.0172e-02,  5.2520e-03,  7.1002e-02, -5.0823e-02,  4.2959e-02,\n",
            "        -3.0499e-02,  6.5180e-02, -4.5658e-02, -4.9689e-02,  4.4079e-02,\n",
            "        -7.6408e-02, -2.3879e-02, -7.6067e-02, -3.0830e-02, -7.3897e-02,\n",
            "        -3.6213e-02, -6.0746e-02, -2.8826e-02, -2.0619e-03, -6.1928e-02,\n",
            "         6.9178e-04, -4.6324e-02,  2.4487e-02, -6.6863e-02, -4.4203e-02,\n",
            "         5.3582e-02, -4.0591e-03,  6.5782e-02,  9.0349e-03, -6.3452e-02,\n",
            "         3.9067e-02,  4.1957e-02,  5.2346e-02,  8.4062e-03, -2.8481e-02,\n",
            "         2.9669e-03,  6.1300e-02,  5.4613e-03, -3.6801e-02, -1.1381e-02,\n",
            "        -6.7438e-02,  5.4379e-03, -5.6409e-02, -4.5316e-02,  6.5840e-02,\n",
            "         5.2700e-02,  2.1983e-02,  7.5390e-02,  4.8142e-02, -1.0844e-03,\n",
            "         4.9548e-03,  7.1593e-02,  1.0434e-02,  1.9977e-02, -8.7873e-02,\n",
            "        -4.7067e-02])), ('hsi_attention_submodel.attention_module.input_projection.weight', tensor([[ 0.0470,  0.0464, -0.0343,  ...,  0.0605, -0.0264, -0.0237],\n",
            "        [-0.0407,  0.0256, -0.0441,  ...,  0.0345, -0.0412,  0.0619],\n",
            "        [-0.0106,  0.0053, -0.0589,  ...,  0.0605, -0.0549, -0.0400],\n",
            "        ...,\n",
            "        [ 0.0116, -0.0002, -0.0107,  ..., -0.0496,  0.0057, -0.0403],\n",
            "        [-0.0060, -0.0623,  0.0064,  ..., -0.0608, -0.0583,  0.0069],\n",
            "        [-0.0557,  0.0292, -0.0381,  ...,  0.0376, -0.0464, -0.0268]])), ('hsi_attention_submodel.attention_module.input_projection.bias', tensor([-3.5508e-02,  5.5334e-02,  5.0352e-02,  4.6452e-02,  3.4975e-02,\n",
            "        -1.9628e-02,  1.2220e-02,  7.5659e-03,  3.4569e-02,  7.1117e-02,\n",
            "         1.6768e-02,  5.1160e-02,  4.4082e-02,  4.7396e-02,  3.8990e-02,\n",
            "        -3.4700e-02, -4.1714e-02,  3.3470e-02, -4.3582e-04,  4.3458e-02,\n",
            "         2.1200e-02, -3.6242e-02,  7.3775e-03,  3.7870e-03, -3.8739e-02,\n",
            "         2.8673e-02,  4.1689e-02, -1.5360e-02,  3.8723e-02,  5.7140e-02,\n",
            "        -2.9868e-02,  3.7207e-02, -2.5621e-03, -3.8325e-02, -1.7284e-02,\n",
            "         5.2974e-02,  3.5449e-02, -1.9215e-02,  1.8721e-02,  6.5762e-02,\n",
            "        -3.8582e-02,  5.1047e-02,  2.4996e-03,  1.9068e-02, -2.0064e-02,\n",
            "         5.4682e-02, -7.0429e-03,  1.7235e-02,  1.0011e-03,  1.5105e-02,\n",
            "         1.9975e-02,  6.6042e-02,  3.6755e-02,  1.8172e-02,  7.0868e-02,\n",
            "         1.1919e-02,  6.0653e-02,  2.4091e-02,  2.5335e-02, -1.2291e-03,\n",
            "        -3.2480e-02,  2.1748e-02,  2.3086e-02, -5.9616e-02, -4.9401e-02,\n",
            "        -5.4675e-02, -5.2752e-02,  2.2030e-02, -3.3423e-02,  4.5553e-03,\n",
            "         2.9393e-02,  1.2704e-02, -9.1203e-03,  9.2936e-03, -1.7609e-02,\n",
            "         3.7369e-02,  4.7078e-02,  2.9591e-02,  3.3763e-03,  3.9574e-03,\n",
            "         3.6706e-02,  3.6746e-02,  6.6118e-02, -1.6511e-02,  1.2916e-03,\n",
            "        -2.8075e-02, -1.5948e-02, -3.9069e-02, -4.4019e-02, -2.5355e-02,\n",
            "        -3.6142e-02, -5.8193e-02,  5.4806e-02,  2.7530e-02,  5.7142e-02,\n",
            "         3.7070e-02,  2.6776e-02,  5.1957e-04,  4.5680e-02, -4.0248e-02,\n",
            "         5.3494e-02, -4.8352e-02,  4.6813e-03,  4.9133e-02,  1.6907e-02,\n",
            "        -3.0952e-02,  3.2472e-04,  8.5357e-03,  5.7710e-02, -2.2081e-02,\n",
            "         3.4380e-02,  4.3363e-02, -1.0449e-02, -4.4504e-03, -1.1589e-03,\n",
            "        -1.0828e-02, -2.0046e-02, -1.6650e-02, -3.8158e-02,  2.1974e-02,\n",
            "        -1.6316e-02,  2.2835e-02, -3.1472e-02, -6.0538e-02, -4.6535e-02,\n",
            "         2.5143e-02, -2.7898e-02, -1.8732e-02, -1.5834e-02,  3.8527e-02,\n",
            "        -2.5959e-02, -3.1349e-02, -3.9292e-02, -4.7465e-02, -3.9085e-02,\n",
            "         2.0793e-02, -4.5556e-02, -5.4461e-02,  2.7261e-02,  2.8726e-03,\n",
            "        -3.3917e-02, -2.6676e-03,  6.1200e-04, -1.2328e-02, -6.0760e-02,\n",
            "        -3.7448e-02,  5.6304e-03, -4.5683e-02,  3.1964e-02,  3.2494e-02,\n",
            "        -4.8441e-02,  3.6395e-02,  3.7863e-03, -2.9460e-02,  4.4133e-02,\n",
            "        -3.2486e-02, -3.9936e-02,  1.7593e-02, -3.3243e-02, -3.9238e-02,\n",
            "        -2.0377e-02,  9.2956e-03,  2.2347e-02, -5.6161e-02, -4.5252e-02,\n",
            "        -1.8529e-02,  3.3135e-02,  4.8098e-02,  5.0713e-02, -2.2390e-02,\n",
            "        -5.5161e-02,  6.6022e-02, -5.1721e-02, -5.5167e-02, -1.1727e-03,\n",
            "         3.0925e-02,  4.8372e-02,  2.4885e-02,  6.0152e-02,  5.5857e-02,\n",
            "         4.7157e-02,  5.7713e-02,  1.7409e-02, -1.6063e-02,  5.0323e-02,\n",
            "         4.6093e-03,  2.2074e-02, -1.2801e-02, -3.7179e-02,  3.0139e-02,\n",
            "         5.5009e-02,  4.3763e-03, -2.3792e-02, -3.5444e-02, -3.4619e-02,\n",
            "         4.1648e-02, -1.1667e-02, -4.8857e-02,  1.3444e-02,  4.9172e-02,\n",
            "         2.2791e-02,  4.3129e-02, -7.2303e-03, -1.8316e-02, -5.0707e-02,\n",
            "         1.2405e-02, -5.2840e-02,  3.5046e-02,  1.2379e-02,  2.5384e-02,\n",
            "         5.3711e-02,  3.0291e-02, -7.7053e-05, -1.0878e-02, -3.3543e-02,\n",
            "        -1.5312e-02,  1.6406e-02,  2.1096e-02,  6.2435e-03,  4.5242e-02,\n",
            "        -6.7889e-02, -4.1890e-02,  2.8506e-02,  1.8540e-02,  4.7192e-02,\n",
            "        -1.8354e-02, -4.3475e-02,  4.0947e-03,  4.7495e-02,  2.5338e-02,\n",
            "         2.8039e-02,  5.9553e-02, -6.0657e-02,  6.4775e-02, -2.5605e-02,\n",
            "        -5.3827e-02, -3.5083e-02, -3.1884e-02,  3.9473e-02, -1.4212e-02,\n",
            "        -2.9033e-02,  3.3051e-02,  4.1634e-02,  3.6140e-03,  1.3142e-02,\n",
            "         3.4323e-02, -3.5909e-02, -1.2252e-02, -1.8117e-02,  2.7217e-03,\n",
            "        -1.4577e-02,  1.1157e-02,  1.3104e-02,  4.2541e-02,  5.7866e-02,\n",
            "        -4.9722e-02])), ('hsi_attention_submodel.attention_module.norm1.weight', tensor([0.9999, 1.0002, 1.0002, 0.9998, 1.0000, 1.0001, 0.9997, 0.9999, 1.0000,\n",
            "        1.0013, 1.0000, 1.0002, 1.0001, 1.0007, 0.9996, 1.0001, 1.0009, 0.9993,\n",
            "        1.0000, 0.9997, 1.0004, 1.0000, 0.9999, 1.0000, 0.9998, 1.0000, 1.0000,\n",
            "        1.0001, 0.9998, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.9998,\n",
            "        1.0003, 0.9999, 1.0000, 1.0002, 1.0000, 1.0000, 0.9998, 1.0002, 1.0001,\n",
            "        0.9999, 1.0004, 1.0000, 0.9999, 0.9998, 1.0000, 1.0010, 1.0001, 1.0002,\n",
            "        1.0009, 0.9999, 1.0000, 1.0000, 0.9999, 0.9998, 0.9997, 0.9999, 0.9989,\n",
            "        1.0007, 0.9997, 1.0000, 0.9993, 0.9998, 1.0004, 1.0000, 1.0003, 0.9995,\n",
            "        0.9999, 1.0015, 1.0000, 0.9993, 0.9988, 0.9998, 1.0000, 1.0002, 0.9997,\n",
            "        0.9999, 1.0001, 0.9988, 0.9999, 0.9999, 1.0011, 1.0005, 1.0001, 1.0002,\n",
            "        0.9999, 1.0008, 0.9998, 1.0000, 0.9997, 1.0002, 0.9998, 0.9997, 0.9999,\n",
            "        1.0004, 0.9998, 0.9997, 1.0001, 1.0000, 1.0001, 1.0001, 0.9998, 1.0000,\n",
            "        1.0005, 0.9999, 0.9997, 1.0002, 0.9999, 1.0005, 1.0000, 0.9996, 1.0000,\n",
            "        0.9995, 1.0003, 0.9997, 0.9998, 0.9999, 1.0003, 1.0001, 0.9998, 1.0001,\n",
            "        1.0000, 0.9997, 1.0000, 0.9997, 1.0003, 0.9992, 1.0000, 0.9995, 1.0001,\n",
            "        0.9994, 0.9999, 1.0002, 1.0000, 1.0000, 1.0006, 1.0001, 0.9997, 1.0001,\n",
            "        1.0003, 0.9988, 1.0000, 0.9998, 0.9999, 0.9996, 1.0001, 1.0000, 0.9999,\n",
            "        1.0000, 1.0003, 1.0001, 1.0002, 1.0001, 1.0000, 1.0001, 0.9999, 0.9998,\n",
            "        1.0000, 1.0001, 0.9990, 1.0003, 0.9998, 1.0000, 1.0007, 0.9998, 0.9999,\n",
            "        1.0001, 1.0006, 1.0005, 0.9999, 0.9998, 1.0004, 1.0000, 1.0002, 0.9998,\n",
            "        1.0000, 0.9999, 0.9999, 0.9998, 0.9999, 1.0000, 1.0029, 1.0001, 1.0000,\n",
            "        1.0000, 0.9998, 0.9998, 0.9999, 1.0000, 0.9997, 1.0003, 1.0002, 0.9998,\n",
            "        1.0000, 1.0000, 0.9995, 1.0000, 1.0002, 1.0000, 1.0002, 1.0000, 1.0001,\n",
            "        1.0000, 0.9997, 1.0000, 1.0000, 0.9998, 1.0009, 1.0001, 0.9998, 0.9998,\n",
            "        1.0002, 1.0000, 1.0000, 0.9996, 1.0002, 0.9998, 1.0001, 0.9999, 0.9999,\n",
            "        1.0003, 1.0007, 1.0000, 1.0000, 0.9992, 1.0000, 1.0001, 1.0003, 0.9999,\n",
            "        1.0000, 0.9999, 1.0001, 1.0000, 0.9999, 1.0000, 1.0000, 1.0002, 1.0001,\n",
            "        0.9999, 1.0000, 0.9999, 0.9996, 1.0000, 1.0007, 1.0000, 0.9999, 0.9998,\n",
            "        0.9994, 0.9999, 0.9999, 1.0000])), ('hsi_attention_submodel.attention_module.norm1.bias', tensor([-4.9637e-04,  1.6144e-04,  1.3318e-04, -1.2089e-04,  6.5731e-05,\n",
            "        -1.1895e-04,  5.7884e-04,  3.6118e-04,  6.7292e-05,  7.3819e-04,\n",
            "        -5.7168e-06,  2.7736e-04,  1.8511e-04,  4.5643e-04, -3.7591e-04,\n",
            "         1.3997e-04, -8.9781e-04, -4.8822e-04,  1.0295e-03, -6.6514e-04,\n",
            "         4.6028e-04,  2.9650e-04,  9.7605e-04, -4.5335e-05,  4.8150e-04,\n",
            "        -5.1305e-04,  3.8034e-05,  3.6091e-04, -1.1981e-04,  1.1420e-05,\n",
            "         2.3407e-05, -6.4762e-05, -6.3367e-05, -1.4547e-04,  7.3936e-05,\n",
            "        -9.3844e-05,  6.2134e-04,  5.9183e-04,  2.0012e-04,  2.7743e-04,\n",
            "        -5.9518e-06, -8.1480e-06, -2.4794e-04, -8.0250e-04, -2.8543e-04,\n",
            "        -6.0803e-05, -3.8406e-04, -2.4101e-04,  2.0281e-04,  6.4478e-04,\n",
            "        -3.3772e-05,  3.5552e-04, -7.0344e-04, -2.6532e-04,  6.1783e-04,\n",
            "        -1.3942e-04,  5.4695e-06,  5.3097e-04, -1.9783e-04, -3.8309e-04,\n",
            "         2.4329e-04, -7.3356e-04, -6.7049e-04, -5.1257e-04,  1.4482e-04,\n",
            "        -1.6948e-04,  2.9128e-04, -4.2539e-04, -5.5746e-04, -9.0276e-05,\n",
            "         2.2737e-04, -2.6198e-04, -1.2001e-04, -1.2780e-03, -4.2804e-05,\n",
            "        -6.3509e-04, -8.7890e-04,  4.8881e-04, -1.1717e-04,  2.2072e-04,\n",
            "        -6.2055e-04,  5.3238e-04,  3.9682e-04,  6.5331e-04,  2.7672e-04,\n",
            "        -5.2997e-05, -1.2466e-03, -2.9447e-04,  1.5122e-04, -4.4426e-04,\n",
            "         1.7662e-05, -9.0386e-04, -1.2801e-04,  1.3430e-04, -1.7831e-04,\n",
            "         2.4488e-04,  5.1706e-04,  7.2445e-04, -1.6910e-05, -3.2831e-04,\n",
            "        -2.5008e-04,  3.8175e-04,  8.2543e-05, -4.9394e-04, -6.0488e-04,\n",
            "        -1.6526e-04,  6.4430e-04,  3.3719e-04,  2.5620e-04,  2.6565e-04,\n",
            "        -1.1457e-04,  2.6034e-04, -2.2249e-05,  3.0225e-04, -3.3842e-04,\n",
            "         3.8130e-04,  3.3153e-04,  4.4574e-04, -3.0269e-04, -1.8961e-04,\n",
            "         4.2169e-04, -2.9055e-04, -2.9521e-04, -1.3629e-04,  3.7467e-04,\n",
            "         1.0200e-04,  9.7327e-06,  3.1677e-04,  9.8246e-05, -3.1156e-04,\n",
            "        -5.3798e-04,  4.4418e-04, -1.0037e-04,  3.4436e-04, -1.3178e-04,\n",
            "        -6.8327e-04,  1.6548e-04, -1.3600e-04,  4.7005e-04, -1.2963e-04,\n",
            "        -4.6510e-04,  2.9145e-04, -4.6519e-04, -6.1334e-04, -2.9405e-04,\n",
            "         6.9206e-04,  1.4807e-05,  1.7665e-04, -3.5118e-04, -4.7720e-04,\n",
            "        -1.7499e-04, -5.1125e-04,  6.6157e-05, -1.5434e-04,  7.7283e-04,\n",
            "        -7.1647e-05, -4.9335e-04, -1.0393e-03, -4.5226e-05, -2.1148e-04,\n",
            "        -4.4343e-04,  3.1027e-04,  1.3252e-04, -3.9087e-05,  4.7771e-04,\n",
            "        -4.6696e-04,  2.4840e-04,  3.4562e-04,  5.9034e-04,  1.7441e-04,\n",
            "         1.1639e-04,  2.0767e-04, -3.8661e-04, -2.4984e-04,  1.4478e-04,\n",
            "         1.8024e-04,  2.9907e-04, -1.4675e-04,  4.1358e-04, -1.1386e-04,\n",
            "        -1.6673e-04, -5.6334e-05, -9.4172e-05,  1.0913e-04, -8.0927e-05,\n",
            "         1.9049e-04,  1.6198e-03, -5.3600e-04,  2.0362e-04, -1.3215e-04,\n",
            "        -1.8566e-04,  4.5339e-04,  1.3687e-04,  2.2615e-04, -2.6117e-04,\n",
            "         4.4293e-04, -1.8646e-04,  2.2230e-04,  2.2430e-05,  2.7155e-04,\n",
            "         6.3957e-04, -1.5253e-05,  5.7799e-04,  3.2059e-04, -7.0920e-04,\n",
            "         3.2164e-04, -1.2258e-04, -3.8971e-04,  4.0258e-04, -7.6977e-05,\n",
            "         4.3277e-05, -1.1920e-04, -4.9785e-04, -7.5020e-05,  1.5695e-04,\n",
            "         1.8341e-04,  1.5050e-04,  2.7607e-04, -1.6661e-04, -4.3392e-04,\n",
            "        -7.7014e-04,  1.2733e-04,  2.9506e-04, -1.9544e-04, -5.8862e-05,\n",
            "        -3.9059e-04, -9.4042e-04,  1.2280e-04,  3.5307e-04, -5.3323e-04,\n",
            "        -2.4209e-04,  9.2349e-04, -2.1282e-04,  2.6545e-04, -7.3285e-05,\n",
            "         6.2580e-05, -1.0500e-04, -1.5362e-05, -4.3158e-05,  1.1629e-04,\n",
            "         1.8973e-04,  2.5886e-04,  1.9704e-04,  1.7593e-04,  1.1001e-04,\n",
            "        -2.5054e-04,  2.6859e-04,  2.3622e-04, -9.0205e-04,  1.8649e-05,\n",
            "         2.9081e-05, -2.4835e-04, -3.3717e-04, -2.2811e-04, -7.5197e-05,\n",
            "         6.6373e-05])), ('hsi_attention_submodel.attention_module.norm2.weight', tensor([0.9995, 1.0000, 1.0060, 1.0019, 1.0157, 1.0022, 1.0153, 1.0000, 1.0162,\n",
            "        1.0365, 1.0126, 1.0002, 1.0002, 1.0093, 1.0014, 1.0054, 1.0083, 1.0071,\n",
            "        1.0054, 1.0011, 1.0001, 1.0005, 1.0010, 1.0032, 1.0011, 1.0039, 1.0028,\n",
            "        1.0006, 1.0049, 1.0000, 1.0001, 0.9998, 1.0006, 1.0031, 1.0287, 1.0041,\n",
            "        1.0040, 1.0012, 1.0031, 1.0077, 1.0000, 1.0001, 1.0036, 1.0013, 1.0091,\n",
            "        1.0000, 1.0188, 1.0072, 1.0081, 1.0178, 1.0091, 1.0066, 1.0001, 0.9999,\n",
            "        1.0029, 1.0027, 1.0003, 1.0002, 1.0155, 1.0001, 1.0089, 1.0097, 1.0027,\n",
            "        1.0005, 1.0095, 1.0054, 1.0001, 1.0000, 1.0015, 1.0000, 1.0067, 1.0093,\n",
            "        1.0005, 1.0006, 1.0006, 1.0228, 1.0053, 1.0019, 1.0026, 1.0131, 1.0056,\n",
            "        1.0010, 1.0001, 1.0182, 1.0024, 1.0000, 1.0038, 1.0047, 1.0003, 1.0036,\n",
            "        1.0319, 1.0050, 1.0018, 0.9998, 1.0040, 1.0009, 1.0071, 1.0025, 1.0011,\n",
            "        0.9999, 1.0031, 1.0020, 1.0002, 1.0045, 1.0009, 1.0078, 1.0130, 1.0032,\n",
            "        1.0263, 1.0024, 1.0028, 1.0005, 1.0024, 1.0002, 1.0080, 1.0029, 1.0017,\n",
            "        1.0011, 1.0003, 1.0027, 1.0165, 1.0221, 1.0226, 1.0021, 1.0001, 1.0007,\n",
            "        1.0157, 1.0004, 1.0002, 1.0031, 1.0071, 1.0037, 0.9998, 1.0029, 1.0001,\n",
            "        1.0021, 1.0006, 1.0006, 1.0028, 1.0006, 1.0001, 1.0062, 1.0002, 1.0007,\n",
            "        1.0006, 1.0049, 1.0005, 1.0012, 1.0011, 1.0372, 1.0056, 1.0042, 1.0006,\n",
            "        1.0028, 1.0003, 1.0151, 0.9998, 1.0219, 1.0036, 1.0066, 1.0048, 1.0025,\n",
            "        1.0000, 1.0149, 1.0090, 1.0000, 1.0157, 1.0226, 1.0063, 1.0000, 1.0007,\n",
            "        1.0098, 1.0060, 1.0046, 1.0000, 0.9996, 0.9999, 1.0011, 1.0033, 1.0096,\n",
            "        1.0003, 1.0273, 1.0075, 1.0032, 1.0028, 1.0018, 1.0028, 0.9999, 1.0006,\n",
            "        1.0036, 1.0004, 1.0020, 1.0017, 1.0065, 1.0204, 1.0028, 1.0041, 1.0120,\n",
            "        1.0074, 1.0018, 1.0006, 1.0000, 1.0024, 1.0097, 1.0041, 1.0083, 1.0125,\n",
            "        1.0006, 1.0075, 1.0025, 1.0010, 1.0000, 1.0013, 1.0044, 1.0043, 1.0018,\n",
            "        1.0089, 1.0013, 1.0118, 1.0013, 1.0040, 1.0174, 0.9998, 1.0006, 1.0079,\n",
            "        1.0039, 1.0093, 1.0000, 1.0234, 1.0049, 1.0012, 1.0001, 1.0007, 1.0032,\n",
            "        1.0179, 1.0095, 1.0117, 1.0013, 1.0007, 1.0282, 1.0009, 1.0030, 0.9999,\n",
            "        1.0000, 1.0119, 1.0098, 1.0061, 1.0365, 1.0132, 1.0002, 1.0095, 1.0164,\n",
            "        1.0084, 1.0024, 1.0008, 1.0092])), ('hsi_attention_submodel.attention_module.norm2.bias', tensor([-0.0017,  0.0006,  0.0059,  0.0030, -0.0097, -0.0037, -0.0099,  0.0015,\n",
            "         0.0104,  0.0140, -0.0086,  0.0008,  0.0019,  0.0072,  0.0030, -0.0058,\n",
            "        -0.0078,  0.0063,  0.0058,  0.0021,  0.0011, -0.0028,  0.0026,  0.0049,\n",
            "        -0.0029,  0.0045, -0.0040, -0.0020,  0.0051, -0.0006, -0.0007, -0.0009,\n",
            "        -0.0022, -0.0045, -0.0133,  0.0044, -0.0056,  0.0023, -0.0048,  0.0070,\n",
            "         0.0003,  0.0009, -0.0055,  0.0029, -0.0069, -0.0006, -0.0108,  0.0067,\n",
            "        -0.0076, -0.0111, -0.0082,  0.0061, -0.0016, -0.0002,  0.0045, -0.0040,\n",
            "         0.0003,  0.0014, -0.0096, -0.0014,  0.0073,  0.0071, -0.0038, -0.0010,\n",
            "         0.0076, -0.0056,  0.0006,  0.0004,  0.0034, -0.0010,  0.0066, -0.0074,\n",
            "        -0.0031,  0.0016, -0.0025,  0.0117,  0.0059, -0.0029, -0.0041,  0.0082,\n",
            "        -0.0061,  0.0023,  0.0009, -0.0112, -0.0059, -0.0008, -0.0052, -0.0055,\n",
            "         0.0021,  0.0049,  0.0133,  0.0058,  0.0027, -0.0010,  0.0050,  0.0018,\n",
            "        -0.0065, -0.0039, -0.0033,  0.0011,  0.0049,  0.0040, -0.0013,  0.0050,\n",
            "         0.0024, -0.0073,  0.0089,  0.0044,  0.0125, -0.0043, -0.0041,  0.0015,\n",
            "         0.0037, -0.0009,  0.0070,  0.0036, -0.0031, -0.0027,  0.0016,  0.0040,\n",
            "         0.0098,  0.0116, -0.0116,  0.0039,  0.0007, -0.0032, -0.0090,  0.0029,\n",
            "        -0.0015, -0.0042, -0.0064, -0.0052,  0.0007, -0.0046,  0.0007,  0.0036,\n",
            "        -0.0023, -0.0012, -0.0043,  0.0025,  0.0003,  0.0066,  0.0021, -0.0020,\n",
            "        -0.0026, -0.0061, -0.0018,  0.0026, -0.0027,  0.0147,  0.0060,  0.0047,\n",
            "        -0.0026,  0.0038,  0.0010,  0.0098, -0.0027,  0.0118,  0.0046, -0.0066,\n",
            "        -0.0057, -0.0034, -0.0012, -0.0092,  0.0069, -0.0004,  0.0096,  0.0111,\n",
            "        -0.0060,  0.0005, -0.0017, -0.0074,  0.0054, -0.0056, -0.0003, -0.0008,\n",
            "        -0.0010,  0.0028, -0.0051, -0.0084, -0.0018,  0.0121,  0.0064,  0.0048,\n",
            "         0.0046,  0.0030,  0.0038, -0.0017, -0.0020, -0.0043, -0.0016, -0.0039,\n",
            "        -0.0040, -0.0065,  0.0106, -0.0047, -0.0051, -0.0086, -0.0073,  0.0038,\n",
            "        -0.0021, -0.0002,  0.0035, -0.0079,  0.0047, -0.0070,  0.0084,  0.0023,\n",
            "        -0.0071,  0.0036, -0.0033, -0.0005,  0.0027, -0.0052,  0.0054, -0.0033,\n",
            "         0.0074, -0.0024, -0.0086, -0.0027,  0.0050, -0.0102, -0.0010,  0.0020,\n",
            "         0.0063, -0.0050,  0.0070, -0.0005,  0.0113, -0.0060,  0.0023, -0.0023,\n",
            "        -0.0022,  0.0041, -0.0103, -0.0068, -0.0083,  0.0026, -0.0022, -0.0133,\n",
            "        -0.0024, -0.0040,  0.0007, -0.0006, -0.0082, -0.0080, -0.0060, -0.0145,\n",
            "        -0.0090,  0.0011,  0.0078, -0.0105,  0.0067, -0.0040, -0.0015,  0.0073])), ('hsi_attention_submodel.attention_module.multihead_attn.in_proj_weight', tensor([[ 6.9954e-02, -6.2274e-02, -2.0421e-02,  ..., -6.9244e-02,\n",
            "          5.9179e-02,  5.9477e-02],\n",
            "        [ 7.2256e-02,  3.7551e-02,  3.5245e-02,  ...,  6.9681e-03,\n",
            "          7.5949e-02,  5.3975e-02],\n",
            "        [-3.5250e-02, -8.5173e-03, -1.8294e-02,  ..., -3.9611e-02,\n",
            "          5.7834e-02, -3.9056e-02],\n",
            "        ...,\n",
            "        [-4.7505e-02,  2.3431e-02, -2.9413e-02,  ...,  6.8667e-02,\n",
            "          6.4274e-02,  7.0660e-02],\n",
            "        [-5.7777e-03,  2.8327e-02, -4.0300e-02,  ..., -2.0161e-02,\n",
            "          1.6846e-03,  5.6200e-02],\n",
            "        [-2.9705e-05, -5.1609e-03, -6.0782e-02,  ..., -6.4904e-02,\n",
            "          9.1413e-03, -2.5814e-02]])), ('hsi_attention_submodel.attention_module.multihead_attn.in_proj_bias', tensor([-1.9084e-08, -1.3522e-05, -3.1114e-07,  1.3185e-05, -1.1559e-05,\n",
            "        -1.2404e-05, -6.4641e-06,  1.5577e-06, -6.4221e-07, -1.4688e-05,\n",
            "         1.8601e-06, -4.3099e-07,  4.3907e-06, -1.7938e-06, -3.7615e-06,\n",
            "         9.1638e-06, -4.9981e-06,  1.0410e-06,  2.0269e-06,  1.8819e-06,\n",
            "        -3.5890e-06, -3.5614e-06, -2.0565e-06, -9.4825e-07, -1.5828e-06,\n",
            "         8.2837e-06, -1.4932e-05,  1.1823e-05,  1.1771e-05,  6.2180e-06,\n",
            "        -4.1268e-06,  1.4737e-05,  8.3004e-06, -8.9115e-06, -1.3769e-05,\n",
            "         2.3408e-05,  4.2013e-06,  1.0226e-05, -1.5411e-06, -1.8306e-05,\n",
            "         1.7285e-05,  7.8549e-06, -1.4591e-05, -1.0588e-05,  1.0353e-05,\n",
            "         3.9731e-06,  1.2646e-05, -3.1542e-05, -2.4065e-05, -5.1924e-06,\n",
            "        -8.8851e-06, -2.3256e-05,  2.5988e-05, -1.8510e-05, -4.4042e-06,\n",
            "        -2.6432e-05, -1.3270e-05, -1.7500e-06, -1.6083e-05, -1.2901e-05,\n",
            "        -8.9562e-06,  2.5212e-05, -6.5813e-06, -1.5661e-05, -3.1387e-06,\n",
            "         4.0689e-07,  6.2921e-07,  1.6094e-06,  1.9133e-08,  5.5133e-07,\n",
            "        -3.6857e-06, -2.5232e-06, -1.8798e-06,  6.3830e-06, -2.1155e-06,\n",
            "        -1.5217e-06, -4.1613e-06, -1.0248e-07,  1.1375e-06, -5.7171e-06,\n",
            "         1.7549e-06,  3.5616e-06,  3.0976e-06, -9.0137e-07, -1.0945e-06,\n",
            "        -2.9615e-06, -2.7673e-06,  1.4525e-06, -7.0870e-07, -1.4538e-07,\n",
            "        -3.1331e-06,  5.2936e-06, -2.5941e-06,  8.9829e-07,  3.2844e-06,\n",
            "         2.5887e-06, -6.5983e-06, -1.2685e-05,  2.3688e-05, -5.3278e-06,\n",
            "         1.7530e-05, -1.3394e-06, -7.7867e-06,  6.4442e-06,  1.4766e-05,\n",
            "        -3.4173e-05, -1.6339e-05, -7.8459e-06, -2.4637e-06, -1.1698e-05,\n",
            "        -3.0132e-06,  6.1706e-06, -1.3376e-05,  4.1665e-06,  1.1795e-05,\n",
            "        -1.0613e-05,  2.9811e-05,  4.1753e-06, -4.2933e-06, -4.9683e-06,\n",
            "        -1.8461e-05,  1.7871e-05, -1.5734e-05, -8.7971e-06,  2.7613e-06,\n",
            "        -3.8971e-05, -1.2924e-05,  2.8572e-06, -7.0518e-05, -5.1124e-05,\n",
            "         2.8115e-05, -2.1131e-05,  1.1437e-05,  1.3140e-05,  2.9319e-05,\n",
            "         2.4228e-05, -8.1909e-05,  1.6312e-05, -3.0691e-05, -2.5275e-06,\n",
            "         2.2945e-05, -6.9924e-05, -1.9958e-05, -1.7394e-05, -5.8252e-06,\n",
            "         3.3633e-05,  2.6436e-05, -3.1356e-05,  4.1524e-05,  6.4646e-05,\n",
            "         1.3427e-05,  4.7522e-05, -8.1634e-05, -2.8821e-05,  2.2052e-05,\n",
            "        -2.0180e-05, -1.4172e-05, -8.2854e-06,  2.8033e-06, -3.6993e-05,\n",
            "         2.5543e-06, -8.1249e-07,  1.8460e-06, -1.2539e-06, -4.8912e-06,\n",
            "         4.2897e-06, -8.6814e-07, -1.4215e-06, -2.5234e-06, -5.0429e-06,\n",
            "        -1.1002e-06, -8.3076e-07, -3.6729e-06,  6.4646e-06, -3.2093e-06,\n",
            "        -1.9544e-07,  2.2322e-06, -3.2501e-06, -5.6447e-07,  9.0991e-07,\n",
            "         4.3801e-06, -3.1894e-06, -2.4148e-06,  2.7751e-06,  4.2666e-06,\n",
            "         2.5083e-06, -4.3441e-07,  2.5910e-07,  5.8083e-06, -1.3023e-06,\n",
            "         6.7993e-06,  9.9129e-08,  1.6436e-06, -1.5987e-05,  1.6937e-05,\n",
            "         2.3265e-05,  2.3327e-05,  1.5320e-05,  8.6513e-06,  5.7431e-06,\n",
            "         3.6599e-06,  4.4292e-07,  2.1630e-06, -1.0688e-05,  8.6274e-07,\n",
            "         4.8949e-06, -4.1370e-06, -1.9703e-05, -2.1175e-06,  1.1794e-05,\n",
            "         7.6787e-07, -9.3354e-06,  9.0715e-06, -1.2802e-05, -9.0943e-06,\n",
            "        -1.0372e-05, -3.3868e-06,  1.6862e-06,  1.3418e-05, -1.5935e-05,\n",
            "        -9.3537e-06, -1.0852e-05, -3.2876e-06,  9.1684e-06, -4.3696e-06,\n",
            "         3.0989e-06, -1.9196e-07, -3.3440e-06, -1.5969e-06, -6.1060e-06,\n",
            "        -3.1354e-06, -9.4915e-06,  5.5052e-06,  2.1613e-07, -8.7077e-07,\n",
            "        -5.4641e-08, -6.3457e-06, -3.3203e-06,  4.5650e-06,  2.7150e-06,\n",
            "         4.0878e-06,  2.7267e-06,  8.3427e-07, -1.0006e-05,  3.9722e-06,\n",
            "        -3.4904e-06, -2.9042e-06,  1.1237e-06,  1.0959e-05,  3.4351e-06,\n",
            "        -9.7891e-06,  5.8099e-06, -3.3990e-06, -4.3126e-06,  7.3255e-07,\n",
            "         3.2872e-06, -1.0434e-13,  7.3301e-14,  6.4833e-14,  1.9008e-15,\n",
            "         1.1566e-13,  7.6130e-14, -1.7097e-13,  2.0854e-13, -1.0962e-13,\n",
            "         1.2286e-13, -6.7059e-14,  2.1990e-13,  3.6266e-13, -1.1145e-13,\n",
            "         8.6072e-14, -3.9324e-14,  1.8259e-13,  1.9984e-13, -5.9750e-14,\n",
            "         1.8681e-13,  1.5608e-13, -8.8722e-14, -3.0505e-14,  2.5839e-14,\n",
            "        -6.1460e-13,  1.2932e-14,  6.8242e-14,  2.2087e-14, -2.0505e-13,\n",
            "        -2.9421e-13, -2.1780e-14, -1.4046e-14,  1.5453e-14,  1.5346e-13,\n",
            "        -3.4802e-13, -2.2994e-13,  2.4466e-13, -5.0992e-13,  2.5023e-14,\n",
            "        -1.7134e-13,  6.1322e-14,  1.9732e-13,  1.3746e-13,  3.4834e-14,\n",
            "         1.2598e-13, -6.8300e-14,  2.7986e-13,  5.6778e-14,  2.0624e-14,\n",
            "         8.7889e-14,  1.5566e-13, -1.6682e-13,  9.4598e-14,  1.0504e-13,\n",
            "         2.6886e-13, -6.4441e-14,  4.1967e-14,  2.1311e-13,  3.2821e-13,\n",
            "         8.5920e-14,  9.1311e-14, -2.2823e-13,  1.0010e-13,  4.0238e-13,\n",
            "        -1.4664e-14,  2.9490e-14,  1.7297e-14, -2.3568e-14, -2.0069e-14,\n",
            "        -7.1941e-16,  3.3026e-16, -3.8599e-14, -2.4852e-14, -2.3530e-14,\n",
            "         1.2955e-13, -2.3925e-14,  8.1381e-16, -1.9897e-14,  5.1320e-14,\n",
            "         1.4121e-14, -3.1127e-14,  2.2636e-14,  1.1466e-14, -1.4732e-13,\n",
            "         3.2160e-14,  2.8368e-14,  2.1386e-14, -1.2191e-14, -2.2608e-14,\n",
            "        -1.1772e-14,  6.8833e-14,  1.0024e-14,  6.0293e-14,  2.5013e-14,\n",
            "         4.1239e-14, -1.8664e-14,  1.2103e-13,  1.9359e-14, -7.8513e-14,\n",
            "        -5.2501e-14, -2.9359e-14,  2.8936e-14,  3.3914e-14,  2.8640e-14,\n",
            "        -6.9701e-15,  5.2393e-14, -1.3201e-14,  8.2849e-14, -1.8353e-13,\n",
            "        -2.7119e-15, -3.8297e-14, -1.9275e-13,  1.0465e-16,  6.4073e-15,\n",
            "         5.2606e-14,  3.8599e-14, -2.5420e-14,  6.4325e-14,  2.2250e-14,\n",
            "         3.3072e-15,  1.1300e-13, -1.5822e-13,  1.0335e-13, -5.9934e-14,\n",
            "        -9.8452e-14, -2.3410e-14, -1.2318e-13, -1.7331e-13,  6.2163e-14,\n",
            "         1.1353e-13,  4.9200e-14,  1.0703e-13,  1.6059e-13, -5.3623e-14,\n",
            "         2.1653e-14,  1.1190e-13,  6.8464e-14, -5.6106e-13,  2.6882e-13,\n",
            "         2.4319e-13, -6.7008e-14, -9.1397e-14, -2.7256e-13, -1.0308e-13,\n",
            "         5.5689e-14,  1.7854e-14, -5.4495e-14, -6.0125e-14, -1.5855e-14,\n",
            "        -1.9914e-13, -1.1702e-13,  2.0947e-13, -2.3195e-13,  1.1363e-13,\n",
            "         4.7792e-14, -7.1173e-14,  3.0681e-13,  2.9722e-13,  1.6456e-13,\n",
            "         4.5649e-13,  1.1138e-13,  2.1791e-14, -1.2381e-13, -8.8077e-15,\n",
            "         2.4716e-14, -1.9743e-14,  6.6866e-15,  2.7604e-14,  4.1433e-14,\n",
            "         4.9057e-14,  5.2213e-14,  5.6864e-14, -6.3370e-16, -4.6965e-14,\n",
            "         2.0584e-14, -2.2717e-14,  7.9982e-15, -8.7986e-15,  2.7738e-14,\n",
            "         5.2387e-15, -3.9128e-14, -3.7686e-14,  4.8340e-16,  1.0725e-15,\n",
            "         4.1057e-14,  8.4069e-14,  2.0780e-14, -4.1620e-14,  1.6171e-14,\n",
            "        -2.3533e-15, -4.1255e-14,  3.9088e-14,  1.9750e-14,  2.3483e-14,\n",
            "         3.4022e-15,  9.4451e-14,  1.6138e-14,  5.5860e-14,  6.7308e-14,\n",
            "        -3.6462e-15, -1.5165e-13,  1.4338e-13, -1.7109e-14,  6.1500e-14,\n",
            "         1.6979e-14,  8.8297e-16, -3.4181e-15,  4.3535e-15, -5.8797e-15,\n",
            "         5.3050e-14, -1.8424e-14,  7.3069e-14,  1.5150e-14,  8.4995e-14,\n",
            "        -1.8563e-13, -5.1966e-14, -2.2964e-14,  4.8537e-14,  2.0289e-13,\n",
            "        -1.0656e-14, -1.3421e-13,  8.7709e-14, -2.6318e-14, -7.4165e-14,\n",
            "         2.7793e-14, -1.5257e-13, -8.3939e-14, -5.0531e-15, -1.1668e-13,\n",
            "         8.2950e-14, -2.8281e-15,  1.6211e-14, -6.3497e-15,  9.2617e-14,\n",
            "        -3.6422e-14,  5.0276e-14, -5.0563e-15, -4.9300e-14,  1.8489e-13,\n",
            "        -4.8477e-16, -4.5660e-14,  5.5698e-14, -1.1887e-13,  7.2007e-14,\n",
            "        -2.1201e-14, -5.2215e-14, -8.2928e-14, -3.1413e-14,  4.9347e-14,\n",
            "         6.1885e-14, -6.5343e-14,  4.3196e-14, -4.6434e-14, -6.3348e-15,\n",
            "        -1.0768e-13,  1.9699e-14,  6.8870e-04, -1.1265e-04, -4.1759e-05,\n",
            "        -2.0178e-04, -8.4688e-05,  1.2670e-04, -2.9487e-04,  1.9915e-04,\n",
            "         3.0724e-04, -1.9583e-04,  4.0327e-04, -1.1692e-03, -4.9604e-04,\n",
            "        -1.0947e-03, -5.9119e-04, -3.2924e-04, -1.5642e-03,  1.3308e-03,\n",
            "        -1.0571e-05,  7.2870e-04, -2.9552e-04, -1.4255e-03,  1.6419e-05,\n",
            "        -7.5380e-05, -2.3632e-04, -5.4133e-04, -3.8453e-06,  3.9592e-05,\n",
            "        -3.5870e-04,  6.8108e-04, -4.1253e-04,  8.0323e-04,  4.4511e-04,\n",
            "        -1.3122e-03,  3.6848e-05, -2.8097e-04, -3.9479e-05,  1.0570e-03,\n",
            "         5.8353e-04,  1.3126e-04, -1.0270e-03,  8.2728e-04,  5.9998e-04,\n",
            "        -9.3740e-05, -1.2457e-03, -6.0841e-04,  1.8486e-03, -1.2395e-04,\n",
            "        -2.5876e-04,  3.4004e-04, -7.7347e-04,  3.3836e-04, -3.3059e-04,\n",
            "         3.2047e-04, -3.4707e-04,  1.7403e-03,  3.3478e-04,  5.1348e-04,\n",
            "         7.3074e-04,  7.5815e-05, -7.0992e-04, -1.1190e-04, -2.9038e-04,\n",
            "        -1.0173e-03, -3.5748e-05, -1.6819e-03,  5.4110e-04,  7.5531e-05,\n",
            "         1.6359e-04,  1.0151e-03,  1.7589e-03,  2.7374e-05, -1.6212e-04,\n",
            "         3.1108e-04,  3.2405e-04,  1.5240e-04,  9.5250e-04,  3.0984e-04,\n",
            "         7.8952e-04,  6.5299e-04,  1.3901e-03, -2.2468e-04,  5.8357e-04,\n",
            "        -4.5995e-04, -5.1123e-04, -1.9299e-04, -4.3523e-04,  1.5332e-03,\n",
            "        -2.3514e-04,  6.3226e-04,  1.5063e-04, -3.8933e-04, -9.5089e-04,\n",
            "        -7.0250e-05, -6.5943e-04,  1.2192e-03,  3.8697e-04,  6.2673e-05,\n",
            "         4.3822e-04,  6.7176e-04,  5.7688e-04,  5.0670e-04, -5.3665e-04,\n",
            "         1.1619e-03, -3.3599e-04, -3.9630e-04,  7.1335e-04, -1.5663e-04,\n",
            "        -5.1985e-04,  4.6660e-05, -5.3168e-04, -5.4670e-05,  6.3640e-04,\n",
            "        -1.6566e-03,  7.0569e-04,  4.7417e-04, -1.4932e-04, -9.4414e-05,\n",
            "        -4.2594e-04,  9.4701e-04,  2.1106e-04, -5.5618e-04,  6.5524e-04,\n",
            "        -2.5424e-04, -2.9483e-04,  5.9163e-04, -1.3253e-03, -5.4827e-04,\n",
            "         1.1619e-03,  1.0595e-03,  6.8859e-04, -3.4825e-04,  1.2197e-03,\n",
            "        -9.8028e-04,  9.4243e-04,  1.7380e-03, -2.9955e-04,  9.9977e-04,\n",
            "        -2.9256e-04, -5.5587e-04, -5.9513e-04,  6.2844e-04,  2.0067e-04,\n",
            "         3.0296e-06, -7.7465e-04, -8.3994e-04,  8.5312e-04,  1.2555e-04,\n",
            "         2.2025e-04, -1.8292e-04,  4.3651e-05,  3.9402e-04,  1.8231e-03,\n",
            "         3.3159e-04, -9.1580e-04, -5.6312e-05,  3.8234e-04,  3.6217e-04,\n",
            "        -1.6437e-04,  5.9751e-04,  3.1178e-04, -2.9954e-04,  4.9261e-04,\n",
            "        -5.2046e-04, -8.3382e-05,  5.6528e-04, -5.7441e-04,  1.9439e-04,\n",
            "        -2.2747e-04,  9.2165e-04,  5.4799e-04, -3.6532e-04,  3.5674e-04,\n",
            "         7.8453e-05, -2.6596e-04, -4.6455e-04,  1.4715e-03, -1.1903e-03,\n",
            "         1.5736e-03,  4.7607e-04,  5.8178e-04, -6.2069e-04, -6.0660e-04,\n",
            "         9.7885e-05, -9.9569e-05,  6.9430e-04, -1.5217e-04, -3.9760e-04,\n",
            "        -1.0262e-03, -2.8296e-04,  1.0269e-04,  4.7750e-04, -3.6926e-05,\n",
            "         3.7323e-05, -5.1380e-04,  1.6086e-04,  1.4453e-03, -3.0119e-04,\n",
            "        -7.9432e-04,  2.3424e-04,  8.0680e-04,  4.6113e-04, -4.5319e-04,\n",
            "        -8.1161e-04,  1.0511e-03, -9.8806e-05,  2.9540e-05, -4.4640e-04,\n",
            "        -7.7109e-04,  5.3641e-05,  6.2997e-04, -4.5718e-04,  4.6092e-04,\n",
            "         2.8821e-04,  2.2463e-03, -2.0140e-04, -7.0816e-04, -1.1389e-03,\n",
            "         2.4868e-03, -1.0356e-03, -9.8356e-04, -1.3617e-04, -1.2611e-04,\n",
            "        -1.8461e-04,  1.6440e-04, -1.9913e-03,  2.3059e-04, -1.2210e-04,\n",
            "         9.3723e-05, -4.1660e-05, -3.6712e-04,  1.0791e-03, -2.8415e-04,\n",
            "        -2.2042e-04,  3.1000e-04, -1.0896e-03,  3.9229e-05,  6.0068e-04,\n",
            "        -8.9747e-05, -6.0507e-04,  2.6074e-04,  1.8099e-04, -1.0988e-03,\n",
            "        -4.6025e-04,  1.1538e-03,  2.0813e-05,  5.2905e-04, -9.6214e-04,\n",
            "        -3.9719e-04, -5.8440e-04,  4.7062e-04, -7.7467e-04, -6.6560e-04,\n",
            "        -1.7200e-04, -4.0022e-04,  2.0560e-04])), ('hsi_attention_submodel.attention_module.multihead_attn.out_proj.weight', tensor([[-0.0319, -0.0271,  0.0364,  ...,  0.0004, -0.0622, -0.0358],\n",
            "        [-0.0312,  0.0209, -0.0382,  ...,  0.0393, -0.0063, -0.0460],\n",
            "        [-0.0354,  0.0587,  0.0547,  ...,  0.0257,  0.0426, -0.0607],\n",
            "        ...,\n",
            "        [ 0.0533,  0.0015,  0.0128,  ..., -0.0307,  0.0059, -0.0438],\n",
            "        [ 0.0091,  0.0579,  0.0220,  ..., -0.0629,  0.0615, -0.0045],\n",
            "        [ 0.0133, -0.0056,  0.0622,  ...,  0.0514,  0.0003, -0.0616]])), ('hsi_attention_submodel.attention_module.multihead_attn.out_proj.bias', tensor([-4.0064e-03, -7.9114e-05,  1.2186e-03, -1.2989e-03, -1.3554e-03,\n",
            "         4.1582e-05, -2.1617e-03,  2.8257e-03,  4.0867e-03, -1.2756e-06,\n",
            "        -9.6352e-04, -9.8173e-04,  1.7434e-03,  2.1005e-04,  8.8681e-04,\n",
            "        -4.4356e-04, -2.6896e-03,  2.7146e-04,  1.4319e-03, -1.7909e-03,\n",
            "         1.3997e-03, -2.4172e-03,  2.0686e-03,  2.3012e-03, -7.6353e-04,\n",
            "        -1.2994e-04,  5.8537e-04, -1.8956e-05, -1.5577e-04, -4.7821e-05,\n",
            "         2.7462e-03, -2.0982e-03, -1.5829e-03, -3.7659e-04, -2.7328e-03,\n",
            "        -1.7571e-03, -2.1541e-03, -7.8747e-04, -2.0480e-03,  2.1712e-03,\n",
            "        -5.7056e-04,  9.6827e-04, -2.6552e-03,  9.5114e-04,  1.9687e-03,\n",
            "        -1.5611e-03, -1.9618e-03,  2.0227e-03, -3.4474e-03, -3.7692e-03,\n",
            "        -3.2901e-03,  8.5771e-04, -1.1170e-03, -1.3118e-03,  2.0608e-03,\n",
            "         4.8293e-04, -4.1660e-06,  1.5987e-03, -1.1947e-03, -8.4536e-04,\n",
            "         1.3180e-03, -5.6512e-04,  2.6637e-03,  3.4449e-03,  2.0169e-03,\n",
            "        -6.6988e-05,  2.7714e-03,  6.0244e-04,  1.9954e-03, -9.5089e-04,\n",
            "         2.4827e-03, -4.0038e-04, -3.2252e-03, -1.0808e-03, -1.3538e-03,\n",
            "         2.9264e-03,  2.2542e-03,  1.8058e-03, -3.5003e-04, -5.9701e-04,\n",
            "        -8.2961e-04, -2.9017e-04, -9.5624e-05, -3.3587e-03, -5.5825e-03,\n",
            "         1.7539e-03, -1.7286e-03, -8.2624e-04,  1.7793e-03,  2.2806e-03,\n",
            "         1.2027e-03,  3.0341e-03, -2.8310e-03, -2.1819e-03,  1.6634e-03,\n",
            "        -2.3314e-03, -7.2665e-05,  2.9626e-04, -2.3196e-03,  1.5557e-03,\n",
            "         3.6662e-03,  2.9334e-03, -3.0810e-04,  1.0362e-04,  8.6381e-04,\n",
            "        -1.9877e-03,  2.5502e-03,  1.4021e-03,  2.6957e-03, -1.3893e-03,\n",
            "         5.0103e-04, -7.0268e-04,  9.7099e-04,  1.5361e-03,  2.2677e-03,\n",
            "        -1.7258e-03,  2.2372e-04,  3.3147e-04,  1.3414e-03,  1.1974e-03,\n",
            "         1.6252e-03,  3.1371e-03, -1.2183e-03,  1.5471e-03, -2.1549e-03,\n",
            "        -3.0497e-03,  1.9624e-03,  4.3695e-03,  1.6902e-03,  9.7793e-04,\n",
            "         2.0669e-04, -1.5833e-03,  1.8877e-03, -1.2847e-03, -1.5583e-03,\n",
            "         4.8015e-04, -2.5692e-04,  3.0742e-03, -6.1706e-04,  1.9083e-03,\n",
            "         5.7185e-04,  3.1031e-03,  2.6207e-03,  2.1401e-03, -2.1922e-03,\n",
            "        -2.4837e-03,  4.7077e-04,  2.9404e-04, -1.4826e-05,  2.6167e-03,\n",
            "         2.1064e-03, -6.3035e-04, -1.5463e-03, -1.4713e-03, -2.6222e-03,\n",
            "         2.6052e-03, -4.3516e-03,  3.8817e-03,  6.0225e-04, -1.7237e-03,\n",
            "        -1.4068e-03,  2.7645e-03, -9.0320e-04, -8.4440e-05, -1.5217e-04,\n",
            "         2.4151e-03,  2.2165e-03,  1.9975e-04,  5.7046e-04, -4.0104e-04,\n",
            "         1.1678e-03,  5.5866e-04, -1.1544e-03, -1.1898e-03,  1.6585e-03,\n",
            "        -2.8197e-03,  2.1328e-03,  1.2782e-03, -2.4772e-03, -3.3653e-03,\n",
            "        -6.1475e-04, -1.5887e-05,  2.6598e-04,  2.0658e-03,  2.4278e-03,\n",
            "        -1.3723e-03, -6.6988e-04, -3.2940e-03, -1.5628e-04,  1.7511e-03,\n",
            "         4.2227e-04, -1.8484e-03, -1.8769e-03, -1.2658e-03,  8.8568e-04,\n",
            "        -2.0275e-03, -7.0586e-04, -1.7496e-03, -2.4573e-03,  1.8234e-03,\n",
            "        -3.1891e-04, -1.5575e-04, -2.4591e-04, -1.6398e-03, -2.2782e-04,\n",
            "        -5.7087e-04,  1.2639e-03,  2.1100e-03, -1.9732e-03, -1.4804e-03,\n",
            "        -2.2359e-03, -1.4441e-03,  6.8450e-04, -1.9719e-04,  1.8255e-03,\n",
            "         9.9486e-04,  2.1714e-03,  3.3479e-03, -1.7522e-03,  8.4707e-04,\n",
            "         1.8286e-03, -1.2359e-03, -1.8110e-03, -9.3448e-04, -1.5697e-03,\n",
            "        -6.9237e-04, -3.6961e-04,  6.0484e-04,  1.8805e-04, -2.1669e-03,\n",
            "        -1.2418e-03, -2.0998e-03,  6.7755e-04, -8.0178e-04, -1.4127e-03,\n",
            "         2.5201e-03, -7.7639e-04,  1.8799e-04, -4.1205e-05, -2.9100e-03,\n",
            "         6.4411e-04,  1.3640e-03,  2.3721e-03,  9.6806e-04, -9.4710e-04,\n",
            "        -1.6286e-03, -1.4178e-05, -8.9580e-04, -1.6380e-03,  7.9567e-04,\n",
            "         2.3142e-03, -3.7423e-03,  1.1152e-04, -1.7564e-04, -7.3713e-04,\n",
            "         9.3654e-04])), ('hsi_attention_submodel.attention_module.linear1.weight', tensor([[-0.0598, -0.0437, -0.0301,  ..., -0.0207,  0.0599,  0.0039],\n",
            "        [ 0.0214,  0.0591, -0.0514,  ..., -0.0645,  0.0580, -0.0051],\n",
            "        [-0.0151,  0.0545, -0.0328,  ..., -0.0099, -0.0334,  0.0009],\n",
            "        ...,\n",
            "        [-0.0160, -0.0188,  0.0260,  ..., -0.0434,  0.0618, -0.0056],\n",
            "        [ 0.0184, -0.0025, -0.0635,  ...,  0.0624, -0.0072,  0.0183],\n",
            "        [ 0.0135,  0.0395,  0.0366,  ..., -0.0394,  0.0410, -0.0664]])), ('hsi_attention_submodel.attention_module.linear1.bias', tensor([ 0.0505, -0.0080,  0.0453,  0.0504,  0.0564,  0.0620,  0.0659,  0.0640,\n",
            "        -0.0399, -0.0472,  0.0100, -0.0244,  0.0117, -0.0305, -0.0202,  0.0249,\n",
            "        -0.0440,  0.0380,  0.0708,  0.0497,  0.0064,  0.0309, -0.0583,  0.0019,\n",
            "        -0.0308, -0.0228, -0.0089, -0.0305,  0.0500, -0.0054, -0.0253,  0.0178,\n",
            "        -0.0100,  0.0516,  0.0298,  0.0383,  0.0182,  0.0171, -0.0607,  0.0059,\n",
            "         0.0272, -0.0263,  0.0490,  0.0133,  0.0652, -0.0418, -0.0425, -0.0072,\n",
            "        -0.0341,  0.0085,  0.0441, -0.0234, -0.0170, -0.0193,  0.0626,  0.0392,\n",
            "        -0.0280, -0.0377,  0.0615, -0.0519, -0.0521, -0.0011, -0.0498, -0.0018,\n",
            "        -0.0207, -0.0595, -0.0105, -0.0194, -0.0095,  0.0071, -0.0118,  0.0414,\n",
            "        -0.0454, -0.0463,  0.0003,  0.0147,  0.0245,  0.0259,  0.0554, -0.0480,\n",
            "        -0.0641, -0.0057, -0.0190,  0.0041,  0.0737,  0.0378, -0.0370, -0.0061,\n",
            "         0.0014,  0.0499, -0.0002, -0.0370, -0.0136,  0.0247, -0.0219,  0.0065,\n",
            "        -0.0435, -0.0198,  0.0259,  0.0473,  0.0453,  0.0438,  0.0034,  0.0140,\n",
            "        -0.0257, -0.0029, -0.0118,  0.0533, -0.0548,  0.0393,  0.0080,  0.0624,\n",
            "         0.0595, -0.0073,  0.0275,  0.0315, -0.0168,  0.0144, -0.0231,  0.0036,\n",
            "         0.0494,  0.0035, -0.0588, -0.0425,  0.0149,  0.0448, -0.0302, -0.0485,\n",
            "         0.0260,  0.0204, -0.0458, -0.0171, -0.0532,  0.0057, -0.0008, -0.0116,\n",
            "         0.0310,  0.0217,  0.0238,  0.0290,  0.0265,  0.0395, -0.0512,  0.0378,\n",
            "         0.0144,  0.0097, -0.0234,  0.0491,  0.0607, -0.0255,  0.0149, -0.0327,\n",
            "         0.0029,  0.0194, -0.0216,  0.0360,  0.0438,  0.0270, -0.0099,  0.0403,\n",
            "        -0.0345,  0.0536, -0.0393, -0.0187,  0.0069, -0.0322,  0.0292,  0.0545,\n",
            "         0.0214, -0.0302, -0.0230, -0.0469, -0.0592, -0.0065,  0.0296,  0.0272,\n",
            "         0.0053,  0.0079,  0.0514,  0.0025, -0.0523,  0.0539,  0.0478, -0.0042,\n",
            "         0.0445,  0.0043, -0.0039, -0.0306,  0.0423, -0.0541,  0.0284,  0.0597,\n",
            "        -0.0627,  0.0088,  0.0496,  0.0320, -0.0015,  0.0575, -0.0035, -0.0520,\n",
            "         0.0276,  0.0651,  0.0215, -0.0407,  0.0504,  0.0109, -0.0183,  0.0141,\n",
            "        -0.0084,  0.0468, -0.0225,  0.0136, -0.0045,  0.0129, -0.0229, -0.0275,\n",
            "        -0.0637,  0.0411, -0.0207, -0.0252, -0.0442, -0.0307, -0.0196,  0.0182,\n",
            "         0.0173, -0.0284,  0.0587,  0.0298,  0.0475,  0.0259, -0.0154,  0.0474,\n",
            "         0.0529, -0.0425, -0.0573, -0.0380,  0.0159,  0.0168, -0.0261,  0.0265,\n",
            "         0.0421,  0.0328,  0.0124, -0.0600,  0.0228, -0.0536,  0.0487, -0.0593,\n",
            "         0.0026,  0.0386, -0.0418, -0.0195,  0.0194,  0.0268,  0.0199,  0.0428])), ('hsi_attention_submodel.attention_module.linear2.weight', tensor([[ 0.0558,  0.0334, -0.0365,  ..., -0.0415, -0.0255, -0.0576],\n",
            "        [ 0.0430,  0.0558,  0.0384,  ...,  0.0122,  0.0292, -0.0544],\n",
            "        [ 0.0133,  0.0082, -0.0094,  ..., -0.0033, -0.0070,  0.0113],\n",
            "        ...,\n",
            "        [-0.0426, -0.0250, -0.0559,  ..., -0.0575, -0.0054, -0.0592],\n",
            "        [-0.0021, -0.0115,  0.0182,  ...,  0.0176,  0.0392, -0.0588],\n",
            "        [ 0.0494,  0.0352, -0.0138,  ...,  0.0369, -0.0112,  0.0013]])), ('hsi_attention_submodel.attention_module.linear2.bias', tensor([ 0.0016,  0.0166,  0.0320,  0.0405, -0.0350,  0.0052,  0.0555,  0.0173,\n",
            "        -0.0098, -0.0152, -0.0352, -0.0215,  0.0005, -0.0500, -0.0201,  0.0468,\n",
            "         0.0588, -0.0117, -0.0367, -0.0246,  0.0169, -0.0136, -0.0314,  0.0363,\n",
            "         0.0105, -0.0225, -0.0072, -0.0078,  0.0140, -0.0153, -0.0036,  0.0181,\n",
            "         0.0513, -0.0194, -0.0280,  0.0130,  0.0334,  0.0557, -0.0284, -0.0329,\n",
            "        -0.0224,  0.0042, -0.0388,  0.0551,  0.0225,  0.0586, -0.0373, -0.0046,\n",
            "         0.0512, -0.0502,  0.0473,  0.0217,  0.0038,  0.0188,  0.0677, -0.0222,\n",
            "         0.0581, -0.0304,  0.0552,  0.0345, -0.0015, -0.0499, -0.0518,  0.0339,\n",
            "        -0.0406,  0.0284,  0.0286,  0.0206,  0.0240, -0.0521, -0.0417,  0.0034,\n",
            "        -0.0331,  0.0188, -0.0648, -0.0137, -0.0239,  0.0375,  0.0711, -0.0578,\n",
            "         0.0223, -0.0232,  0.0002, -0.0377, -0.0403, -0.0493, -0.0476,  0.0487,\n",
            "        -0.0012,  0.0136,  0.0659,  0.0205, -0.0266,  0.0274, -0.0042,  0.0511,\n",
            "        -0.0290, -0.0126,  0.0240,  0.0457,  0.0117, -0.0318, -0.0359, -0.0564,\n",
            "        -0.0118, -0.0060,  0.0579,  0.0401,  0.0245, -0.0116,  0.0126, -0.0309,\n",
            "        -0.0194,  0.0273, -0.0570,  0.0557,  0.0599, -0.0208, -0.0395, -0.0017,\n",
            "        -0.0248, -0.0561, -0.0103,  0.0464, -0.0064, -0.0220, -0.0149,  0.0367,\n",
            "        -0.0051,  0.0386,  0.0153,  0.0264,  0.0401,  0.0336,  0.0119,  0.0020,\n",
            "         0.0491, -0.0059, -0.0506, -0.0002, -0.0271,  0.0566, -0.0166,  0.0318,\n",
            "         0.0344,  0.0352,  0.0080,  0.0036, -0.0555, -0.0529, -0.0318, -0.0020,\n",
            "         0.0025,  0.0224, -0.0028, -0.0231,  0.0366, -0.0525, -0.0324, -0.0151,\n",
            "        -0.0374,  0.0277,  0.0497,  0.0074, -0.0295,  0.0167,  0.0095, -0.0127,\n",
            "        -0.0277,  0.0193, -0.0547,  0.0280,  0.0204, -0.0497,  0.0184, -0.0382,\n",
            "        -0.0547,  0.0553, -0.0185,  0.0352,  0.0602, -0.0329,  0.0589, -0.0168,\n",
            "         0.0133,  0.0416, -0.0607, -0.0119, -0.0069, -0.0034,  0.0403,  0.0188,\n",
            "        -0.0193,  0.0547,  0.0212, -0.0491, -0.0425, -0.0016, -0.0034,  0.0452,\n",
            "        -0.0184, -0.0127, -0.0467, -0.0441,  0.0305, -0.0628,  0.0155, -0.0374,\n",
            "         0.0191,  0.0663,  0.0071,  0.0250,  0.0194, -0.0244, -0.0310,  0.0282,\n",
            "         0.0496, -0.0291, -0.0139,  0.0220, -0.0354, -0.0402,  0.0293, -0.0426,\n",
            "        -0.0554, -0.0617,  0.0243, -0.0221,  0.0550,  0.0630, -0.0248, -0.0349,\n",
            "         0.0404, -0.0626, -0.0159,  0.0422, -0.0118,  0.0591,  0.0429,  0.0310,\n",
            "         0.0121, -0.0219,  0.0164,  0.0293,  0.0158,  0.0173,  0.0439,  0.0075,\n",
            "        -0.0533,  0.0182, -0.0587,  0.0003, -0.0224, -0.0318,  0.0350,  0.0180])), ('hsi_attention_submodel.attention_module.linear3.weight', tensor([[-0.0338, -0.0229,  0.0424,  ...,  0.0254,  0.0456,  0.0318],\n",
            "        [ 0.0170,  0.0532, -0.0354,  ..., -0.0365, -0.0653,  0.0585],\n",
            "        [-0.0435,  0.0073,  0.0534,  ...,  0.0059,  0.0042,  0.0286],\n",
            "        ...,\n",
            "        [ 0.0466, -0.0237,  0.0057,  ...,  0.0398, -0.0061,  0.0067],\n",
            "        [ 0.0362,  0.0351, -0.0280,  ...,  0.0123, -0.0409,  0.0048],\n",
            "        [ 0.0356, -0.0435, -0.0621,  ...,  0.0471,  0.0389, -0.0218]])), ('hsi_attention_submodel.attention_module.linear3.bias', tensor([-8.8957e-03, -3.6991e-02,  5.0671e-02,  2.0049e-03,  2.6686e-02,\n",
            "        -4.3268e-03,  2.9320e-02, -1.1603e-02,  6.9141e-02, -3.4898e-02,\n",
            "         6.5855e-02,  3.5870e-02,  3.6546e-02,  1.9383e-02,  4.1908e-02,\n",
            "        -2.3041e-02,  1.0833e-02, -2.6516e-02, -4.1238e-02,  4.6233e-02,\n",
            "        -3.5487e-02,  2.2094e-02, -6.2592e-02,  3.7443e-02, -3.9142e-02,\n",
            "        -4.4420e-02, -3.1139e-02,  5.8793e-02,  1.5230e-02, -7.5288e-03,\n",
            "        -1.1391e-02,  6.3358e-02,  1.1677e-02,  1.2972e-02,  4.8158e-02,\n",
            "        -5.1543e-02,  8.4013e-03, -1.0113e-02, -1.6246e-02, -6.1156e-02,\n",
            "         2.7524e-02, -2.9134e-02, -4.6920e-02, -1.9273e-02,  1.7914e-02,\n",
            "        -6.1917e-02, -3.1923e-04,  3.8157e-02,  5.3972e-02, -1.7512e-02,\n",
            "        -9.4546e-03, -3.9477e-02,  4.1483e-03,  3.5472e-02, -6.4971e-03,\n",
            "        -4.8786e-02, -1.8876e-02,  6.2983e-02,  6.8410e-02,  3.4653e-02,\n",
            "        -3.0433e-02,  3.0759e-02, -1.3482e-02, -3.4048e-03, -4.6905e-02,\n",
            "        -2.3834e-02, -3.3951e-02, -4.2312e-02, -3.2273e-02, -3.9575e-02,\n",
            "        -1.5360e-02,  7.7065e-03, -5.7931e-02, -3.2615e-02,  1.8552e-02,\n",
            "        -4.0612e-02,  3.9845e-03,  5.7572e-02,  4.0082e-02, -2.9782e-02,\n",
            "         3.2764e-02,  4.9750e-02, -5.5143e-02, -2.4829e-03, -5.0037e-02,\n",
            "        -3.5446e-02, -3.6406e-02,  7.7152e-02, -4.1246e-03,  6.8331e-03,\n",
            "        -4.1407e-02,  1.4418e-02, -3.8023e-02, -2.4456e-02, -1.2533e-02,\n",
            "        -4.2472e-03,  4.4877e-02,  3.2644e-02,  2.0656e-02,  4.2517e-02,\n",
            "        -2.7762e-02,  1.4969e-02,  1.0280e-02,  3.5571e-02, -2.2188e-02,\n",
            "         4.4273e-05, -2.6965e-03,  2.3642e-02,  5.8148e-02, -2.9704e-02,\n",
            "        -9.4872e-03, -1.1189e-02,  6.3948e-02,  9.3414e-03,  3.9056e-02,\n",
            "        -5.0481e-02,  7.6585e-04, -7.7399e-03,  4.6162e-02, -5.7755e-02,\n",
            "         2.4067e-02,  8.8772e-03,  2.4609e-02,  2.6113e-02,  5.4403e-02,\n",
            "         5.2545e-02, -5.0573e-02,  8.1883e-02,  4.0541e-02,  3.1364e-02,\n",
            "         1.9074e-02, -4.5106e-02, -4.6156e-02, -3.4300e-02,  5.3781e-02,\n",
            "         2.9344e-02, -1.0720e-02,  4.1002e-02, -3.3648e-02,  3.7035e-02,\n",
            "         5.3635e-02, -2.6582e-02, -5.4111e-02, -4.9877e-02])), ('hsi_attention_submodel.attention_module.final_linear.weight', tensor([[-0.0144,  0.0318,  0.0809,  ..., -0.0620,  0.0136,  0.0260],\n",
            "        [-0.0901, -0.0547, -0.0729,  ..., -0.0194,  0.0897, -0.0517],\n",
            "        [-0.0578,  0.0855, -0.0171,  ...,  0.0889, -0.0345,  0.0281],\n",
            "        ...,\n",
            "        [ 0.0557, -0.0551, -0.0152,  ...,  0.0060,  0.0827, -0.0481],\n",
            "        [-0.0829,  0.0214, -0.0434,  ..., -0.0391,  0.0529,  0.0412],\n",
            "        [-0.0407, -0.0040,  0.0632,  ..., -0.0646,  0.0369, -0.0408]])), ('hsi_attention_submodel.attention_module.final_linear.bias', tensor([ 6.0180e-03, -5.9117e-02,  5.6000e-02, -5.7072e-02, -9.0183e-02,\n",
            "         5.8562e-02, -6.9592e-02,  5.3468e-02,  2.2848e-03,  5.0190e-02,\n",
            "        -5.6885e-02, -5.1377e-03,  4.0277e-02, -3.0910e-02, -3.1904e-02,\n",
            "        -1.0698e-02,  1.0846e-02, -8.0973e-02, -6.1668e-02, -9.0398e-03,\n",
            "        -1.1792e-03, -4.4807e-02,  2.4272e-02,  5.5999e-02, -1.2873e-02,\n",
            "         5.4548e-02,  4.9514e-02,  4.9834e-02,  2.2252e-02,  9.0683e-03,\n",
            "        -7.8168e-02, -6.1810e-03,  6.0117e-02, -8.2110e-02, -7.8611e-02,\n",
            "         2.8724e-02, -5.7232e-02, -4.5119e-02,  6.0446e-02, -2.9862e-03,\n",
            "         4.0696e-02, -4.9972e-02, -7.8767e-02, -6.2426e-02, -7.6508e-02,\n",
            "        -5.6767e-02, -6.1389e-02,  1.5449e-02, -2.8197e-02, -6.8019e-03,\n",
            "         3.5818e-02, -9.4194e-02,  4.2374e-02, -2.5674e-02,  1.6986e-02,\n",
            "         5.2938e-02, -5.7730e-02, -8.8089e-02, -6.1896e-02,  3.2257e-02,\n",
            "         4.4130e-03, -7.4538e-02,  5.5109e-02, -7.7753e-02, -1.2116e-02,\n",
            "        -5.8815e-02, -5.1054e-03, -6.6074e-02, -7.8550e-02,  5.7951e-02,\n",
            "        -9.3483e-02,  2.5123e-02,  3.4032e-03, -4.9247e-02,  1.4262e-02,\n",
            "         6.7308e-02,  4.8439e-02, -6.1428e-02,  5.5817e-02, -7.7043e-02,\n",
            "         6.4943e-02, -1.7004e-02, -9.3895e-03,  2.0857e-03, -1.8828e-02,\n",
            "         5.6425e-02, -8.4729e-02,  7.9037e-05, -4.6084e-02, -4.6444e-02,\n",
            "        -2.1619e-02, -8.1448e-02, -7.7943e-02,  2.3727e-02, -5.8951e-02,\n",
            "        -5.4704e-02,  4.3453e-02,  2.1934e-02,  5.0096e-02,  2.9861e-02,\n",
            "        -1.6274e-02, -6.8064e-02,  1.0730e-02, -1.3007e-02, -7.3973e-02,\n",
            "        -3.6545e-02, -5.6253e-02, -1.0358e-03, -4.5335e-02, -3.2266e-02,\n",
            "        -7.6537e-02, -8.1832e-02, -3.3112e-02,  1.0555e-02,  6.9822e-02,\n",
            "        -1.1602e-02, -2.4987e-02, -5.3826e-02, -5.4134e-02, -2.4812e-02,\n",
            "         3.1172e-02,  2.5923e-02,  2.0099e-02,  1.0557e-02,  2.5768e-02,\n",
            "        -1.0840e-02,  6.7285e-02, -1.8118e-02, -7.4101e-02,  4.0152e-02,\n",
            "         4.9137e-03, -4.5209e-02, -1.5580e-02, -7.4751e-02, -7.7179e-02,\n",
            "         2.8217e-02, -2.8029e-02,  2.4213e-02, -2.6569e-02, -6.1849e-02,\n",
            "        -2.1400e-02, -6.5065e-02, -8.5010e-02, -2.0884e-02])), ('lidar_attention_submodel.patch_embedding.pos_embedding', tensor([[[ 2.5901e-04, -3.7757e-05,  1.2616e-04,  ..., -4.1799e-04,\n",
            "           4.5314e-04,  3.5654e-04],\n",
            "         [ 2.5923e-04, -3.8686e-05,  1.2178e-04,  ..., -4.1680e-04,\n",
            "           4.5120e-04,  3.5185e-04],\n",
            "         [ 2.5707e-04, -3.5503e-05,  1.1951e-04,  ..., -4.1471e-04,\n",
            "           4.4839e-04,  3.4528e-04],\n",
            "         ...,\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00]]])), ('lidar_attention_submodel.patch_embedding.proj.weight', tensor([[[[ 0.0187]],\n",
            "\n",
            "         [[ 0.0344]],\n",
            "\n",
            "         [[-0.0059]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0450]],\n",
            "\n",
            "         [[ 0.0614]],\n",
            "\n",
            "         [[-0.0240]]],\n",
            "\n",
            "\n",
            "        [[[-0.0659]],\n",
            "\n",
            "         [[-0.0772]],\n",
            "\n",
            "         [[-0.0562]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0187]],\n",
            "\n",
            "         [[-0.0117]],\n",
            "\n",
            "         [[ 0.0432]]],\n",
            "\n",
            "\n",
            "        [[[-0.0577]],\n",
            "\n",
            "         [[ 0.0732]],\n",
            "\n",
            "         [[ 0.0104]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0689]],\n",
            "\n",
            "         [[-0.0567]],\n",
            "\n",
            "         [[-0.0296]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0112]],\n",
            "\n",
            "         [[ 0.0821]],\n",
            "\n",
            "         [[ 0.0041]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0378]],\n",
            "\n",
            "         [[-0.0672]],\n",
            "\n",
            "         [[ 0.0639]]],\n",
            "\n",
            "\n",
            "        [[[-0.0645]],\n",
            "\n",
            "         [[ 0.0693]],\n",
            "\n",
            "         [[-0.0467]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0020]],\n",
            "\n",
            "         [[ 0.0530]],\n",
            "\n",
            "         [[-0.0523]]],\n",
            "\n",
            "\n",
            "        [[[-0.0162]],\n",
            "\n",
            "         [[ 0.0705]],\n",
            "\n",
            "         [[ 0.0720]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0628]],\n",
            "\n",
            "         [[-0.0254]],\n",
            "\n",
            "         [[ 0.0084]]]])), ('lidar_attention_submodel.patch_embedding.proj.bias', tensor([-0.0643, -0.0700,  0.0650, -0.0845,  0.0004,  0.0747, -0.0203,  0.0097,\n",
            "        -0.0132, -0.0801,  0.0745,  0.0494, -0.0486, -0.0130,  0.0604, -0.0157,\n",
            "         0.0640, -0.0561, -0.0422, -0.0549, -0.0650,  0.0647,  0.0434, -0.0425,\n",
            "        -0.0283,  0.0329,  0.0245, -0.0303,  0.0243, -0.0721, -0.0072, -0.0167,\n",
            "         0.0665, -0.0589, -0.0331,  0.0536,  0.0722,  0.0071, -0.0019,  0.0186,\n",
            "         0.0381, -0.0130, -0.0723, -0.0781, -0.0597, -0.0394,  0.0144, -0.0096,\n",
            "        -0.0742,  0.0326,  0.0579,  0.0383,  0.0536,  0.0091,  0.0169, -0.0401,\n",
            "        -0.0456, -0.0589,  0.0215, -0.0809,  0.0005,  0.0383, -0.0224,  0.0735,\n",
            "         0.0462, -0.0111,  0.0620, -0.0318,  0.0479, -0.0680, -0.0486, -0.0653,\n",
            "        -0.0077,  0.0710,  0.0587,  0.0347, -0.0663,  0.0324, -0.0377,  0.0182,\n",
            "        -0.0176, -0.0503, -0.0236, -0.0684, -0.0442,  0.0073,  0.0557, -0.0217,\n",
            "         0.0330,  0.0011, -0.0410,  0.0653,  0.0639, -0.0804,  0.0521,  0.0591,\n",
            "        -0.0795,  0.0434, -0.0670,  0.0826, -0.0491,  0.0186, -0.0298,  0.0340,\n",
            "        -0.0091,  0.0403,  0.0057, -0.0619,  0.0431, -0.0335, -0.0515, -0.0403,\n",
            "        -0.0109,  0.0351, -0.0031, -0.0325, -0.0322, -0.0046, -0.0471,  0.0594,\n",
            "         0.0062, -0.0545,  0.0525, -0.0192, -0.0572, -0.0503, -0.0765,  0.0104,\n",
            "        -0.0036,  0.0661, -0.0352,  0.0033, -0.0471, -0.0664,  0.0722,  0.0154,\n",
            "        -0.0707,  0.0400, -0.0432,  0.0666,  0.0478, -0.0682, -0.0035, -0.0027,\n",
            "        -0.0262, -0.0607,  0.0587,  0.0073,  0.0346,  0.0558,  0.0453,  0.0131,\n",
            "        -0.0683, -0.0049,  0.0317, -0.0030,  0.0384, -0.0485, -0.0300, -0.0112,\n",
            "        -0.0172, -0.0017, -0.0694, -0.0085, -0.0176, -0.0278,  0.0141, -0.0540,\n",
            "        -0.0620, -0.0562, -0.0350,  0.0180,  0.0455,  0.0527,  0.0732, -0.0294,\n",
            "        -0.0037,  0.0440, -0.0150, -0.0418,  0.0812,  0.0288,  0.0555,  0.0304,\n",
            "         0.0487, -0.0020, -0.0181, -0.0081,  0.0587,  0.0142,  0.0793,  0.0039,\n",
            "        -0.0490,  0.0273,  0.0133, -0.0046, -0.0212, -0.0180, -0.0790,  0.0035,\n",
            "         0.0757, -0.0616, -0.0363, -0.0655,  0.0007, -0.0311,  0.0173,  0.0339,\n",
            "         0.0478,  0.0524, -0.0563, -0.0119, -0.0292,  0.0176,  0.0612,  0.0156,\n",
            "         0.0356,  0.0084,  0.0713,  0.0296,  0.0231, -0.0815,  0.0569,  0.0526,\n",
            "        -0.0503,  0.0089, -0.0786, -0.0344,  0.0489, -0.0309, -0.0816, -0.0252,\n",
            "         0.0158, -0.0390, -0.0497, -0.0748,  0.0690,  0.0506, -0.0847, -0.0809,\n",
            "         0.0418,  0.0269,  0.0740, -0.0525, -0.0508, -0.0375, -0.0617,  0.0513,\n",
            "        -0.0783, -0.0016, -0.0016, -0.0679, -0.0258, -0.0298, -0.0297,  0.0427])), ('lidar_attention_submodel.attention_module.input_projection.weight', tensor([[-0.0451, -0.0101,  0.0269,  ...,  0.0259,  0.0408,  0.0065],\n",
            "        [ 0.0353,  0.0559, -0.0195,  ..., -0.0430, -0.0142,  0.0599],\n",
            "        [-0.0037, -0.0082,  0.0171,  ..., -0.0433,  0.0373, -0.0315],\n",
            "        ...,\n",
            "        [ 0.0261, -0.0373, -0.0206,  ..., -0.0243, -0.0018, -0.0501],\n",
            "        [-0.0355, -0.0332, -0.0062,  ..., -0.0281, -0.0336,  0.0396],\n",
            "        [-0.0301,  0.0089,  0.0143,  ..., -0.0577, -0.0067, -0.0063]])), ('lidar_attention_submodel.attention_module.input_projection.bias', tensor([-1.4270e-02,  5.0983e-02,  1.6040e-03, -3.3389e-02, -5.0542e-02,\n",
            "        -3.6162e-02, -5.0324e-02, -5.4859e-02,  1.3874e-02, -9.1500e-03,\n",
            "        -5.9157e-03,  3.7426e-02,  2.4987e-02,  6.4621e-02,  4.5715e-02,\n",
            "         4.2324e-02, -5.4691e-02, -2.0042e-02,  5.9915e-02, -5.2220e-02,\n",
            "         5.1458e-02,  5.0232e-02, -3.8870e-02,  1.3913e-02,  1.2728e-03,\n",
            "         6.6151e-03, -2.3900e-02,  4.3087e-02,  1.9545e-02,  6.9110e-02,\n",
            "        -3.5127e-02, -3.4427e-02,  6.0025e-02,  6.0335e-03,  4.7684e-02,\n",
            "        -3.9888e-02, -4.9520e-02, -5.3029e-02, -5.4453e-02,  4.3663e-02,\n",
            "        -2.0894e-03,  2.5385e-02, -3.9602e-02,  3.2721e-02, -3.1843e-02,\n",
            "        -4.6341e-02,  1.4071e-02,  3.5808e-02, -3.8833e-02, -2.4129e-02,\n",
            "         5.2989e-02, -3.3947e-02, -4.7457e-02, -2.9304e-02, -2.4129e-02,\n",
            "        -1.7968e-03, -5.2893e-02,  5.3100e-03, -3.0246e-02, -3.2575e-02,\n",
            "         6.3643e-03,  5.6459e-02,  1.5583e-02,  4.5694e-03,  1.6556e-02,\n",
            "         4.9698e-02, -2.6423e-03, -2.7143e-02,  5.0981e-02,  4.2945e-02,\n",
            "        -4.1995e-02,  5.0515e-02, -3.9434e-02,  2.2520e-02, -4.9334e-02,\n",
            "        -9.0767e-03, -4.5486e-02,  5.8619e-02,  4.8082e-02,  6.1563e-02,\n",
            "         5.1755e-02,  1.9336e-02,  2.0652e-02,  2.6693e-02, -2.5748e-02,\n",
            "        -2.9941e-02, -4.1552e-02,  5.6446e-02,  4.5036e-02, -6.4728e-03,\n",
            "         3.9507e-02, -3.3980e-02, -2.0126e-02,  1.7271e-02,  2.0000e-03,\n",
            "         1.8113e-02,  2.5432e-02, -8.0302e-03,  4.4944e-02,  3.6861e-02,\n",
            "         4.8325e-02,  4.9324e-02,  5.2788e-04,  1.7002e-02, -5.7462e-02,\n",
            "         5.7316e-02,  5.3201e-02,  4.8380e-02, -4.4000e-02,  1.3510e-02,\n",
            "        -3.7557e-02,  1.9389e-02, -3.5649e-02, -4.5465e-02, -5.7143e-02,\n",
            "         5.6745e-02, -1.0017e-02, -1.2111e-03,  2.5118e-02, -3.2184e-02,\n",
            "        -1.7968e-02,  5.5197e-02,  5.1696e-02, -4.6980e-02, -1.4367e-02,\n",
            "        -2.1026e-02, -6.0109e-02,  3.6922e-02, -3.3162e-02, -7.9786e-03,\n",
            "        -2.4750e-02,  3.5556e-02, -2.4573e-02,  3.3648e-02,  3.8188e-02,\n",
            "        -2.3487e-02, -3.3845e-02, -1.4603e-02, -3.0334e-02,  7.2169e-03,\n",
            "         1.5946e-02, -3.4392e-02, -2.9023e-02, -1.7550e-02, -1.0539e-03,\n",
            "         5.9697e-02,  3.8631e-02, -2.5963e-02,  2.3262e-03, -2.2628e-02,\n",
            "         6.4532e-03,  5.6377e-02, -1.1074e-02,  2.1205e-03,  3.8849e-02,\n",
            "         2.8990e-02,  3.8033e-02,  4.7021e-02,  3.3763e-03, -2.8827e-02,\n",
            "         3.4848e-02,  2.5606e-03,  3.5387e-02, -1.6820e-02, -4.1076e-02,\n",
            "         3.5042e-02, -6.2724e-02, -4.6924e-02, -3.4516e-02, -2.8183e-05,\n",
            "        -6.0871e-02, -5.3796e-04, -2.6336e-02,  1.4090e-02,  1.7859e-02,\n",
            "         3.6834e-02, -3.1966e-02, -4.5293e-02, -3.0622e-02, -1.1590e-02,\n",
            "        -3.6317e-02,  4.8153e-02, -3.7122e-02, -2.1267e-02, -4.1660e-02,\n",
            "         5.7412e-02,  5.5916e-02, -3.1360e-02,  1.5685e-02,  3.4494e-02,\n",
            "        -4.7027e-02, -4.0705e-03, -8.8673e-03,  3.2725e-02, -9.0909e-03,\n",
            "        -9.9352e-03, -4.0136e-02, -9.4733e-03,  4.0116e-02,  5.6271e-02,\n",
            "         5.6478e-02,  9.6062e-03,  5.2462e-02, -4.8564e-02,  4.9490e-02,\n",
            "         3.9530e-02,  2.8333e-02,  1.6530e-02,  4.4896e-02, -4.5932e-02,\n",
            "         1.5950e-03, -5.0059e-02, -1.7518e-02, -9.1339e-03,  2.3433e-03,\n",
            "        -1.0205e-02,  5.0659e-02,  1.0947e-02,  1.6650e-02, -1.2691e-02,\n",
            "         3.3862e-02, -3.8719e-02,  4.5019e-02,  5.3504e-03, -1.8995e-02,\n",
            "        -4.4368e-02, -6.7079e-02,  1.3580e-02, -5.3189e-02, -2.1264e-03,\n",
            "         5.7026e-02, -8.0311e-03,  3.4309e-02, -5.2758e-02,  3.1470e-03,\n",
            "        -1.9762e-02,  3.6901e-02, -1.2125e-02,  6.5733e-03,  5.3633e-02,\n",
            "         3.7448e-02,  3.3411e-02,  2.9409e-02,  3.9122e-02, -5.2368e-02,\n",
            "         7.8673e-03, -2.5129e-02, -1.3160e-02, -3.2424e-02, -1.9887e-02,\n",
            "         2.5865e-02, -4.0011e-02,  6.3580e-04,  2.8479e-02, -5.9446e-02,\n",
            "        -5.1172e-02])), ('lidar_attention_submodel.attention_module.norm1.weight', tensor([0.9996, 1.0001, 0.9996, 0.9999, 1.0004, 0.9996, 1.0000, 0.9999, 0.9999,\n",
            "        1.0000, 1.0000, 1.0003, 1.0000, 1.0007, 1.0000, 0.9999, 0.9999, 1.0002,\n",
            "        1.0001, 0.9995, 0.9996, 1.0000, 1.0000, 1.0003, 1.0000, 0.9998, 1.0002,\n",
            "        1.0002, 1.0000, 1.0001, 1.0001, 0.9997, 1.0000, 1.0007, 1.0000, 1.0010,\n",
            "        0.9996, 1.0016, 1.0001, 1.0000, 1.0001, 1.0000, 0.9999, 1.0000, 1.0000,\n",
            "        1.0001, 1.0002, 0.9999, 0.9995, 0.9999, 1.0002, 1.0013, 1.0000, 0.9992,\n",
            "        1.0000, 0.9999, 1.0002, 0.9995, 1.0001, 0.9998, 1.0003, 0.9996, 1.0000,\n",
            "        0.9998, 0.9997, 1.0004, 1.0003, 1.0002, 0.9997, 0.9999, 0.9998, 0.9998,\n",
            "        1.0001, 0.9999, 1.0001, 1.0000, 1.0000, 1.0003, 0.9996, 1.0003, 1.0000,\n",
            "        0.9999, 1.0001, 0.9999, 1.0001, 1.0000, 0.9996, 1.0001, 0.9988, 1.0000,\n",
            "        1.0001, 1.0006, 1.0001, 1.0000, 1.0000, 1.0003, 1.0001, 1.0001, 0.9997,\n",
            "        0.9999, 1.0003, 1.0003, 1.0001, 0.9998, 1.0000, 1.0002, 1.0001, 0.9992,\n",
            "        0.9999, 1.0002, 1.0001, 1.0008, 1.0000, 1.0001, 0.9999, 1.0000, 1.0002,\n",
            "        0.9992, 1.0000, 1.0000, 1.0001, 0.9999, 0.9996, 1.0000, 0.9999, 1.0003,\n",
            "        1.0001, 1.0002, 1.0000, 1.0000, 0.9998, 1.0003, 0.9999, 0.9999, 1.0000,\n",
            "        1.0002, 1.0000, 1.0004, 0.9999, 1.0001, 0.9999, 0.9997, 1.0003, 1.0000,\n",
            "        0.9998, 1.0004, 1.0000, 0.9999, 1.0000, 0.9997, 0.9999, 1.0002, 1.0000,\n",
            "        1.0004, 1.0004, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 1.0001, 1.0001,\n",
            "        0.9999, 1.0003, 1.0000, 1.0009, 1.0002, 0.9996, 0.9999, 1.0000, 1.0004,\n",
            "        1.0007, 0.9995, 1.0009, 1.0000, 1.0003, 1.0001, 0.9997, 1.0002, 1.0000,\n",
            "        1.0000, 1.0002, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0001,\n",
            "        0.9993, 1.0002, 0.9999, 1.0000, 0.9998, 1.0000, 1.0000, 1.0001, 0.9996,\n",
            "        1.0000, 0.9999, 1.0004, 1.0011, 1.0002, 1.0000, 1.0002, 0.9990, 1.0000,\n",
            "        1.0002, 1.0005, 0.9996, 1.0000, 0.9997, 0.9999, 0.9997, 0.9999, 1.0000,\n",
            "        1.0006, 0.9999, 0.9992, 1.0002, 0.9999, 1.0005, 0.9997, 1.0000, 0.9999,\n",
            "        1.0000, 1.0006, 1.0004, 0.9999, 1.0000, 0.9999, 0.9999, 0.9997, 0.9998,\n",
            "        1.0001, 1.0000, 0.9999, 1.0000, 1.0000, 1.0001, 1.0000, 1.0000, 1.0000,\n",
            "        1.0001, 0.9997, 1.0000, 0.9998, 1.0002, 1.0000, 1.0000, 1.0004, 1.0003,\n",
            "        1.0001, 1.0001, 1.0004, 1.0000])), ('lidar_attention_submodel.attention_module.norm1.bias', tensor([ 1.9424e-04,  4.0031e-05, -4.2049e-04,  1.7464e-04, -2.5998e-04,\n",
            "         6.6729e-04, -2.8286e-04,  1.8027e-04, -6.9317e-05, -2.0481e-05,\n",
            "         4.0414e-05,  3.3265e-04,  1.0365e-04,  5.5764e-04,  4.6157e-05,\n",
            "        -3.2308e-04,  5.4664e-05, -3.2781e-04, -7.9697e-05,  3.1467e-04,\n",
            "         3.1724e-04, -4.3180e-04, -1.1887e-04,  7.0882e-04,  4.6640e-04,\n",
            "        -5.9717e-04,  3.0382e-04,  1.5169e-04, -7.7259e-05,  3.7151e-04,\n",
            "        -4.2096e-04,  4.2367e-04,  5.0420e-04,  4.7722e-04,  1.3942e-04,\n",
            "        -5.7839e-04,  2.8437e-04, -8.8083e-04,  2.5902e-04,  3.8815e-06,\n",
            "        -1.0146e-04, -6.2386e-05,  2.5915e-04, -2.6538e-04,  1.7685e-04,\n",
            "        -4.6180e-04,  1.7811e-04, -2.0468e-04,  7.1454e-04,  3.7135e-04,\n",
            "         1.6485e-04, -5.1223e-04, -1.9182e-04, -4.1720e-04,  1.1182e-04,\n",
            "        -3.5189e-04, -1.5495e-04,  6.6383e-04, -6.7595e-04,  2.6027e-04,\n",
            "        -6.8365e-04, -4.0292e-04, -2.2260e-06, -9.1346e-05,  1.1706e-04,\n",
            "         2.7256e-04, -6.9497e-04, -1.2970e-04, -1.6544e-04, -1.5052e-05,\n",
            "         3.8326e-04, -1.1086e-04,  2.4378e-04, -2.8621e-04, -1.2914e-04,\n",
            "        -1.1340e-04,  1.8756e-05,  6.4927e-04, -4.8872e-04,  3.7232e-04,\n",
            "         2.0246e-04,  4.2951e-04,  3.9672e-05, -1.8270e-04,  1.0020e-04,\n",
            "         1.3794e-04,  3.6975e-04,  2.3734e-04, -6.7942e-04, -3.0367e-05,\n",
            "         1.7891e-04, -2.5484e-04, -4.2652e-04, -1.2681e-05,  8.5760e-05,\n",
            "         2.9782e-04, -1.5003e-04, -4.9767e-05, -2.3418e-04, -3.9540e-04,\n",
            "         2.2707e-04,  4.8819e-04,  8.2334e-05, -3.4932e-04, -2.1181e-05,\n",
            "         1.5984e-04,  6.7214e-05, -4.9644e-04,  1.7545e-04, -2.0840e-04,\n",
            "        -2.4953e-04,  5.1769e-04,  2.2227e-04, -6.5136e-05, -4.1189e-04,\n",
            "        -7.8531e-05, -3.8026e-04,  8.3737e-04,  1.1129e-04,  5.6672e-05,\n",
            "         1.8947e-04, -2.0448e-04,  3.7069e-04, -2.5153e-04, -4.7841e-04,\n",
            "        -2.3581e-04, -2.6285e-04, -1.6973e-04,  2.8330e-05,  3.1947e-05,\n",
            "         4.5968e-04,  3.5347e-04,  2.8365e-04, -1.6270e-04, -5.8027e-04,\n",
            "        -7.4465e-04,  2.2951e-04, -4.9278e-04, -8.9412e-04,  6.2379e-05,\n",
            "        -4.0231e-04,  1.5536e-04, -4.3051e-04, -5.9029e-05, -2.8622e-04,\n",
            "         6.5070e-04, -4.8800e-04, -2.5259e-05,  1.2632e-04, -3.0317e-04,\n",
            "         7.2092e-05,  9.3591e-05,  2.4622e-04,  3.7453e-04,  4.3699e-04,\n",
            "        -3.7059e-04,  2.0561e-04, -1.1071e-04,  7.0934e-05,  4.7423e-05,\n",
            "        -2.9041e-04,  3.1802e-04, -2.9724e-04, -2.7505e-04, -4.0043e-05,\n",
            "         7.5914e-04, -2.7760e-04,  6.8288e-04,  2.6448e-04,  2.7629e-04,\n",
            "        -2.9716e-04, -3.7767e-04,  3.4639e-04,  8.9259e-04, -1.0698e-04,\n",
            "         2.4409e-04,  4.4616e-04,  2.3722e-04, -9.0041e-05, -2.6563e-04,\n",
            "        -5.8117e-05,  1.5709e-04, -4.4483e-05, -8.8481e-05, -1.0499e-05,\n",
            "         1.2740e-04,  8.3348e-04,  2.8436e-05, -1.0557e-04, -3.2528e-04,\n",
            "        -5.7639e-04,  4.9680e-04, -6.0494e-05, -1.7457e-04,  4.9865e-04,\n",
            "        -6.0902e-05, -2.0492e-04, -2.1198e-04,  4.1836e-05, -5.4710e-05,\n",
            "         4.9100e-04,  1.5238e-03,  1.3505e-04, -2.1007e-04,  6.1993e-04,\n",
            "        -5.8035e-04,  1.9094e-06, -3.0354e-04,  5.6596e-04,  2.1844e-04,\n",
            "        -2.7683e-05,  3.0030e-04,  6.7676e-04, -8.7425e-04,  1.2799e-04,\n",
            "         2.2865e-05,  7.8794e-04, -6.9132e-05,  7.1816e-04, -3.8911e-04,\n",
            "         1.5605e-04, -5.3834e-04, -3.6213e-04,  3.6159e-05,  2.2132e-04,\n",
            "         3.8892e-06, -6.6748e-04,  9.0277e-04, -4.9866e-06,  3.2434e-04,\n",
            "        -2.5212e-04,  1.9118e-04,  4.8344e-04,  2.4281e-04,  1.3833e-04,\n",
            "         6.2841e-05, -3.3935e-05, -5.1037e-05, -2.4106e-04,  1.6145e-04,\n",
            "        -1.7693e-04, -2.5534e-05, -9.4363e-05,  9.2250e-05,  3.0614e-04,\n",
            "        -3.5440e-07,  1.1283e-04,  5.7079e-04, -1.1886e-04,  6.9068e-05,\n",
            "         6.0458e-04, -1.3724e-04, -1.4615e-04,  3.3723e-04, -4.8818e-04,\n",
            "         1.9137e-05])), ('lidar_attention_submodel.attention_module.norm2.weight', tensor([1.0006, 1.0004, 1.0260, 1.0005, 1.0079, 1.0001, 1.0043, 1.0001, 1.0032,\n",
            "        1.0001, 1.0049, 1.0013, 1.0001, 1.0187, 1.0142, 1.0093, 1.0020, 1.0001,\n",
            "        1.0027, 1.0065, 1.0006, 1.0019, 1.0041, 1.0000, 1.0021, 1.0000, 1.0014,\n",
            "        1.0079, 1.0001, 1.0130, 1.0016, 1.0008, 1.0003, 1.0001, 1.0011, 1.0000,\n",
            "        1.0008, 1.0000, 1.0018, 1.0047, 1.0317, 0.9999, 1.0100, 1.0010, 1.0005,\n",
            "        1.0018, 1.0000, 1.0011, 1.0091, 1.0043, 1.0024, 0.9998, 1.0028, 1.0111,\n",
            "        1.0026, 1.0053, 1.0058, 1.0353, 1.0213, 1.0005, 1.0005, 1.0192, 1.0118,\n",
            "        1.0009, 1.0030, 0.9995, 1.0045, 1.0023, 1.0163, 1.0016, 1.0008, 1.0095,\n",
            "        1.0008, 1.0012, 1.0012, 1.0116, 1.0181, 1.0048, 1.0020, 1.0085, 1.0039,\n",
            "        1.0033, 1.0057, 1.0325, 1.0053, 1.0054, 1.0030, 1.0001, 1.0076, 1.0040,\n",
            "        0.9999, 1.0082, 1.0022, 0.9998, 1.0287, 1.0015, 1.0006, 1.0000, 1.0004,\n",
            "        1.0099, 1.0005, 1.0047, 1.0015, 1.0000, 1.0036, 1.0006, 1.0051, 1.0062,\n",
            "        1.0111, 1.0157, 1.0259, 1.0249, 1.0010, 1.0039, 1.0064, 1.0018, 1.0041,\n",
            "        1.0077, 1.0109, 1.0171, 1.0040, 1.0024, 1.0004, 1.0043, 1.0119, 1.0072,\n",
            "        1.0011, 1.0013, 1.0004, 1.0001, 1.0016, 1.0019, 1.0025, 1.0093, 1.0003,\n",
            "        1.0068, 1.0000, 1.0060, 1.0027, 1.0019, 1.0194, 1.0000, 1.0081, 1.0000,\n",
            "        1.0023, 1.0004, 1.0007, 1.0007, 1.0002, 1.0001, 1.0031, 1.0007, 1.0002,\n",
            "        1.0062, 1.0044, 1.0068, 1.0120, 1.0194, 1.0005, 1.0009, 1.0128, 1.0069,\n",
            "        1.0072, 1.0333, 1.0006, 1.0013, 1.0002, 1.0034, 1.0075, 1.0066, 1.0119,\n",
            "        1.0024, 1.0018, 1.0005, 1.0192, 0.9999, 1.0000, 1.0160, 1.0026, 1.0227,\n",
            "        1.0136, 1.0046, 1.0050, 1.0005, 1.0011, 1.0001, 1.0155, 1.0022, 1.0000,\n",
            "        1.0070, 1.0000, 1.0011, 1.0024, 1.0024, 1.0001, 1.0026, 1.0033, 1.0020,\n",
            "        1.0000, 1.0002, 1.0056, 1.0340, 1.0008, 1.0000, 1.0003, 1.0050, 1.0094,\n",
            "        1.0192, 1.0102, 1.0014, 1.0011, 1.0040, 1.0090, 1.0050, 1.0007, 1.0004,\n",
            "        1.0037, 1.0019, 1.0012, 1.0034, 1.0004, 1.0042, 1.0014, 1.0194, 1.0011,\n",
            "        1.0097, 1.0010, 1.0174, 1.0014, 1.0002, 1.0076, 1.0046, 1.0002, 1.0010,\n",
            "        1.0009, 1.0151, 1.0188, 1.0006, 1.0201, 0.9999, 1.0031, 1.0040, 1.0003,\n",
            "        0.9999, 1.0014, 1.0012, 1.0202, 1.0129, 1.0049, 1.0006, 1.0018, 1.0048,\n",
            "        1.0017, 1.0226, 1.0028, 1.0023])), ('lidar_attention_submodel.attention_module.norm2.bias', tensor([ 1.8414e-03,  1.4137e-03, -1.2023e-02, -1.8929e-03, -7.1412e-03,\n",
            "        -1.0590e-03, -4.6587e-03,  1.1810e-03, -4.7840e-03, -1.4230e-03,\n",
            "        -5.5624e-03,  3.0913e-03,  8.7087e-04,  9.7746e-03, -9.6533e-03,\n",
            "        -7.6031e-03, -3.5094e-03,  1.5376e-03,  4.1658e-03,  5.8587e-03,\n",
            "        -1.7330e-03,  3.6633e-03,  5.1926e-03,  1.6122e-05,  3.5208e-03,\n",
            "         1.0960e-03,  2.8338e-03,  7.0627e-03, -4.1728e-04,  9.3054e-03,\n",
            "        -3.0595e-03,  3.0274e-03, -1.2565e-03, -1.3985e-03, -3.0274e-03,\n",
            "        -1.0105e-03,  2.9340e-03,  8.3012e-05,  3.1524e-03, -5.0045e-03,\n",
            "        -1.3537e-02,  6.4925e-05, -7.5178e-03,  2.6008e-03,  1.6603e-03,\n",
            "         3.3707e-03, -5.2123e-04,  3.4564e-03, -7.1267e-03,  5.2088e-03,\n",
            "        -3.7158e-03,  8.8860e-04,  4.2765e-03,  8.2409e-03, -4.9105e-03,\n",
            "         5.3319e-03, -6.0546e-03, -1.4322e-02,  1.1202e-02,  2.3067e-03,\n",
            "        -1.5551e-03,  1.0519e-02, -8.1827e-03, -1.9213e-03, -3.7654e-03,\n",
            "        -2.3032e-04,  5.3482e-03, -4.0500e-03,  9.8934e-03,  4.0608e-03,\n",
            "        -2.5647e-03,  7.8576e-03,  2.2622e-03, -3.0940e-03,  3.2224e-03,\n",
            "        -8.3262e-03,  1.0561e-02,  5.4011e-03,  3.7833e-03,  7.1985e-03,\n",
            "         4.8116e-03, -5.3847e-03, -5.8712e-03, -1.4181e-02,  5.8322e-03,\n",
            "        -5.3373e-03, -4.3224e-03, -4.8938e-04, -6.5202e-03, -5.1118e-03,\n",
            "         1.0032e-03,  7.0095e-03, -3.7162e-03,  3.0366e-04, -1.2988e-02,\n",
            "         2.8668e-03, -1.7630e-03,  1.3741e-04,  1.3670e-03, -7.5792e-03,\n",
            "        -1.4278e-03,  5.3052e-03,  2.7704e-03,  6.6869e-04, -4.6382e-03,\n",
            "        -2.8761e-03,  6.1430e-03,  5.9219e-03, -7.9613e-03, -9.6036e-03,\n",
            "         1.1954e-02, -1.2008e-02, -1.9985e-03, -4.6470e-03, -5.6803e-03,\n",
            "        -3.0761e-03, -4.6721e-03, -6.5781e-03,  7.9849e-03,  9.5980e-03,\n",
            "        -5.1954e-03, -4.2355e-03, -1.4603e-03,  5.1509e-03,  8.0262e-03,\n",
            "        -6.9463e-03, -3.0290e-03, -2.7236e-03, -1.4096e-03, -1.2545e-03,\n",
            "        -3.0211e-03,  3.6737e-03, -3.9470e-03, -6.8978e-03, -1.0612e-03,\n",
            "        -6.2309e-03, -3.6669e-04, -5.5771e-03,  4.2767e-03, -3.2333e-03,\n",
            "         1.1139e-02, -1.7648e-03, -6.3939e-03,  1.0390e-04, -3.4442e-03,\n",
            "        -1.7650e-03,  2.4419e-03, -2.1137e-03,  1.1957e-03, -8.7279e-04,\n",
            "        -3.9990e-03, -2.3460e-03,  1.4235e-03,  5.8387e-03, -5.7369e-03,\n",
            "         6.4291e-03,  8.1406e-03,  1.0877e-02,  1.7716e-03, -2.2722e-03,\n",
            "        -8.4385e-03,  6.1553e-03,  6.8568e-03,  1.3728e-02,  1.8690e-03,\n",
            "         2.8132e-03,  1.6736e-03,  4.8954e-03, -6.7304e-03,  5.9047e-03,\n",
            "         9.0589e-03, -3.6372e-03, -3.0354e-03, -2.1388e-03,  1.0499e-02,\n",
            "        -1.1243e-03, -5.5240e-04, -9.7064e-03,  4.1375e-03, -1.1130e-02,\n",
            "         9.2980e-03,  5.8454e-03,  5.1512e-03, -1.5267e-03, -2.9677e-03,\n",
            "         1.3112e-03,  9.6890e-03,  3.6374e-03, -2.3647e-04, -6.3251e-03,\n",
            "        -9.0157e-04, -2.6789e-03, -3.8850e-03, -3.5250e-03,  1.0698e-03,\n",
            "         4.6345e-03, -4.3933e-03, -3.4876e-03,  3.8087e-04, -1.1069e-03,\n",
            "         5.3632e-03,  1.4052e-02, -2.1223e-03, -8.2152e-04,  1.0802e-03,\n",
            "         5.7468e-03,  7.5851e-03, -1.0976e-02,  7.5688e-03, -2.6163e-03,\n",
            "         2.7641e-03,  5.6090e-03, -8.3571e-03, -5.5976e-03, -2.2283e-03,\n",
            "        -1.6426e-03,  4.6511e-03, -3.3151e-03, -2.4826e-03,  4.8040e-03,\n",
            "         1.6357e-03,  5.5549e-03, -2.7957e-03,  1.1195e-02, -2.6088e-03,\n",
            "        -7.3278e-03,  2.5064e-03,  9.9043e-03,  2.6410e-03,  9.3737e-04,\n",
            "         7.0420e-03, -4.8652e-03, -4.8646e-05, -3.0624e-03,  1.6832e-03,\n",
            "        -9.1478e-03, -1.0248e-02,  2.6837e-03,  1.0613e-02,  4.9434e-04,\n",
            "         4.3842e-03, -4.8075e-03, -1.2175e-03,  4.5315e-04, -3.0012e-03,\n",
            "         2.7620e-03, -1.0407e-02,  8.8739e-03,  5.5512e-03, -1.9055e-03,\n",
            "         3.1421e-03, -4.9701e-03,  3.4728e-03,  1.2256e-02, -4.2063e-03,\n",
            "         3.5750e-03])), ('lidar_attention_submodel.attention_module.multihead_attn.in_proj_weight', tensor([[ 0.0541,  0.0570, -0.0390,  ..., -0.0254, -0.0371,  0.0579],\n",
            "        [ 0.0719, -0.0753,  0.0272,  ..., -0.0374, -0.0758,  0.0298],\n",
            "        [-0.0423,  0.0758, -0.0595,  ...,  0.0758,  0.0070, -0.0654],\n",
            "        ...,\n",
            "        [-0.0593, -0.0689,  0.0367,  ...,  0.0465,  0.0658,  0.0472],\n",
            "        [-0.0726,  0.0249,  0.0600,  ...,  0.0266, -0.0459, -0.0667],\n",
            "        [-0.0331,  0.0499, -0.0178,  ..., -0.0351,  0.0288, -0.0655]])), ('lidar_attention_submodel.attention_module.multihead_attn.in_proj_bias', tensor([-2.8680e-06,  3.3536e-07, -3.0973e-06,  4.1332e-06, -2.2146e-06,\n",
            "        -8.0288e-06, -9.6783e-07, -1.1908e-06,  1.3010e-06,  1.0167e-05,\n",
            "        -8.7793e-06,  3.6252e-06, -9.8708e-06,  2.7296e-06, -1.1046e-05,\n",
            "         5.0821e-07,  8.5530e-06, -1.1861e-05,  1.9484e-06,  2.7725e-07,\n",
            "         4.2837e-06,  7.0399e-06, -5.6260e-06,  3.8552e-06,  7.5096e-06,\n",
            "        -3.1080e-06, -3.5891e-06, -7.5015e-06, -8.0271e-06, -5.1814e-06,\n",
            "         1.1422e-06,  1.2562e-06,  1.3493e-05, -8.6223e-06, -1.1916e-05,\n",
            "         5.6200e-07, -4.9438e-07, -8.5408e-07, -1.1044e-05, -7.6303e-06,\n",
            "        -3.9176e-06, -4.2943e-06,  6.7473e-07, -4.7758e-06,  5.3594e-06,\n",
            "        -1.6538e-05,  3.0733e-06, -7.1425e-06,  7.1450e-06,  1.6683e-06,\n",
            "         3.9358e-06, -5.2413e-06, -5.5180e-06,  4.4050e-06,  8.7030e-07,\n",
            "         8.5099e-06,  2.0386e-06,  1.2954e-05, -1.5199e-05,  2.1284e-06,\n",
            "         1.8743e-06, -1.2104e-05, -1.4769e-06,  1.3313e-05,  1.0311e-06,\n",
            "        -1.1080e-06, -2.8855e-06,  9.2317e-07, -9.6007e-07, -1.0673e-06,\n",
            "         4.0841e-06,  9.1679e-07, -5.0540e-08,  3.0788e-06,  1.7173e-06,\n",
            "        -2.3447e-06,  9.8346e-07,  1.0241e-06, -2.6301e-06,  4.2711e-06,\n",
            "        -1.6166e-06, -9.1337e-07,  1.6633e-06,  2.5319e-06, -3.2994e-07,\n",
            "         3.5695e-07, -2.7893e-06,  3.5393e-06, -8.1817e-07, -5.7674e-06,\n",
            "         2.7931e-06, -2.9830e-06, -9.6506e-07, -1.0958e-07,  2.0045e-07,\n",
            "         6.0356e-06,  1.9423e-06,  2.5323e-07,  1.2214e-06,  1.0841e-05,\n",
            "         3.2248e-06, -3.1110e-06,  4.0360e-06, -5.0603e-07,  1.0154e-05,\n",
            "         5.2446e-06, -2.5033e-06,  5.7170e-06, -7.4610e-08, -7.2511e-06,\n",
            "        -3.5443e-06, -2.7834e-06,  2.0500e-06,  2.8290e-06, -2.1369e-06,\n",
            "        -3.4212e-06, -8.7962e-06,  8.6760e-06,  6.7457e-06, -7.0476e-06,\n",
            "        -1.1608e-06, -2.2669e-06,  8.6512e-06, -4.1829e-06, -8.1869e-06,\n",
            "        -6.5492e-06,  6.8401e-06, -3.8195e-06, -5.4819e-06,  5.6472e-06,\n",
            "        -6.0065e-06,  7.4476e-06,  8.3846e-06,  9.1157e-06, -2.5192e-06,\n",
            "         1.5554e-06, -3.8796e-06, -3.3713e-06, -1.3098e-06, -3.8099e-06,\n",
            "         4.7627e-06, -3.5568e-06,  5.9262e-06,  3.6021e-06,  6.7732e-06,\n",
            "         4.4346e-07,  2.8477e-06,  1.1882e-06,  3.5238e-06, -3.9638e-06,\n",
            "        -6.7016e-06, -4.4355e-06,  6.7117e-06,  1.1887e-06, -2.3007e-06,\n",
            "        -4.7227e-06,  2.6580e-07, -4.8350e-06,  5.6065e-06,  3.7307e-07,\n",
            "         1.1117e-06, -3.3891e-06, -2.2145e-06, -3.0608e-07, -1.8726e-07,\n",
            "        -1.0670e-05,  2.9619e-06,  4.5672e-06, -3.5634e-06,  4.1046e-06,\n",
            "         2.1115e-06, -4.1074e-06, -4.5057e-07, -7.0554e-06,  5.3732e-06,\n",
            "         4.6120e-06, -7.2462e-06,  4.5031e-06, -4.8156e-06,  1.0498e-07,\n",
            "        -3.3945e-06, -4.0181e-07, -1.2914e-06, -4.8288e-07,  3.3577e-06,\n",
            "         5.9957e-06, -7.3320e-06,  1.8830e-06,  4.1783e-06,  2.0612e-06,\n",
            "         4.0544e-06, -2.6179e-06, -2.1246e-05,  5.6574e-06,  1.4070e-06,\n",
            "         5.8413e-06,  9.6727e-06, -1.4434e-05,  1.0671e-06, -6.1281e-08,\n",
            "         7.6002e-06,  5.8341e-06,  5.4355e-06,  1.6380e-05, -1.6625e-06,\n",
            "         6.1159e-06, -8.1498e-06,  9.9975e-06, -6.2563e-07, -1.2196e-05,\n",
            "         8.2126e-06, -1.2466e-05, -8.8002e-06,  5.5790e-06, -4.5088e-06,\n",
            "        -1.5559e-05,  6.0347e-06,  3.6393e-06, -1.6624e-06,  1.4900e-05,\n",
            "        -6.8657e-06, -1.0880e-06,  4.4332e-06, -2.4588e-05, -4.5657e-07,\n",
            "        -2.1563e-08, -2.1648e-07,  1.7762e-07, -1.7988e-07,  3.3526e-07,\n",
            "         1.5721e-07, -1.3064e-07, -2.3111e-07,  3.9300e-09, -5.8707e-07,\n",
            "        -4.1359e-08,  2.2680e-07,  1.6993e-07,  1.1798e-07, -2.4149e-07,\n",
            "         6.3443e-08,  3.8910e-07,  4.7660e-07, -4.0102e-08, -4.1287e-07,\n",
            "        -5.5225e-07, -4.9648e-07,  7.7461e-08,  3.1291e-07, -2.2971e-07,\n",
            "         5.4379e-07, -5.4246e-07, -3.5800e-07,  2.6162e-07,  1.0491e-07,\n",
            "         1.8818e-07, -8.3545e-15, -1.6729e-14,  1.1010e-14, -9.5643e-14,\n",
            "         5.3652e-15, -2.7684e-14, -8.4500e-15,  2.9077e-14, -1.8452e-15,\n",
            "         1.0566e-14,  4.6382e-14,  5.4218e-14, -1.7818e-14,  1.7250e-14,\n",
            "        -1.2579e-14, -4.2537e-14, -3.6588e-14,  1.3103e-15,  2.8063e-14,\n",
            "        -1.1203e-15,  1.6817e-14,  7.8590e-14,  2.1459e-14,  1.9841e-15,\n",
            "         1.0889e-14, -4.1635e-15,  3.1339e-14,  1.8047e-15, -2.0258e-14,\n",
            "        -2.8669e-14, -6.6331e-15,  2.4809e-14,  9.1167e-15, -4.2750e-14,\n",
            "         5.4272e-15,  1.4817e-13, -6.3284e-14, -9.9112e-15, -2.0743e-13,\n",
            "        -1.7348e-13,  2.2171e-14,  8.3546e-14,  4.7616e-15,  3.0528e-14,\n",
            "        -1.3359e-13,  4.7620e-14,  9.6720e-14, -9.3842e-14,  7.7301e-14,\n",
            "        -3.5485e-14, -3.2592e-13, -7.3867e-14, -2.1170e-14,  2.3843e-13,\n",
            "         4.0715e-14, -1.0154e-13,  9.1490e-15,  8.8312e-16,  1.5165e-14,\n",
            "        -1.0367e-13, -1.4030e-13, -3.1018e-13, -7.7883e-14,  1.0167e-13,\n",
            "         1.0291e-13, -4.5864e-14, -7.6501e-14,  2.5846e-14, -1.6334e-13,\n",
            "        -8.3412e-14,  1.0788e-14,  3.3939e-15,  1.6527e-14,  5.7783e-15,\n",
            "         2.0099e-14,  8.7094e-15,  9.1000e-14, -6.3250e-14,  2.3414e-14,\n",
            "        -4.8484e-14,  2.5837e-14, -6.6512e-15,  5.5634e-14, -3.2995e-14,\n",
            "         7.9384e-14, -5.1101e-14, -1.8436e-14,  3.0833e-15, -1.3020e-14,\n",
            "        -2.7907e-14,  1.7000e-14, -3.3715e-14,  2.8585e-14, -6.5352e-14,\n",
            "         3.6032e-14, -1.4167e-14, -7.9664e-14, -4.6383e-15, -7.4485e-14,\n",
            "         1.4906e-14,  5.1427e-14, -2.1384e-14,  7.0700e-15, -1.3530e-13,\n",
            "        -7.7042e-14, -5.7005e-14, -6.4685e-14, -1.4009e-13, -3.5779e-14,\n",
            "        -8.8521e-14, -5.5850e-14, -1.0089e-14, -1.1355e-14, -3.8613e-14,\n",
            "        -5.1866e-14,  2.6865e-14, -2.2430e-14, -5.2243e-14, -3.3831e-14,\n",
            "        -4.5595e-15, -6.3334e-14, -1.4804e-13, -1.9169e-14,  1.4887e-14,\n",
            "        -2.8586e-14, -5.4515e-14, -2.8118e-14,  8.7857e-14, -2.6124e-13,\n",
            "        -3.6202e-13, -1.9348e-13, -7.0650e-14,  2.2757e-13,  5.3821e-14,\n",
            "         4.7447e-14, -1.2438e-13, -1.2424e-13, -6.5170e-14,  7.3779e-14,\n",
            "         7.9874e-14,  1.1506e-14,  5.7962e-14,  7.3793e-14, -2.6033e-13,\n",
            "        -2.9384e-14, -1.3368e-13,  9.5645e-14,  1.5274e-14, -7.2918e-14,\n",
            "        -2.6613e-13,  1.3010e-13, -3.6070e-14,  8.2662e-14, -6.9113e-14,\n",
            "        -1.6722e-13, -6.2907e-14,  5.9271e-14, -7.2846e-15, -2.2756e-13,\n",
            "         5.0491e-14, -4.1897e-14, -1.0016e-13, -4.6587e-14,  2.0477e-13,\n",
            "        -3.2240e-15, -2.5044e-15,  4.6389e-14, -3.8637e-15, -4.0275e-15,\n",
            "        -3.7411e-14,  1.1426e-14, -2.9032e-14, -3.8811e-14,  1.6088e-15,\n",
            "         1.0801e-13, -5.1114e-14, -1.5688e-15,  3.4832e-14,  2.4828e-14,\n",
            "         5.7510e-14,  8.0673e-14,  1.0823e-14, -3.3741e-15, -1.3417e-14,\n",
            "        -3.7938e-14,  7.1538e-14, -8.6296e-14, -5.9259e-14,  5.7003e-14,\n",
            "         2.0963e-14,  4.2689e-14, -4.3487e-14, -2.8284e-13, -1.2715e-13,\n",
            "        -7.9502e-14, -1.7494e-13, -2.3364e-14,  1.8109e-13, -1.2258e-13,\n",
            "        -1.1623e-13, -3.0316e-13, -1.7859e-14, -4.0670e-14, -1.1837e-13,\n",
            "        -1.8888e-14, -9.0242e-14, -7.2392e-14,  5.7275e-14,  2.1256e-14,\n",
            "        -8.9241e-14, -2.7752e-13, -1.4399e-13, -2.4073e-13,  1.9508e-13,\n",
            "        -2.7616e-14, -7.6810e-14, -3.0837e-13, -3.4720e-14, -3.3033e-13,\n",
            "         1.3636e-13, -5.6299e-14, -1.6594e-13, -8.8022e-14,  1.5448e-13,\n",
            "         3.9114e-13, -1.3370e-14,  1.0862e-13, -5.5812e-14,  4.3196e-14,\n",
            "         2.4396e-14,  2.2555e-14, -1.1243e-13, -9.1934e-14, -2.7390e-13,\n",
            "         7.5029e-14, -1.2387e-13,  3.4348e-13, -9.4868e-14,  6.1726e-15,\n",
            "        -2.2983e-13,  1.7541e-13,  4.0525e-14, -3.3495e-14, -4.3839e-14,\n",
            "        -9.8548e-14,  2.2207e-13, -1.4971e-13,  3.0490e-14,  6.1338e-14,\n",
            "        -1.5135e-13, -1.3306e-13, -4.9904e-14,  1.0607e-13,  2.2804e-13,\n",
            "         2.0496e-13,  1.7668e-13,  2.8194e-04, -1.5941e-04,  8.2358e-04,\n",
            "         6.8222e-05, -6.1117e-04,  7.2149e-04,  1.0946e-04,  1.5754e-04,\n",
            "        -7.0260e-04, -1.3282e-04, -2.8324e-04,  1.7856e-04,  2.8444e-04,\n",
            "        -4.4201e-05,  7.6163e-05, -5.9427e-04,  4.5412e-04, -6.6774e-04,\n",
            "        -7.6263e-04, -2.3785e-05, -2.2165e-04, -8.8576e-04,  4.0502e-04,\n",
            "         1.9885e-04, -2.8506e-04, -2.2441e-05,  2.3048e-04, -7.7035e-04,\n",
            "        -1.5455e-05, -1.4947e-03,  3.0460e-04, -3.0142e-04, -5.6684e-04,\n",
            "        -1.4029e-03, -1.0756e-03,  5.1638e-04, -1.9169e-04, -5.0018e-04,\n",
            "        -1.0855e-03, -4.7343e-05, -8.3670e-04, -3.7061e-04,  9.9053e-08,\n",
            "        -8.2484e-04, -7.3520e-04, -7.3316e-04, -5.8617e-04, -3.6911e-04,\n",
            "         1.0005e-03,  1.4392e-03, -6.0089e-04, -1.0571e-03, -8.3569e-05,\n",
            "        -6.7347e-04, -5.5011e-04,  1.0252e-03, -4.2516e-04, -9.3531e-05,\n",
            "        -1.3249e-03,  1.6752e-04, -7.9835e-04,  2.3377e-04,  2.5164e-04,\n",
            "         1.2534e-03,  3.9019e-04, -1.6763e-04,  1.5899e-04, -2.6469e-04,\n",
            "        -7.2835e-04,  1.7738e-04,  7.7761e-05,  6.9678e-04,  2.7040e-04,\n",
            "        -9.9569e-04, -7.6894e-05,  6.2750e-04,  1.1556e-04,  7.4043e-04,\n",
            "         1.5728e-03,  1.9902e-04, -6.2392e-04,  6.6269e-04, -3.9633e-04,\n",
            "        -7.7890e-05, -3.6970e-04, -5.3378e-04,  6.6587e-04, -2.9096e-04,\n",
            "         3.3582e-05, -4.8730e-04,  1.7765e-05,  2.2359e-04, -7.2957e-05,\n",
            "        -4.0285e-04, -7.6163e-04, -3.2661e-05,  7.0641e-04,  1.7739e-04,\n",
            "        -4.3337e-04,  7.8397e-05, -3.9325e-04,  1.3790e-03, -9.7398e-04,\n",
            "         4.0673e-04, -2.3607e-04, -4.4071e-04, -2.6783e-04, -1.5136e-04,\n",
            "        -2.3726e-04, -6.9591e-04, -7.3165e-04, -2.6621e-05,  4.9862e-04,\n",
            "         5.0565e-04, -1.0958e-03,  1.2123e-04,  5.5393e-04,  3.1022e-04,\n",
            "         1.3590e-04,  7.8774e-04, -1.8167e-04, -2.2423e-04,  4.5985e-04,\n",
            "        -3.7057e-04,  2.4199e-04,  2.5975e-04,  2.3579e-04, -8.6460e-04,\n",
            "        -3.7281e-04, -7.4205e-04, -1.3434e-03,  5.0595e-04, -3.6571e-04,\n",
            "        -1.1644e-04, -2.1504e-04,  1.9722e-06, -8.0557e-04,  2.7911e-04,\n",
            "        -6.5240e-04,  9.5329e-06,  2.6208e-04,  2.6082e-04, -5.3778e-04,\n",
            "         3.9727e-04, -1.6815e-04, -4.1113e-04,  1.1906e-03, -9.0807e-06,\n",
            "         3.8501e-04, -3.6821e-04, -4.3307e-04, -6.8279e-04,  6.0712e-04,\n",
            "         9.0456e-04,  1.3585e-03,  9.7982e-05, -3.8697e-04,  7.7061e-04,\n",
            "        -1.0366e-03,  1.2684e-04, -3.3704e-04,  2.4018e-04, -2.9114e-04,\n",
            "         1.9883e-04, -4.6387e-04, -6.1559e-04, -4.3875e-04, -2.2237e-04,\n",
            "        -1.7346e-04,  1.0958e-03,  2.3291e-05, -2.1923e-04, -4.4912e-05,\n",
            "        -3.9323e-04, -6.1583e-04,  2.6852e-04,  9.9260e-04, -2.1491e-04,\n",
            "        -7.2009e-04, -2.9547e-04, -2.0813e-04,  6.3644e-04,  3.8198e-04,\n",
            "        -4.5571e-04, -8.4806e-04, -1.2974e-06, -3.2157e-04,  1.0047e-04,\n",
            "        -8.1416e-04,  8.9268e-04,  9.1184e-04, -1.0141e-05, -3.5258e-04,\n",
            "         9.3652e-04,  3.7070e-04, -4.0236e-04,  9.5452e-04, -1.8348e-04,\n",
            "        -6.4846e-05,  5.8285e-04,  1.6636e-04,  6.6812e-04, -1.3018e-03,\n",
            "         1.2194e-04, -1.0137e-03,  3.6329e-04, -1.5279e-03,  1.4314e-03,\n",
            "         1.1875e-03, -3.1826e-04,  5.9850e-04, -8.7969e-04,  4.8498e-04,\n",
            "         6.5516e-04,  4.4071e-07,  3.8521e-04, -7.5136e-04, -4.7204e-04,\n",
            "         4.8097e-04,  7.6410e-04, -5.9657e-04, -2.7044e-04, -2.5684e-04,\n",
            "         2.7749e-04,  1.2363e-04, -7.3669e-04, -8.2162e-04, -1.1392e-03,\n",
            "        -2.8639e-04,  5.2653e-04,  7.7902e-04,  5.3965e-04, -6.7289e-04,\n",
            "        -6.1269e-04, -1.8874e-05, -1.2219e-04, -2.8210e-04,  1.3818e-03,\n",
            "         4.4092e-04,  1.0154e-03, -1.9629e-04,  1.8199e-04, -6.8411e-04,\n",
            "        -2.3635e-04, -4.9999e-04,  4.7328e-04,  3.8337e-04,  1.0963e-04,\n",
            "         4.3798e-04, -3.1060e-04,  5.3037e-04,  9.1417e-05,  7.7848e-04,\n",
            "        -8.2170e-04, -3.1429e-04, -9.1484e-05])), ('lidar_attention_submodel.attention_module.multihead_attn.out_proj.weight', tensor([[-0.0582,  0.0578,  0.0414,  ..., -0.0194,  0.0612,  0.0520],\n",
            "        [-0.0382, -0.0006, -0.0566,  ..., -0.0562,  0.0163,  0.0384],\n",
            "        [-0.0041,  0.0125,  0.0433,  ...,  0.0476, -0.0335, -0.0299],\n",
            "        ...,\n",
            "        [ 0.0080, -0.0245, -0.0639,  ...,  0.0056, -0.0275,  0.0317],\n",
            "        [-0.0053,  0.0236,  0.0068,  ...,  0.0045,  0.0020,  0.0085],\n",
            "        [ 0.0617,  0.0437, -0.0249,  ...,  0.0477,  0.0082,  0.0144]])), ('lidar_attention_submodel.attention_module.multihead_attn.out_proj.bias', tensor([ 3.9425e-04, -1.9572e-05, -5.4035e-04, -1.1680e-03, -2.1706e-03,\n",
            "         7.6990e-05,  1.0018e-03,  6.6523e-04, -2.2581e-03, -1.1507e-03,\n",
            "        -1.1858e-03,  1.0264e-03, -9.2600e-04, -1.6293e-03, -3.6433e-03,\n",
            "        -1.4978e-03, -1.0163e-03,  1.1279e-03,  6.3567e-04, -1.5920e-03,\n",
            "         1.0278e-03,  9.1810e-04,  8.6310e-04,  2.9338e-04, -3.2015e-04,\n",
            "         8.6262e-04,  3.0537e-04,  1.0520e-03, -3.9095e-04,  2.8178e-03,\n",
            "         6.8012e-05,  1.5721e-03, -1.9778e-04, -1.4000e-03, -1.3704e-03,\n",
            "         7.7322e-04,  2.3690e-03,  5.8127e-04, -2.8303e-03,  5.6155e-04,\n",
            "        -2.1144e-03,  1.4785e-03, -5.4287e-04,  3.7948e-04,  4.8522e-05,\n",
            "        -5.1204e-04,  2.1524e-04,  1.8909e-03, -3.5810e-04,  9.6624e-04,\n",
            "        -4.0643e-04,  6.6518e-04,  7.0523e-04,  1.9084e-03, -3.4050e-03,\n",
            "        -1.0679e-03, -1.7525e-03, -2.4074e-03,  1.4898e-03,  1.1585e-03,\n",
            "         7.3045e-04,  1.0552e-03, -8.2503e-04,  9.7182e-04,  1.4904e-03,\n",
            "        -2.9578e-03,  1.1187e-03, -1.9281e-03,  1.6410e-03,  3.0269e-03,\n",
            "        -1.4979e-03,  2.1927e-03, -1.7551e-03, -1.7254e-03,  1.7556e-03,\n",
            "        -1.6082e-03,  1.9102e-03,  4.4445e-04,  1.7130e-03,  1.3132e-03,\n",
            "         2.7681e-04, -2.9343e-03, -9.2944e-04, -3.5313e-03,  1.2693e-03,\n",
            "         6.4243e-04, -6.2320e-04, -2.1635e-04, -2.7088e-04, -1.5846e-03,\n",
            "         2.1976e-03,  1.1472e-03, -1.2028e-03, -1.8319e-03, -2.2401e-03,\n",
            "         2.8378e-04,  7.3038e-04,  1.1896e-03, -4.2345e-04, -7.7749e-04,\n",
            "        -1.7598e-03,  5.0419e-04, -1.9819e-03, -3.1635e-04, -5.2295e-04,\n",
            "        -3.0853e-03,  2.5722e-03, -3.6850e-04, -9.6825e-04, -1.7311e-03,\n",
            "         1.7438e-04, -1.6229e-03,  6.7095e-04, -2.2323e-04,  8.9190e-04,\n",
            "         1.0164e-03,  6.1209e-04, -1.9080e-04,  8.1111e-04, -3.5383e-04,\n",
            "        -1.8724e-03, -2.4418e-03,  1.2788e-03,  5.5873e-04, -4.0118e-04,\n",
            "        -2.2228e-03, -1.8900e-03,  7.0015e-05,  4.3267e-04, -2.0667e-03,\n",
            "        -1.4185e-04,  1.1736e-03, -6.3622e-04,  2.5935e-04,  2.6151e-03,\n",
            "        -7.3978e-04,  3.1872e-04,  9.8545e-04,  1.1553e-03,  4.3340e-04,\n",
            "         3.1712e-03, -3.0118e-03,  1.4002e-03,  2.1057e-03,  8.5107e-04,\n",
            "        -1.0124e-03,  1.1193e-03,  2.7208e-04, -2.5714e-03,  3.7789e-04,\n",
            "         1.3402e-03, -1.5476e-03, -1.0665e-03, -4.0287e-04, -2.4488e-03,\n",
            "         8.8505e-04,  1.6519e-05,  2.1719e-03, -1.6916e-03,  6.9574e-04,\n",
            "        -5.6058e-04, -9.9746e-05,  2.1053e-03,  9.9749e-04,  1.2563e-04,\n",
            "        -7.1601e-04,  1.0336e-03,  1.2340e-03, -1.5545e-03, -5.0662e-04,\n",
            "         3.1828e-03, -8.3982e-05,  1.3354e-03, -1.4892e-03,  8.0035e-04,\n",
            "        -2.4697e-03,  1.2640e-03, -1.9471e-03,  8.2729e-04, -3.7221e-04,\n",
            "         2.5903e-03,  2.6528e-03, -4.2201e-04, -8.1664e-05, -1.9427e-03,\n",
            "        -1.9656e-03,  1.8806e-03,  1.5482e-04,  8.5344e-04, -7.3977e-04,\n",
            "        -4.4657e-04, -1.5481e-03, -8.0158e-04,  7.5119e-04, -4.9249e-04,\n",
            "         2.0313e-03, -3.2893e-04, -4.3592e-04,  6.9737e-04, -8.1113e-04,\n",
            "        -8.4822e-04,  1.7904e-03,  4.9311e-04, -8.0354e-04, -1.3781e-03,\n",
            "         1.6275e-03,  1.5641e-03, -3.2583e-03,  3.0586e-04,  1.3161e-04,\n",
            "         4.5631e-04,  2.2454e-03, -4.9978e-03, -1.4596e-03, -1.1461e-03,\n",
            "        -2.3117e-04,  1.1696e-04, -3.7486e-05,  1.6921e-03,  1.3301e-03,\n",
            "         2.3973e-06,  2.2191e-03,  2.3382e-05,  3.4735e-03, -3.1416e-04,\n",
            "        -3.2816e-04,  5.6183e-05,  4.6238e-04, -2.1716e-03, -1.5791e-03,\n",
            "         1.8982e-03,  1.2709e-03,  2.8127e-03, -1.7585e-03, -2.9237e-03,\n",
            "        -4.1938e-04, -7.0416e-04,  1.9489e-03,  2.6518e-04,  1.3723e-03,\n",
            "         6.1989e-04, -1.2302e-04,  4.2188e-04,  1.4610e-03, -2.7369e-04,\n",
            "         5.3812e-04,  2.0556e-04,  1.5816e-03,  1.0715e-03,  9.8917e-04,\n",
            "        -5.0426e-04,  1.0514e-03,  1.2807e-03,  3.9169e-03, -8.3523e-04,\n",
            "        -1.2161e-03])), ('lidar_attention_submodel.attention_module.linear1.weight', tensor([[ 1.5839e-02, -4.7834e-02, -5.9409e-02,  ...,  5.3486e-02,\n",
            "         -3.0669e-02, -4.8096e-02],\n",
            "        [ 1.6219e-02,  9.2233e-04,  4.3645e-02,  ...,  5.1985e-02,\n",
            "         -4.4963e-03,  6.0939e-02],\n",
            "        [-3.3917e-02,  3.7231e-03, -2.8351e-02,  ...,  2.3404e-02,\n",
            "          5.2919e-03, -2.1354e-02],\n",
            "        ...,\n",
            "        [ 2.0936e-02, -2.1795e-02,  6.2078e-02,  ...,  4.5013e-02,\n",
            "          3.2059e-02, -5.7381e-03],\n",
            "        [-1.5312e-02, -3.5574e-03, -3.7645e-02,  ...,  2.5868e-02,\n",
            "         -4.7368e-02, -1.1913e-04],\n",
            "        [ 4.6379e-02,  4.3121e-02,  2.8931e-02,  ..., -3.4144e-02,\n",
            "         -3.9836e-02, -8.8750e-05]])), ('lidar_attention_submodel.attention_module.linear1.bias', tensor([ 0.0203,  0.0412,  0.0438,  0.0408,  0.0092, -0.0343, -0.0461,  0.0034,\n",
            "        -0.0402,  0.0040,  0.0377,  0.0387, -0.0629,  0.0618,  0.0385, -0.0595,\n",
            "        -0.0481, -0.0293,  0.0065,  0.0208, -0.0319,  0.0123,  0.0328,  0.0384,\n",
            "        -0.0181, -0.0276,  0.0537, -0.0263,  0.0229, -0.0031, -0.0310, -0.0245,\n",
            "         0.0488,  0.0139,  0.0169,  0.0048,  0.0434,  0.0665,  0.0372,  0.0151,\n",
            "        -0.0125, -0.0072, -0.0085,  0.0588, -0.0540, -0.0173,  0.0489,  0.0233,\n",
            "         0.0019, -0.0381, -0.0155, -0.0477,  0.0583,  0.0437,  0.0130,  0.0546,\n",
            "        -0.0416, -0.0088, -0.0349,  0.0368, -0.0361, -0.0142,  0.0429, -0.0119,\n",
            "         0.0054, -0.0070, -0.0079,  0.0342, -0.0600,  0.0240,  0.0338, -0.0512,\n",
            "        -0.0015, -0.0381, -0.0597,  0.0352,  0.0276,  0.0553, -0.0149,  0.0227,\n",
            "        -0.0115,  0.0616,  0.0454, -0.0141, -0.0046,  0.0077, -0.0019,  0.0503,\n",
            "         0.0196, -0.0129,  0.0627, -0.0056,  0.0175, -0.0116,  0.0108,  0.0229,\n",
            "         0.0375, -0.0182,  0.0096, -0.0198,  0.0476,  0.0088,  0.0291, -0.0042,\n",
            "         0.0570,  0.0216,  0.0396,  0.0092,  0.0553,  0.0354, -0.0168,  0.0443,\n",
            "        -0.0038,  0.0447, -0.0110, -0.0381, -0.0203, -0.0093, -0.0133, -0.0561,\n",
            "        -0.0095,  0.0464, -0.0390,  0.0181, -0.0555, -0.0324,  0.0518, -0.0253,\n",
            "        -0.0056,  0.0158,  0.0114,  0.0351, -0.0321, -0.0010, -0.0246, -0.0325,\n",
            "         0.0300, -0.0476,  0.0038, -0.0528, -0.0534,  0.0409, -0.0371,  0.0372,\n",
            "         0.0510, -0.0575,  0.0419, -0.0156, -0.0511,  0.0578, -0.0481, -0.0615,\n",
            "         0.0641,  0.0465, -0.0026, -0.0305,  0.0318,  0.0183,  0.0604, -0.0527,\n",
            "        -0.0405, -0.0514, -0.0023, -0.0351,  0.0108,  0.0135, -0.0345,  0.0274,\n",
            "        -0.0122,  0.0385,  0.0233,  0.0205, -0.0520, -0.0573, -0.0074, -0.0339,\n",
            "         0.0514, -0.0205, -0.0089, -0.0284, -0.0254,  0.0319, -0.0192,  0.0004,\n",
            "        -0.0110,  0.0507, -0.0208, -0.0569, -0.0048,  0.0404,  0.0199, -0.0463,\n",
            "        -0.0316, -0.0376,  0.0577,  0.0430,  0.0108, -0.0056,  0.0193, -0.0199,\n",
            "        -0.0278,  0.0044,  0.0566, -0.0559, -0.0542, -0.0493,  0.0409, -0.0488,\n",
            "        -0.0037,  0.0631,  0.0236, -0.0030, -0.0193,  0.0416, -0.0355,  0.0414,\n",
            "         0.0662, -0.0081,  0.0308,  0.0471,  0.0443, -0.0349, -0.0186,  0.0085,\n",
            "        -0.0434,  0.0372,  0.0016, -0.0209,  0.0654,  0.0013,  0.0063,  0.0007,\n",
            "         0.0354,  0.0178,  0.0471,  0.0482, -0.0079, -0.0050, -0.0349,  0.0375,\n",
            "        -0.0160, -0.0228, -0.0399, -0.0394,  0.0636,  0.0110,  0.0252,  0.0594,\n",
            "         0.0495, -0.0103, -0.0445, -0.0481, -0.0336,  0.0478, -0.0466, -0.0265])), ('lidar_attention_submodel.attention_module.linear2.weight', tensor([[ 0.0114, -0.0522, -0.0460,  ...,  0.0190, -0.0526, -0.0369],\n",
            "        [-0.0207, -0.0020,  0.0104,  ...,  0.0140, -0.0329,  0.0544],\n",
            "        [ 0.0021,  0.0273, -0.0032,  ...,  0.0241,  0.0588,  0.0436],\n",
            "        ...,\n",
            "        [ 0.0446,  0.0332,  0.0052,  ...,  0.0040, -0.0118,  0.0216],\n",
            "        [-0.0305, -0.0388,  0.0089,  ..., -0.0083,  0.0538,  0.0350],\n",
            "        [ 0.0288, -0.0490,  0.0510,  ...,  0.0349, -0.0127, -0.0442]])), ('lidar_attention_submodel.attention_module.linear2.bias', tensor([ 0.0591, -0.0540, -0.0600, -0.0500,  0.0358,  0.0465, -0.0107,  0.0250,\n",
            "         0.0166,  0.0492, -0.0011, -0.0133,  0.0296,  0.0484,  0.0465,  0.0637,\n",
            "        -0.0112,  0.0232, -0.0603,  0.0122, -0.0537, -0.0133, -0.0262, -0.0379,\n",
            "         0.0072,  0.0049, -0.0240,  0.0490,  0.0400, -0.0008,  0.0603, -0.0007,\n",
            "         0.0489,  0.0215,  0.0675,  0.0667,  0.0314, -0.0384,  0.0261, -0.0261,\n",
            "         0.0160,  0.0722, -0.0023,  0.0407,  0.0505,  0.0443, -0.0040,  0.0492,\n",
            "        -0.0042,  0.0427, -0.0254, -0.0609,  0.0396,  0.0579,  0.0371,  0.0494,\n",
            "         0.0433,  0.0495, -0.0004,  0.0139,  0.0040, -0.0188, -0.0584, -0.0039,\n",
            "        -0.0497, -0.0024,  0.0289,  0.0479,  0.0493, -0.0438, -0.0554,  0.0602,\n",
            "         0.0175,  0.0136, -0.0116, -0.0444, -0.0013, -0.0341, -0.0265, -0.0422,\n",
            "         0.0044,  0.0465, -0.0169,  0.0579, -0.0543, -0.0541, -0.0123,  0.0554,\n",
            "        -0.0216, -0.0531,  0.0020, -0.0494, -0.0242,  0.0372, -0.0498,  0.0511,\n",
            "         0.0459, -0.0291,  0.0188,  0.0378,  0.0591, -0.0579,  0.0295, -0.0619,\n",
            "         0.0094,  0.0494, -0.0425,  0.0020,  0.0187, -0.0642,  0.0629, -0.0438,\n",
            "         0.0077, -0.0119,  0.0412,  0.0250,  0.0563, -0.0068,  0.0569, -0.0649,\n",
            "        -0.0581, -0.0238, -0.0060, -0.0246, -0.0186,  0.0147,  0.0043,  0.0404,\n",
            "        -0.0423, -0.0608, -0.0492, -0.0580,  0.0105,  0.0309, -0.0051, -0.0103,\n",
            "        -0.0429, -0.0155,  0.0113,  0.0111, -0.0465,  0.0473, -0.0462,  0.0374,\n",
            "        -0.0127, -0.0382, -0.0552,  0.0025,  0.0010, -0.0286,  0.0022, -0.0548,\n",
            "        -0.0485,  0.0560, -0.0093,  0.0183, -0.0446,  0.0124, -0.0592,  0.0402,\n",
            "         0.0547, -0.0581, -0.0216,  0.0625, -0.0426, -0.0298, -0.0484,  0.0469,\n",
            "        -0.0134,  0.0304,  0.0556, -0.0209,  0.0409,  0.0212, -0.0129, -0.0200,\n",
            "         0.0495, -0.0488,  0.0461,  0.0441,  0.0400, -0.0478, -0.0188,  0.0044,\n",
            "         0.0026, -0.0503,  0.0152, -0.0190,  0.0505, -0.0029,  0.0687, -0.0114,\n",
            "         0.0429,  0.0068, -0.0458, -0.0559, -0.0282,  0.0183,  0.0114, -0.0251,\n",
            "        -0.0619,  0.0230,  0.0513, -0.0553,  0.0300, -0.0497,  0.0344, -0.0167,\n",
            "        -0.0138, -0.0425, -0.0025, -0.0037, -0.0129, -0.0512,  0.0292,  0.0226,\n",
            "        -0.0260,  0.0402,  0.0484, -0.0104,  0.0388,  0.0292, -0.0382,  0.0246,\n",
            "         0.0078,  0.0270,  0.0506, -0.0454,  0.0030,  0.0006, -0.0396, -0.0373,\n",
            "         0.0047,  0.0011,  0.0171,  0.0185,  0.0589,  0.0045, -0.0557,  0.0352,\n",
            "         0.0317, -0.0347,  0.0266,  0.0239,  0.0617, -0.0494,  0.0606, -0.0121,\n",
            "        -0.0409,  0.0170, -0.0364, -0.0492,  0.0305, -0.0267,  0.0014, -0.0162])), ('lidar_attention_submodel.attention_module.linear3.weight', tensor([[ 0.0265,  0.0044,  0.0120,  ..., -0.0230, -0.0397, -0.0112],\n",
            "        [ 0.0501, -0.0519,  0.0460,  ...,  0.0046, -0.0571,  0.0354],\n",
            "        [-0.0044,  0.0351, -0.0033,  ...,  0.0270, -0.0411,  0.0366],\n",
            "        ...,\n",
            "        [ 0.0492,  0.0239,  0.0584,  ..., -0.0061, -0.0033,  0.0599],\n",
            "        [-0.0499, -0.0243, -0.0451,  ..., -0.0261, -0.0357,  0.0229],\n",
            "        [ 0.0394, -0.0566,  0.0597,  ..., -0.0222, -0.0198, -0.0082]])), ('lidar_attention_submodel.attention_module.linear3.bias', tensor([-0.0244,  0.0414, -0.0278, -0.0506, -0.0077, -0.0394,  0.0208, -0.0525,\n",
            "         0.0551, -0.0578,  0.0707,  0.0176,  0.0251,  0.0097,  0.0259, -0.0220,\n",
            "        -0.0359,  0.0045, -0.0113,  0.0441, -0.0281,  0.0040,  0.0258, -0.0312,\n",
            "         0.0149,  0.0472, -0.0284,  0.0458,  0.0024, -0.0364, -0.0165, -0.0058,\n",
            "        -0.0245, -0.0261,  0.0480,  0.0414,  0.0611,  0.0703,  0.0113,  0.0596,\n",
            "        -0.0480, -0.0374,  0.0117,  0.0290,  0.0364,  0.0106, -0.0251, -0.0470,\n",
            "        -0.0301, -0.0146,  0.0458,  0.0305, -0.0231, -0.0449,  0.0051,  0.0414,\n",
            "         0.0496,  0.0856, -0.0027, -0.0286,  0.0554, -0.0274, -0.0580, -0.0370,\n",
            "         0.0366, -0.0518, -0.0433,  0.0369,  0.0668,  0.0393, -0.0039,  0.0595,\n",
            "        -0.0161, -0.0170, -0.0004, -0.0597, -0.0141, -0.0087,  0.0147,  0.0313,\n",
            "        -0.0353, -0.0298, -0.0605,  0.0280,  0.0009,  0.0598, -0.0138, -0.0467,\n",
            "         0.0579,  0.0215, -0.0525,  0.0300,  0.0430, -0.0340,  0.0460, -0.0237,\n",
            "        -0.0303,  0.0593, -0.0152,  0.0611, -0.0333,  0.0315,  0.0235, -0.0179,\n",
            "        -0.0391, -0.0159,  0.0233, -0.0089, -0.0219, -0.0617, -0.0118,  0.0025,\n",
            "         0.0511,  0.0108, -0.0512,  0.0391, -0.0310, -0.0450,  0.0516,  0.0160,\n",
            "         0.0278,  0.0230, -0.0510,  0.0179,  0.0421, -0.0400, -0.0477,  0.0572,\n",
            "        -0.0321,  0.0571, -0.0114, -0.0638, -0.0079,  0.0032,  0.0580, -0.0556,\n",
            "        -0.0403,  0.0024, -0.0162, -0.0492, -0.0567, -0.0508, -0.0611, -0.0513])), ('lidar_attention_submodel.attention_module.final_linear.weight', tensor([[-0.0860,  0.0794, -0.0188,  ...,  0.0687,  0.0069,  0.0398],\n",
            "        [-0.0201, -0.0763,  0.0776,  ..., -0.0624,  0.0118, -0.0439],\n",
            "        [ 0.0384,  0.0142,  0.0082,  ..., -0.0435,  0.0147, -0.0525],\n",
            "        ...,\n",
            "        [-0.0110,  0.0397, -0.0383,  ...,  0.0170,  0.0559,  0.0240],\n",
            "        [ 0.0602,  0.0115,  0.0632,  ..., -0.0435, -0.0573,  0.0391],\n",
            "        [ 0.0578,  0.0372,  0.0635,  ...,  0.0301,  0.0568, -0.0625]])), ('lidar_attention_submodel.attention_module.final_linear.bias', tensor([-0.0048, -0.0901, -0.0520, -0.0600,  0.0252, -0.0243, -0.0295,  0.0696,\n",
            "         0.0088, -0.0450, -0.0109, -0.0160,  0.0662,  0.0182,  0.0629,  0.0449,\n",
            "        -0.0011,  0.0689,  0.0125, -0.0458,  0.0250,  0.0719,  0.0476, -0.0337,\n",
            "         0.0022, -0.0076,  0.0542,  0.0164, -0.0788,  0.0204, -0.0285, -0.0633,\n",
            "        -0.0360,  0.0288, -0.0519, -0.0389, -0.0780, -0.0280, -0.0689,  0.0021,\n",
            "         0.0081, -0.0790, -0.0475,  0.0409, -0.0497, -0.0114, -0.0511,  0.0025,\n",
            "        -0.0587,  0.0263, -0.0637, -0.0888,  0.0182,  0.0177, -0.0897,  0.0104,\n",
            "        -0.0376,  0.0100,  0.0542,  0.0281, -0.0628, -0.0779, -0.0708,  0.0063,\n",
            "        -0.0556,  0.0587, -0.0130, -0.0171,  0.0025, -0.0411, -0.0407, -0.0212,\n",
            "         0.0005, -0.0910, -0.0376, -0.0873,  0.0151,  0.0392, -0.0129,  0.0400,\n",
            "        -0.0870,  0.0437,  0.0009, -0.0387,  0.0021, -0.0659, -0.0507, -0.0385,\n",
            "         0.0445, -0.0582, -0.0300,  0.0020, -0.0283,  0.0505, -0.0017, -0.0016,\n",
            "         0.0557,  0.0666,  0.0077, -0.0508, -0.0479, -0.0018, -0.0234,  0.0047,\n",
            "         0.0565, -0.0261, -0.0478, -0.0730,  0.0502,  0.0046, -0.0353, -0.0853,\n",
            "        -0.0589, -0.0242, -0.0149,  0.0047, -0.0147,  0.0537, -0.0821,  0.0371,\n",
            "         0.0171,  0.0232, -0.0385, -0.0264, -0.0713, -0.0349,  0.0637, -0.0172,\n",
            "         0.0700,  0.0206,  0.0175, -0.0915, -0.0261,  0.0045, -0.0512,  0.0633,\n",
            "         0.0406, -0.0807,  0.0262, -0.0713,  0.0302, -0.0804, -0.0252,  0.0417])), ('autoencoder.conv1.weight', tensor([[[[-0.0250]],\n",
            "\n",
            "         [[ 0.0377]],\n",
            "\n",
            "         [[-0.0260]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0526]],\n",
            "\n",
            "         [[-0.0415]],\n",
            "\n",
            "         [[ 0.0109]]],\n",
            "\n",
            "\n",
            "        [[[-0.0661]],\n",
            "\n",
            "         [[ 0.0776]],\n",
            "\n",
            "         [[-0.0625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0118]],\n",
            "\n",
            "         [[ 0.0082]],\n",
            "\n",
            "         [[-0.0629]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0603]],\n",
            "\n",
            "         [[-0.0450]],\n",
            "\n",
            "         [[ 0.0245]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0630]],\n",
            "\n",
            "         [[-0.0803]],\n",
            "\n",
            "         [[ 0.0129]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0563]],\n",
            "\n",
            "         [[ 0.0646]],\n",
            "\n",
            "         [[-0.0631]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0083]],\n",
            "\n",
            "         [[ 0.0396]],\n",
            "\n",
            "         [[ 0.0712]]],\n",
            "\n",
            "\n",
            "        [[[-0.0230]],\n",
            "\n",
            "         [[ 0.0428]],\n",
            "\n",
            "         [[-0.0011]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0336]],\n",
            "\n",
            "         [[-0.0781]],\n",
            "\n",
            "         [[-0.0742]]],\n",
            "\n",
            "\n",
            "        [[[-0.0262]],\n",
            "\n",
            "         [[ 0.0010]],\n",
            "\n",
            "         [[ 0.0821]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0333]],\n",
            "\n",
            "         [[ 0.0061]],\n",
            "\n",
            "         [[-0.0268]]]])), ('autoencoder.conv1.bias', tensor([-0.0165, -0.0215, -0.0341, -0.0116,  0.0417, -0.0799, -0.0276,  0.0747,\n",
            "         0.0364, -0.0586, -0.0420,  0.0257, -0.0067, -0.0810,  0.0594,  0.0154,\n",
            "        -0.0766,  0.0069, -0.0092, -0.0817, -0.0518, -0.0658, -0.0650, -0.0034,\n",
            "         0.0040, -0.0716,  0.0358,  0.0614, -0.0007,  0.0350,  0.0324,  0.0421,\n",
            "         0.0515, -0.0193, -0.0048,  0.0330, -0.0379,  0.0282,  0.0204, -0.0662,\n",
            "        -0.0728, -0.0280,  0.0131,  0.0239, -0.0800,  0.0182, -0.0198, -0.0574,\n",
            "        -0.0230,  0.0688,  0.0222,  0.0515, -0.0169, -0.0486,  0.0196,  0.0742,\n",
            "        -0.0250,  0.0240,  0.0104, -0.0297, -0.0777, -0.0123,  0.0031, -0.0510,\n",
            "        -0.0217,  0.0542, -0.0376, -0.0261,  0.0568, -0.0161,  0.0828,  0.0737,\n",
            "        -0.0126, -0.0532, -0.0774,  0.0361, -0.0775,  0.0684, -0.0363,  0.0233,\n",
            "         0.0609, -0.0460,  0.0590,  0.0288,  0.0049,  0.0685,  0.0737, -0.0012,\n",
            "         0.0145, -0.0002, -0.0622, -0.0129, -0.0115,  0.0829,  0.0050,  0.0222,\n",
            "         0.0609,  0.0258,  0.0722,  0.0777, -0.0069, -0.0459,  0.0745,  0.0184,\n",
            "         0.0561, -0.0539,  0.0456,  0.0286,  0.0804,  0.0214, -0.0673,  0.0220,\n",
            "        -0.0669,  0.0592,  0.0226, -0.0152,  0.0353,  0.0274,  0.0081,  0.0016,\n",
            "         0.0047, -0.0077,  0.0136, -0.0334,  0.0178, -0.0521, -0.0084, -0.0615,\n",
            "         0.0356,  0.0013,  0.0141, -0.0498,  0.0702, -0.0686,  0.0749, -0.0583,\n",
            "        -0.0273, -0.0475, -0.0192,  0.0707, -0.0218,  0.0487,  0.0112,  0.0370,\n",
            "        -0.0117, -0.0105,  0.0479, -0.0251, -0.0386,  0.0637, -0.0734, -0.0824,\n",
            "         0.0304, -0.0680,  0.0219,  0.0447, -0.0247,  0.0218,  0.0457, -0.0204,\n",
            "        -0.0283, -0.0705,  0.0699, -0.0778,  0.0125, -0.0471,  0.0824,  0.0429,\n",
            "        -0.0616,  0.0074,  0.0062,  0.0469, -0.0807,  0.0747,  0.0602, -0.0009,\n",
            "         0.0082,  0.0395,  0.0374,  0.0600, -0.0170,  0.0553, -0.0665,  0.0120,\n",
            "         0.0310,  0.0794,  0.0190,  0.0270,  0.0781,  0.0522,  0.0724,  0.0328,\n",
            "        -0.0318,  0.0349, -0.0536,  0.0393, -0.0433, -0.0145, -0.0782,  0.0172,\n",
            "         0.0620, -0.0464,  0.0497,  0.0489,  0.0304,  0.0256,  0.0519, -0.0299,\n",
            "        -0.0599,  0.0608, -0.0387,  0.0197,  0.0064,  0.0095, -0.0772,  0.0468,\n",
            "        -0.0258, -0.0307,  0.0151,  0.0601,  0.0357, -0.0227, -0.0083,  0.0451,\n",
            "        -0.0086,  0.0782, -0.0120,  0.0619,  0.0376, -0.0765,  0.0040,  0.0462,\n",
            "         0.0457, -0.0433, -0.0082, -0.0050,  0.0808,  0.0644, -0.0039, -0.0378,\n",
            "        -0.0084, -0.0159, -0.0787,  0.0053,  0.0558, -0.0687,  0.0020,  0.0675,\n",
            "         0.0533,  0.0668,  0.0526,  0.0321,  0.0098,  0.0247, -0.0725, -0.0589])), ('autoencoder.conv2.weight', tensor([[[[-0.0389]],\n",
            "\n",
            "         [[-0.0349]],\n",
            "\n",
            "         [[ 0.0316]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0553]],\n",
            "\n",
            "         [[-0.0202]],\n",
            "\n",
            "         [[-0.0151]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0500]],\n",
            "\n",
            "         [[-0.0196]],\n",
            "\n",
            "         [[ 0.0602]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0238]],\n",
            "\n",
            "         [[ 0.0080]],\n",
            "\n",
            "         [[ 0.0586]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0198]],\n",
            "\n",
            "         [[-0.0368]],\n",
            "\n",
            "         [[ 0.0016]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0514]],\n",
            "\n",
            "         [[-0.0019]],\n",
            "\n",
            "         [[-0.0220]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0537]],\n",
            "\n",
            "         [[ 0.0507]],\n",
            "\n",
            "         [[-0.0237]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0294]],\n",
            "\n",
            "         [[-0.0123]],\n",
            "\n",
            "         [[ 0.0392]]],\n",
            "\n",
            "\n",
            "        [[[-0.0004]],\n",
            "\n",
            "         [[-0.0588]],\n",
            "\n",
            "         [[-0.0474]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0504]],\n",
            "\n",
            "         [[-0.0608]],\n",
            "\n",
            "         [[-0.0246]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0359]],\n",
            "\n",
            "         [[ 0.0100]],\n",
            "\n",
            "         [[ 0.0457]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0153]],\n",
            "\n",
            "         [[ 0.0399]],\n",
            "\n",
            "         [[ 0.0431]]]])), ('autoencoder.conv2.bias', tensor([ 0.0472, -0.0422,  0.0290,  0.0083,  0.0545, -0.0481, -0.0581, -0.0308,\n",
            "         0.0221,  0.0393, -0.0441, -0.0174, -0.0563, -0.0016,  0.0006, -0.0194,\n",
            "         0.0351,  0.0290,  0.0226, -0.0347,  0.0149,  0.0577, -0.0273,  0.0072,\n",
            "        -0.0278, -0.0416,  0.0059, -0.0326, -0.0387, -0.0157,  0.0536,  0.0326,\n",
            "        -0.0139,  0.0576,  0.0050, -0.0313, -0.0098, -0.0368, -0.0094,  0.0491,\n",
            "        -0.0249, -0.0583,  0.0267, -0.0320, -0.0459, -0.0431,  0.0364, -0.0283,\n",
            "        -0.0162, -0.0560, -0.0238, -0.0383, -0.0623, -0.0496,  0.0138,  0.0607,\n",
            "        -0.0549,  0.0516,  0.0222, -0.0181, -0.0539, -0.0600,  0.0262, -0.0537,\n",
            "         0.0049,  0.0237, -0.0063,  0.0461, -0.0173, -0.0591, -0.0563, -0.0375,\n",
            "        -0.0085, -0.0080, -0.0103,  0.0429, -0.0480, -0.0129,  0.0054, -0.0343,\n",
            "         0.0572, -0.0064, -0.0473,  0.0101, -0.0096, -0.0104, -0.0557,  0.0548,\n",
            "         0.0363, -0.0037,  0.0282, -0.0549, -0.0270, -0.0031, -0.0531, -0.0562,\n",
            "         0.0474,  0.0511,  0.0060,  0.0611,  0.0075, -0.0090,  0.0591, -0.0448,\n",
            "        -0.0284,  0.0359, -0.0368, -0.0565, -0.0532, -0.0559, -0.0615,  0.0241,\n",
            "         0.0041, -0.0481, -0.0310,  0.0556, -0.0403, -0.0296,  0.0226,  0.0314,\n",
            "         0.0186,  0.0132,  0.0500,  0.0224, -0.0154, -0.0356,  0.0348, -0.0471,\n",
            "        -0.0375,  0.0151, -0.0507, -0.0204,  0.0152, -0.0312, -0.0001, -0.0180,\n",
            "        -0.0072,  0.0584, -0.0322,  0.0577,  0.0498,  0.0013,  0.0609, -0.0124,\n",
            "         0.0055,  0.0474,  0.0152, -0.0036,  0.0618, -0.0056,  0.0331,  0.0206,\n",
            "         0.0349, -0.0444,  0.0571, -0.0062, -0.0026,  0.0166, -0.0186,  0.0464,\n",
            "        -0.0328,  0.0241, -0.0271, -0.0416, -0.0241, -0.0393, -0.0386, -0.0566,\n",
            "         0.0514,  0.0330,  0.0283, -0.0089,  0.0279,  0.0412,  0.0227, -0.0543,\n",
            "        -0.0500,  0.0025,  0.0153, -0.0093, -0.0262, -0.0086,  0.0109,  0.0617,\n",
            "         0.0352,  0.0338,  0.0539,  0.0544, -0.0364,  0.0558,  0.0353,  0.0239,\n",
            "         0.0148,  0.0285, -0.0510,  0.0092,  0.0416, -0.0413, -0.0598, -0.0582,\n",
            "        -0.0060, -0.0450, -0.0616,  0.0337,  0.0386, -0.0583,  0.0352,  0.0383,\n",
            "        -0.0489,  0.0218,  0.0090, -0.0023, -0.0106, -0.0320, -0.0221, -0.0410,\n",
            "         0.0380,  0.0200, -0.0216, -0.0128,  0.0390, -0.0118, -0.0107,  0.0358,\n",
            "        -0.0558,  0.0439, -0.0550, -0.0148, -0.0034, -0.0334,  0.0418, -0.0609,\n",
            "         0.0008,  0.0468,  0.0240,  0.0446,  0.0605,  0.0014,  0.0193, -0.0352,\n",
            "        -0.0530,  0.0171, -0.0507, -0.0153,  0.0014, -0.0210,  0.0090,  0.0466,\n",
            "        -0.0529, -0.0499,  0.0470, -0.0093,  0.0370,  0.0399,  0.0263,  0.0566])), ('autoencoder.deconv1.weight', tensor([[[[-0.0450]],\n",
            "\n",
            "         [[-0.0305]],\n",
            "\n",
            "         [[-0.0502]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0015]],\n",
            "\n",
            "         [[ 0.0327]],\n",
            "\n",
            "         [[-0.0622]]],\n",
            "\n",
            "\n",
            "        [[[-0.0445]],\n",
            "\n",
            "         [[-0.0351]],\n",
            "\n",
            "         [[ 0.0473]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0256]],\n",
            "\n",
            "         [[ 0.0134]],\n",
            "\n",
            "         [[ 0.0506]]],\n",
            "\n",
            "\n",
            "        [[[-0.0532]],\n",
            "\n",
            "         [[-0.0428]],\n",
            "\n",
            "         [[ 0.0218]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0459]],\n",
            "\n",
            "         [[ 0.0255]],\n",
            "\n",
            "         [[ 0.0269]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0192]],\n",
            "\n",
            "         [[ 0.0248]],\n",
            "\n",
            "         [[ 0.0227]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0207]],\n",
            "\n",
            "         [[-0.0544]],\n",
            "\n",
            "         [[ 0.0220]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0057]],\n",
            "\n",
            "         [[ 0.0588]],\n",
            "\n",
            "         [[ 0.0579]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0021]],\n",
            "\n",
            "         [[-0.0554]],\n",
            "\n",
            "         [[-0.0528]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0179]],\n",
            "\n",
            "         [[ 0.0617]],\n",
            "\n",
            "         [[ 0.0355]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0372]],\n",
            "\n",
            "         [[-0.0551]],\n",
            "\n",
            "         [[-0.0415]]]])), ('autoencoder.deconv1.bias', tensor([-0.0554,  0.0118,  0.0462, -0.0589,  0.0635,  0.0542, -0.0321,  0.0395,\n",
            "         0.0035,  0.0460,  0.0427, -0.0516,  0.0589,  0.0059,  0.0452, -0.0426,\n",
            "         0.0498, -0.0546, -0.0624,  0.0372, -0.0452, -0.0499,  0.0415, -0.0214,\n",
            "         0.0225, -0.0168,  0.0525,  0.0363,  0.0061,  0.0575,  0.0235,  0.0044,\n",
            "        -0.0529, -0.0517, -0.0407, -0.0154,  0.0425, -0.0031,  0.0012,  0.0390,\n",
            "         0.0536, -0.0564, -0.0250,  0.0473,  0.0539,  0.0198,  0.0546, -0.0084,\n",
            "        -0.0382, -0.0208, -0.0123,  0.0303,  0.0122, -0.0339, -0.0115,  0.0529,\n",
            "        -0.0286,  0.0126,  0.0253,  0.0459, -0.0604, -0.0108, -0.0430, -0.0475,\n",
            "         0.0363,  0.0240, -0.0095,  0.0558,  0.0515,  0.0186, -0.0020,  0.0498,\n",
            "         0.0340, -0.0594, -0.0099, -0.0484,  0.0215, -0.0176, -0.0110,  0.0040,\n",
            "         0.0150, -0.0132,  0.0537,  0.0312,  0.0511,  0.0510,  0.0313, -0.0577,\n",
            "         0.0365, -0.0170, -0.0627, -0.0345,  0.0472,  0.0387,  0.0220,  0.0556,\n",
            "        -0.0123,  0.0407,  0.0575, -0.0191,  0.0506,  0.0488, -0.0539, -0.0457,\n",
            "        -0.0177,  0.0317,  0.0211,  0.0171,  0.0508,  0.0472,  0.0340, -0.0467,\n",
            "         0.0094, -0.0493, -0.0203,  0.0412, -0.0062, -0.0079, -0.0159,  0.0294,\n",
            "        -0.0492, -0.0509, -0.0107, -0.0395,  0.0459, -0.0266, -0.0046,  0.0554,\n",
            "         0.0612, -0.0002,  0.0553, -0.0169,  0.0445,  0.0043, -0.0205, -0.0551,\n",
            "         0.0274,  0.0017, -0.0380, -0.0550,  0.0277,  0.0491,  0.0525, -0.0459,\n",
            "         0.0076,  0.0222,  0.0589, -0.0300,  0.0113,  0.0635,  0.0015,  0.0495,\n",
            "         0.0538, -0.0238,  0.0383,  0.0266,  0.0063,  0.0357, -0.0492,  0.0266,\n",
            "         0.0519, -0.0372, -0.0589,  0.0122, -0.0187,  0.0175,  0.0414, -0.0209,\n",
            "         0.0022,  0.0116,  0.0361,  0.0091, -0.0323, -0.0248, -0.0006,  0.0359,\n",
            "         0.0079,  0.0480, -0.0065,  0.0421, -0.0379, -0.0114, -0.0380,  0.0533,\n",
            "        -0.0280,  0.0347,  0.0312,  0.0552, -0.0334,  0.0091,  0.0066, -0.0178,\n",
            "         0.0444,  0.0369, -0.0066,  0.0218,  0.0448,  0.0163, -0.0071, -0.0048,\n",
            "        -0.0602, -0.0504,  0.0578, -0.0167,  0.0109,  0.0158,  0.0435, -0.0185,\n",
            "         0.0034,  0.0309,  0.0334, -0.0010, -0.0503,  0.0239,  0.0200, -0.0329,\n",
            "         0.0586,  0.0564,  0.0548,  0.0039,  0.0263,  0.0051,  0.0208, -0.0317,\n",
            "        -0.0541,  0.0137,  0.0115,  0.0054, -0.0253, -0.0320, -0.0076, -0.0146,\n",
            "        -0.0498, -0.0431,  0.0541,  0.0095, -0.0263,  0.0536,  0.0595,  0.0501,\n",
            "         0.0362,  0.0133, -0.0092,  0.0132, -0.0006, -0.0113, -0.0159,  0.0533,\n",
            "         0.0376,  0.0041,  0.0321, -0.0352,  0.0059, -0.0492,  0.0385,  0.0357])), ('autoencoder.deconv2.weight', tensor([[[[-0.0535]],\n",
            "\n",
            "         [[-0.0520]],\n",
            "\n",
            "         [[ 0.0254]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0194]],\n",
            "\n",
            "         [[ 0.0715]],\n",
            "\n",
            "         [[ 0.0371]]],\n",
            "\n",
            "\n",
            "        [[[-0.0342]],\n",
            "\n",
            "         [[-0.0355]],\n",
            "\n",
            "         [[ 0.0037]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0446]],\n",
            "\n",
            "         [[-0.0193]],\n",
            "\n",
            "         [[-0.0596]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0100]],\n",
            "\n",
            "         [[-0.0136]],\n",
            "\n",
            "         [[ 0.0253]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0603]],\n",
            "\n",
            "         [[ 0.0019]],\n",
            "\n",
            "         [[ 0.0255]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0240]],\n",
            "\n",
            "         [[-0.0342]],\n",
            "\n",
            "         [[ 0.0696]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0421]],\n",
            "\n",
            "         [[-0.0187]],\n",
            "\n",
            "         [[ 0.0766]]],\n",
            "\n",
            "\n",
            "        [[[-0.0100]],\n",
            "\n",
            "         [[ 0.0038]],\n",
            "\n",
            "         [[-0.0523]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0451]],\n",
            "\n",
            "         [[ 0.0145]],\n",
            "\n",
            "         [[-0.0151]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0737]],\n",
            "\n",
            "         [[ 0.0707]],\n",
            "\n",
            "         [[ 0.0116]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0695]],\n",
            "\n",
            "         [[ 0.0818]],\n",
            "\n",
            "         [[ 0.0531]]]])), ('autoencoder.deconv2.bias', tensor([ 0.0273, -0.0455,  0.0807, -0.0143,  0.0161,  0.0047, -0.0443,  0.0776,\n",
            "         0.0125,  0.0586,  0.0124,  0.0169,  0.0251, -0.0139,  0.0455, -0.0020,\n",
            "         0.0756,  0.0677,  0.0153, -0.0487,  0.0411,  0.0767, -0.0385, -0.0124,\n",
            "        -0.0426, -0.0393,  0.0433,  0.0146, -0.0481,  0.0391,  0.0277,  0.0721,\n",
            "        -0.0435,  0.0153,  0.0189, -0.0381, -0.0408,  0.0730,  0.0810,  0.0611,\n",
            "        -0.0273,  0.0814, -0.0044,  0.0586, -0.0394, -0.0045,  0.0780, -0.0596,\n",
            "         0.0114,  0.0313,  0.0252,  0.0268,  0.0236,  0.0080,  0.0106, -0.0584,\n",
            "        -0.0256, -0.0075, -0.0407, -0.0257, -0.0616,  0.0530,  0.0191, -0.0376,\n",
            "         0.0930,  0.0199,  0.0825,  0.0887,  0.0478, -0.0327,  0.0145, -0.0160,\n",
            "        -0.0614,  0.0512, -0.0130,  0.0726, -0.0380,  0.0328,  0.0244,  0.0447,\n",
            "         0.0756,  0.0502,  0.0919,  0.0561,  0.0371, -0.0041,  0.0778,  0.0585,\n",
            "         0.0227, -0.0607,  0.0609, -0.0240,  0.0505, -0.0439,  0.0155, -0.0353,\n",
            "         0.0384,  0.0497,  0.0955,  0.0352, -0.0249,  0.0705,  0.0629,  0.0448,\n",
            "         0.0634, -0.0509, -0.0070, -0.0501, -0.0557,  0.0870, -0.0029,  0.0694,\n",
            "         0.0280,  0.0707,  0.0295, -0.0395, -0.0520,  0.0299, -0.0107,  0.0191,\n",
            "        -0.0584,  0.0043,  0.0343, -0.0004,  0.0559,  0.0839,  0.0442, -0.0565,\n",
            "        -0.0574,  0.0652, -0.0078, -0.0545, -0.0581,  0.0247,  0.0010,  0.0801,\n",
            "         0.0611,  0.0839,  0.0237,  0.0497,  0.0705,  0.0787,  0.0169, -0.0426]))])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# Assuming IntegratedModel, HSIAttentionSubmodel, LiDARAttentionSubmodel, CNNAutoEncoder are defined\n",
        "# Create an instance of your model\n",
        "model = IntegratedModel(hsi_config, lidar_config)\n",
        "\n",
        "# Define the path where your model is saved\n",
        "model_path = path+'Autoencodermodel_uh2013_sgdp3nfuseddata_20Ksample.pth' # Update the path accordingly # test on 11/05/2024\n",
        "\n",
        "# Load the state dictionary\n",
        "checkpoint = torch.load(model_path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# Optionally, if you want to evaluate the model\n",
        "model.eval()\n",
        "\n",
        "# Print the parameters\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.shape)\n",
        "\n",
        "# Print the full state dictionary\n",
        "print(\"Full state dict:\")\n",
        "print(model.state_dict())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IrRolVFaKZy_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrRolVFaKZy_",
        "outputId": "5e2f6972-050c-46eb-84cd-9553e877c4b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's state_dict:\n",
            "hsi_attention_submodel.patch_embedding.pos_embedding \t torch.Size([1, 145, 256])\n",
            "hsi_attention_submodel.patch_embedding.proj.weight \t torch.Size([256, 144, 1, 1])\n",
            "hsi_attention_submodel.patch_embedding.proj.bias \t torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.input_projection.weight \t torch.Size([256, 256])\n",
            "hsi_attention_submodel.attention_module.input_projection.bias \t torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.norm1.weight \t torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.norm1.bias \t torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.norm2.weight \t torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.norm2.bias \t torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.multihead_attn.in_proj_weight \t torch.Size([768, 256])\n",
            "hsi_attention_submodel.attention_module.multihead_attn.in_proj_bias \t torch.Size([768])\n",
            "hsi_attention_submodel.attention_module.multihead_attn.out_proj.weight \t torch.Size([256, 256])\n",
            "hsi_attention_submodel.attention_module.multihead_attn.out_proj.bias \t torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.linear1.weight \t torch.Size([256, 256])\n",
            "hsi_attention_submodel.attention_module.linear1.bias \t torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.linear2.weight \t torch.Size([256, 256])\n",
            "hsi_attention_submodel.attention_module.linear2.bias \t torch.Size([256])\n",
            "hsi_attention_submodel.attention_module.linear3.weight \t torch.Size([144, 256])\n",
            "hsi_attention_submodel.attention_module.linear3.bias \t torch.Size([144])\n",
            "hsi_attention_submodel.attention_module.final_linear.weight \t torch.Size([144, 144])\n",
            "hsi_attention_submodel.attention_module.final_linear.bias \t torch.Size([144])\n",
            "lidar_attention_submodel.patch_embedding.pos_embedding \t torch.Size([1, 145, 256])\n",
            "lidar_attention_submodel.patch_embedding.proj.weight \t torch.Size([256, 144, 1, 1])\n",
            "lidar_attention_submodel.patch_embedding.proj.bias \t torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.input_projection.weight \t torch.Size([256, 256])\n",
            "lidar_attention_submodel.attention_module.input_projection.bias \t torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.norm1.weight \t torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.norm1.bias \t torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.norm2.weight \t torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.norm2.bias \t torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.multihead_attn.in_proj_weight \t torch.Size([768, 256])\n",
            "lidar_attention_submodel.attention_module.multihead_attn.in_proj_bias \t torch.Size([768])\n",
            "lidar_attention_submodel.attention_module.multihead_attn.out_proj.weight \t torch.Size([256, 256])\n",
            "lidar_attention_submodel.attention_module.multihead_attn.out_proj.bias \t torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.linear1.weight \t torch.Size([256, 256])\n",
            "lidar_attention_submodel.attention_module.linear1.bias \t torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.linear2.weight \t torch.Size([256, 256])\n",
            "lidar_attention_submodel.attention_module.linear2.bias \t torch.Size([256])\n",
            "lidar_attention_submodel.attention_module.linear3.weight \t torch.Size([144, 256])\n",
            "lidar_attention_submodel.attention_module.linear3.bias \t torch.Size([144])\n",
            "lidar_attention_submodel.attention_module.final_linear.weight \t torch.Size([144, 144])\n",
            "lidar_attention_submodel.attention_module.final_linear.bias \t torch.Size([144])\n",
            "autoencoder.conv1.weight \t torch.Size([256, 144, 1, 1])\n",
            "autoencoder.conv1.bias \t torch.Size([256])\n",
            "autoencoder.conv2.weight \t torch.Size([256, 256, 1, 1])\n",
            "autoencoder.conv2.bias \t torch.Size([256])\n",
            "autoencoder.deconv1.weight \t torch.Size([256, 256, 1, 1])\n",
            "autoencoder.deconv1.bias \t torch.Size([256])\n",
            "autoencoder.deconv2.weight \t torch.Size([256, 144, 1, 1])\n",
            "autoencoder.deconv2.bias \t torch.Size([144])\n"
          ]
        }
      ],
      "source": [
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fKXW7ynlGQ9D",
      "metadata": {
        "id": "fKXW7ynlGQ9D"
      },
      "source": [
        "# 6. Band Selection based on Applied Trained Model and Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a28U1TDIEtIY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a28U1TDIEtIY",
        "outputId": "34578ac1-5a39-4191-9e3f-150bae79f175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all_fused_masks.shape: (20000, 9, 144)\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of your model\n",
        "model = IntegratedModel(hsi_config, lidar_config)\n",
        "\n",
        "# Define the path where your model is saved\n",
        "model_path = path+'Autoencodermodel_uh2013_sgdp3nfuseddata_20Ksample.pth' # Update the path accordingly\n",
        "\n",
        "# Load the state dictionary\n",
        "checkpoint = torch.load(model_path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# Optionally, if you want to evaluate the model\n",
        "model.eval()\n",
        "\n",
        "# List to store fused masks\n",
        "all_fused_masks = []  # all_fused_attention_masks\n",
        "\n",
        "# Process each pair of DataLoaders (HSI and LiDAR for train, val, test)\n",
        "dataloaders = zip([hsi_train_dataloader, hsi_val_dataloader, hsi_test_dataloader],\n",
        "                  [lidar_train_dataloader, lidar_val_dataloader, lidar_test_dataloader])\n",
        "\n",
        "for hsi_loader, lidar_loader in dataloaders:\n",
        "    with torch.no_grad():\n",
        "        for hsi_patches, lidar_patches in zip(hsi_loader, lidar_loader):\n",
        "            hsi_patches = hsi_patches[0].to(device)  # Unpack and move to device\n",
        "            lidar_patches = lidar_patches[0].to(device)  # Unpack and move to device\n",
        "            fused_mask,_ = model(hsi_patches, lidar_patches)\n",
        "            all_fused_masks.append(fused_mask.cpu().numpy())\n",
        "\n",
        "# Concatenate all fused masks\n",
        "all_fused_masks = np.concatenate(all_fused_masks, axis=0)  # all_fused_attention_masks\n",
        "print('all_fused_masks.shape:', all_fused_masks.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_JRt_F_sNT-n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JRt_F_sNT-n",
        "outputId": "e26082b5-c83c-4558-acfb-50d105017aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all_fused_masks shape: (20000, 9, 144)\n",
            "A_norm shape: (144,)\n"
          ]
        }
      ],
      "source": [
        "#6.0 Band Selection\n",
        "import numpy as np\n",
        "\n",
        "# Re-initializing the dummy data for demonstration as the state was reset\n",
        "all_fused_masks = all_fused_masks\n",
        "print('all_fused_masks shape:',all_fused_masks.shape)\n",
        "\n",
        "# Compute the mean attention value across all samples and spatial locations for each band\n",
        "# This will result in a vector A of length 144, where each Ai is the aggregated attention score for the i-th band\n",
        "A = all_fused_masks.mean(axis=(0, 1))\n",
        "\n",
        "# Normalize the aggregated attention scores to ensure they are on a comparable scale\n",
        "A_norm = (A - A.min()) / (A.max() - A.min())\n",
        "\n",
        "A_norm  # This is the normalized attention for each band\n",
        "print('A_norm shape:', A_norm.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample normalized attention scores for each band\n",
        "attention_scores = A_norm  # Normalize to sum to 1\n",
        "\n",
        "# Calculate Weight Matrix W\n",
        "num_bands = attention_scores.shape[0]\n",
        "#W = np.zeros((num_bands, num_bands))\n",
        "attention_distance_matrix = np.outer(A_norm, A_norm)\n",
        "W = np.outer(A_norm, A_norm)\n",
        "\n",
        "for i in range(num_bands):\n",
        "    for j in range(num_bands):\n",
        "        W[i, j] = attention_scores[i] *  attention_scores[j]\n",
        "        #W[i, j] = (1 - attention_scores[i]) * (1 - attention_scores[j])\n",
        "\n",
        "# Plot the Weight Matrix\n",
        "plt.imshow(W, cmap='hot', interpolation='nearest')\n",
        "plt.colorbar()\n",
        "plt.title('Weight Matrix W')\n",
        "plt.xlabel('Band j')\n",
        "plt.ylabel('Band i')\n",
        "plt.show()\n",
        "\n",
        "print('Attention matrix shape:', W.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "6fzbC4BZLbIw",
        "outputId": "72c3bdfc-d5a4-49c4-f207-165d3c9fe2d5"
      },
      "id": "6fzbC4BZLbIw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention matrix shape: (144, 144)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QVp8lfOcTav9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "QVp8lfOcTav9",
        "outputId": "24662848-4c6a-4a3d-f204-17aecd5ba45b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'all_fused_masks' is available with shape (20000, 81, 144)\n",
        "# Reshape to (20000*81, 144) for correlation computation\n",
        "band_data = all_fused_masks.reshape(-1, all_fused_masks.shape[-1])\n",
        "\n",
        "# Compute the Pearson Correlation Matrix across bands\n",
        "correlation_matrix = np.corrcoef(band_data, rowvar=False)\n",
        "\n",
        "# Plot the correlation matrix using seaborn's heatmap function\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title('Pearson Correlation Matrix Between Bands')\n",
        "plt.xlabel('Band Number')\n",
        "plt.ylabel('Band Number')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'correlation_matrix' and 'A_norm' are defined earlier in your code\n",
        "def calculate_combined_distance(A_norm, correlation_matrix, alpha=0.8, beta=0.2):\n",
        "    # Using A_norm directly as it represents high attention\n",
        "    attention_distance_matrix = np.outer(A_norm, A_norm)\n",
        "\n",
        "    # Dissimilarity distance based on correlation\n",
        "    dissimilarity_distance = 1 - abs(correlation_matrix)\n",
        "\n",
        "    # Combined distance\n",
        "    combined_distance = alpha * attention_distance_matrix + beta * dissimilarity_distance\n",
        "    return combined_distance # he combined distance in this version is a weighted sum where higher attention and higher dissimilarity (lower correlation) are favored.\n",
        "\n",
        "# Define multiple seeds for K-means\n",
        "#seeds = [42, 0, 123]  # Example seed values\n",
        "seeds = [42]  # Example seed values\n",
        "# List of different values of k\n",
        "k_values = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
        "\n",
        "for k in k_values:\n",
        "    print(f\"\\n-- For k = {k} --\")\n",
        "\n",
        "    all_selected_bands = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        combined_distance = calculate_combined_distance(A_norm, correlation_matrix)\n",
        "\n",
        "        # Apply K-means clustering\n",
        "        kmeans = KMeans(n_clusters=k, init='k-means++', random_state=seed)\n",
        "        kmeans.fit(combined_distance)\n",
        "        clusters = kmeans.labels_\n",
        "\n",
        "        # Select bands for the current seed\n",
        "        selected_bands = []\n",
        "        for cluster_idx in range(k):\n",
        "            cluster_members = np.where(clusters == cluster_idx)[0]\n",
        "            if cluster_members.size > 0:\n",
        "                # Select the band with the highest attention within this cluster\n",
        "                selected_band = cluster_members[np.argmax(A_norm[cluster_members])]\n",
        "                selected_bands.append(selected_band)\n",
        "\n",
        "        # Store the selected bands for the current seed\n",
        "        all_selected_bands.append(np.array(selected_bands))\n",
        "\n",
        "    # Print selected bands for each seed\n",
        "    for idx, selected_bands in enumerate(all_selected_bands):\n",
        "        print(f\"Selected bands for seed {seeds[idx]}: {selected_bands.tolist()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUYJERccL5UX",
        "outputId": "9ecd5bb3-28f6-4a0c-bbf0-41d8259a1186"
      },
      "id": "qUYJERccL5UX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- For k = 1 --\n",
            "Selected bands for seed 42: [54]\n",
            "\n",
            "-- For k = 5 --\n",
            "Selected bands for seed 42: [81, 62, 137, 91, 54]\n",
            "\n",
            "-- For k = 10 --\n",
            "Selected bands for seed 42: [29, 108, 32, 18, 59, 104, 54, 137, 103, 91]\n",
            "\n",
            "-- For k = 15 --\n",
            "Selected bands for seed 42: [104, 103, 121, 15, 58, 54, 62, 108, 91, 12, 18, 102, 137, 69, 114]\n",
            "\n",
            "-- For k = 20 --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected bands for seed 42: [14, 140, 18, 15, 69, 23, 31, 12, 43, 103, 137, 54, 104, 98, 114, 102, 62, 1, 108, 59]\n",
            "\n",
            "-- For k = 25 --\n",
            "Selected bands for seed 42: [107, 137, 69, 103, 31, 104, 23, 18, 43, 7, 54, 32, 81, 15, 140, 68, 59, 114, 83, 35, 108, 128, 80, 55, 1]\n",
            "\n",
            "-- For k = 30 --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected bands for seed 42: [98, 1, 103, 12, 31, 63, 128, 18, 132, 121, 15, 102, 108, 54, 114, 140, 107, 35, 137, 62, 59, 67, 7, 55, 104, 29, 32, 69, 81, 141]\n",
            "\n",
            "-- For k = 35 --\n",
            "Selected bands for seed 42: [32, 28, 108, 121, 18, 115, 1, 81, 114, 7, 91, 19, 69, 15, 135, 83, 35, 140, 87, 31, 102, 132, 59, 112, 103, 104, 137, 128, 12, 90, 54, 67, 58, 62, 88]\n",
            "\n",
            "-- For k = 40 --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected bands for seed 42: [58, 7, 124, 106, 18, 114, 132, 103, 128, 137, 17, 133, 108, 35, 32, 31, 42, 140, 59, 88, 69, 90, 1, 81, 141, 67, 104, 54, 12, 87, 121, 91, 28, 29, 77, 62, 55, 15, 115, 102]\n",
            "\n",
            "-- For k = 45 --\n",
            "Selected bands for seed 42: [12, 58, 108, 45, 113, 124, 18, 140, 128, 69, 137, 114, 55, 83, 59, 62, 102, 133, 35, 104, 31, 7, 1, 88, 106, 110, 90, 132, 103, 54, 87, 67, 141, 66, 15, 121, 73, 32, 19, 115, 28, 77, 91, 42, 43]\n",
            "\n",
            "-- For k = 50 --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected bands for seed 42: [62, 58, 124, 90, 121, 54, 140, 114, 81, 7, 87, 104, 98, 108, 42, 69, 18, 59, 1, 14, 19, 31, 103, 82, 137, 128, 67, 32, 107, 35, 132, 15, 23, 45, 141, 106, 115, 17, 102, 55, 73, 12, 77, 51, 29, 133, 36, 13, 91, 46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p3_50=[62, 58, 124, 90, 121, 54, 140, 114, 81, 7, 87, 104, 98, 108, 42, 69, 18, 59, 1, 14, 19, 31, 103, 82, 137, 128, 67, 32, 107, 35, 132, 15, 23, 45, 141, 106, 115, 17, 102, 55, 73, 12, 77, 51, 29, 133, 36, 13, 91, 46]\n",
        "p3_45=[12, 58, 108, 45, 113, 124, 18, 140, 128, 69, 137, 114, 55, 83, 59, 62, 102, 133, 35, 104, 31, 7, 1, 88, 106, 110, 90, 132, 103, 54, 87, 67, 141, 66, 15, 121, 73, 32, 19, 115, 28, 77, 91, 42, 43]\n",
        "p3_40=[58, 7, 124, 106, 18, 114, 132, 103, 128, 137, 17, 133, 108, 35, 32, 31, 42, 140, 59, 88, 69, 90, 1, 81, 141, 67, 104, 54, 12, 87, 121, 91, 28, 29, 77, 62, 55, 15, 115, 102]\n",
        "p3_35=[32, 28, 108, 121, 18, 115, 1, 81, 114, 7, 91, 19, 69, 15, 135, 83, 35, 140, 87, 31, 102, 132, 59, 112, 103, 104, 137, 128, 12, 90, 54, 67, 58, 62, 88]\n",
        "p3_30=[98, 1, 103, 12, 31, 63, 128, 18, 132, 121, 15, 102, 108, 54, 114, 140, 107, 35, 137, 62, 59, 67, 7, 55, 104, 29, 32, 69, 81, 141]\n",
        "p3_25=[107, 137, 69, 103, 31, 104, 23, 18, 43, 7, 54, 32, 81, 15, 140, 68, 59, 114, 83, 35, 108, 128, 80, 55, 1]\n",
        "p3_20=[14, 140, 18, 15, 69, 23, 31, 12, 43, 103, 137, 54, 104, 98, 114, 102, 62, 1, 108, 59]\n",
        "p3_15=[104, 103, 121, 15, 58, 54, 62, 108, 91, 12, 18, 102, 137, 69, 114]\n",
        "p3_10=[29, 108, 32, 18, 59, 104, 54, 137, 103, 91]\n",
        "p3_5=[81, 62, 137, 91, 54]\n",
        "p3_1=[54]"
      ],
      "metadata": {
        "id": "-NlEZ2ydf2tS"
      },
      "id": "-NlEZ2ydf2tS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p5_50=[18, 95, 97, 29, 12, 77, 31, 124, 9, 81, 47, 22, 51, 125, 57, 64, 40, 14, 132, 6, 123, 142, 65, 1, 86, 26, 54, 27, 36, 17, 82, 112, 84, 106, 116, 45, 139, 19, 53, 62, 100, 75, 108, 70, 90, 136, 15, 113, 33, 44]\n",
        "p5_45=[31, 26, 65, 12, 5, 60, 124, 40, 81, 85, 29, 116, 113, 45, 36, 57, 75, 100, 1, 82, 47, 51, 14, 17, 86, 54, 78, 95, 112, 64, 49, 136, 129, 6, 142, 108, 62, 77, 84, 132, 19, 125, 24, 15, 97]\n",
        "p5_40=[77, 86, 31, 36, 12, 75, 106, 125, 81, 54, 29, 57, 51, 17, 6, 132, 124, 65, 116, 15, 84, 62, 142, 82, 140, 1, 9, 40, 45, 22, 95, 136, 113, 112, 71, 80, 70, 100, 19, 60]\n",
        "p5_35=[62, 75, 27, 124, 135, 81, 12, 60, 77, 82, 15, 126, 21, 36, 31, 57, 113, 29, 101, 65, 96, 1, 26, 40, 116, 142, 86, 112, 17, 6, 19, 129, 132, 95, 45]\n",
        "\n",
        "p5_30=[111, 19, 123, 124, 54, 12, 1, 36, 45, 82, 81, 29, 110, 116, 97, 57, 75, 63, 62, 136, 86, 140, 77, 17, 132, 40, 95, 65, 112, 31]\n",
        "p5_25=[123, 63, 17, 124, 36, 29, 12, 54, 132, 31, 81, 75, 86, 77, 73, 65, 57, 62, 142, 1, 140, 96, 116, 45, 82]\n",
        "p5_20=[116, 65, 60, 136, 124, 81, 54, 12, 86, 6, 29, 71, 36, 72, 17, 140, 57, 125, 75, 1]\n",
        "p5_15=[116, 29, 82, 36, 12, 71, 62, 136, 75, 81, 57, 90, 80, 45, 1]\n",
        "p5_10=[129, 36, 57, 62, 75, 12, 116, 81, 82, 53]\n",
        "p5_5=[81, 123, 57, 6, 75]\n",
        "p5_1=[81]"
      ],
      "metadata": {
        "id": "ZB3kA1qhMJlc"
      },
      "id": "ZB3kA1qhMJlc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p7_50=[125, 52, 68, 41, 76, 44, 22, 7, 56, 62, 50, 19, 20, 38, 140, 127, 132, 59, 32, 119, 137, 4, 45, 67, 75, 47, 33, 57, 37, 94, 36, 142, 53, 1, 90, 58, 51, 23, 143, 40, 73, 12, 74, 115, 17, 66, 14, 117, 103, 48]\n",
        "p7_45=[19, 67, 32, 132, 23, 31, 38, 142, 1, 59, 74, 76, 125, 62, 7, 20, 140, 43, 36, 44, 47, 56, 53, 52, 95, 12, 75, 122, 37, 40, 94, 107, 119, 143, 137, 46, 57, 4, 90, 117, 33, 66, 127, 73, 48]\n",
        "p7_40=[83, 74, 12, 125, 76, 56, 45, 7, 143, 19, 142, 32, 94, 38, 137, 140, 17, 117, 127, 62, 132, 115, 119, 52, 3, 37, 88, 1, 48, 47, 57, 51, 59, 36, 40, 6, 44, 24, 73, 53]\n",
        "p7_35=[33, 74, 44, 52, 76, 125, 94, 57, 83, 23, 62, 127, 38, 36, 73, 140, 37, 117, 115, 75, 137, 132, 108, 39, 7, 107, 32, 48, 47, 1, 119, 19, 41, 12, 53]\n",
        "p7_30=[48, 7, 36, 32, 73, 76, 127, 37, 43, 44, 52, 38, 74, 62, 1, 140, 14, 12, 132, 57, 9, 108, 17, 119, 47, 117, 107, 122, 137, 125]\n",
        "p7_25=[52, 1, 7, 43, 32, 57, 76, 115, 74, 127, 78, 117, 62, 140, 38, 104, 132, 120, 95, 45, 37, 101, 73, 108, 83]\n",
        "p7_20=[14, 57, 62, 7, 142, 30, 13, 38, 32, 104, 74, 76, 117, 140, 48, 127, 1, 119, 73, 132]\n",
        "p7_15=[62, 141, 7, 44, 117, 127, 76, 95, 74, 48, 32, 142, 143, 38, 57]\n",
        "p7_10=[127, 57, 6, 7, 36, 120, 62, 38, 74, 53]\n",
        "p7_5=[6, 7, 110, 117, 62]\n",
        "p7_1=[62]"
      ],
      "metadata": {
        "id": "AEwxbJL2S9zU"
      },
      "id": "AEwxbJL2S9zU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29OdQ8ySS9lx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29OdQ8ySS9lx",
        "outputId": "d359a07d-70a0-41a1-8a0b-b108141cd0fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "-- For k = 1 --\n",
            "Selected bands for seed 42: [0]\n",
            "\n",
            "-- For k = 5 --\n",
            "Selected bands for seed 42: [0, 11, 3, 20, 1]\n",
            "\n",
            "-- For k = 10 --\n",
            "Selected bands for seed 42: [20, 6, 5, 14, 11, 46, 1, 2, 0, 3]\n",
            "\n",
            "-- For k = 15 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [20, 23, 1, 0, 14, 39, 11, 4, 15, 26, 21, 10, 5, 41, 2]\n",
            "\n",
            "-- For k = 20 --\n",
            "Selected bands for seed 42: [14, 10, 21, 4, 15, 53, 5, 11, 20, 18, 6, 1, 28, 0, 26, 39, 49, 22, 2, 24]\n",
            "\n",
            "-- For k = 25 --\n",
            "Selected bands for seed 42: [3, 20, 1, 34, 18, 45, 14, 21, 32, 2, 54, 24, 6, 80, 49, 22, 30, 10, 5, 46, 11, 26, 59, 0, 15]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "-- For k = 30 --\n",
            "Selected bands for seed 42: [63, 10, 22, 8, 24, 4, 34, 1, 20, 3, 56, 5, 49, 11, 15, 0, 30, 28, 13, 55, 48, 6, 18, 107, 14, 59, 26, 80, 2, 21]\n",
            "\n",
            "-- For k = 35 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [13, 26, 1, 121, 62, 5, 92, 22, 15, 20, 11, 56, 0, 42, 4, 17, 48, 18, 59, 49, 10, 54, 127, 46, 21, 2, 14, 43, 32, 6, 63, 60, 80, 30, 107]\n",
            "\n",
            "-- For k = 40 --\n",
            "Selected bands for seed 42: [18, 21, 0, 15, 26, 14, 23, 1, 28, 5, 107, 4, 75, 6, 59, 39, 3, 46, 54, 22, 13, 56, 11, 24, 92, 10, 2, 20, 87, 12, 30, 7, 121, 63, 64, 69, 53, 38, 70, 17]\n",
            "\n",
            "-- For k = 45 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [69, 18, 14, 11, 2, 20, 70, 1, 34, 26, 5, 60, 49, 10, 3, 48, 22, 15, 54, 23, 107, 128, 80, 24, 4, 21, 46, 92, 61, 6, 7, 78, 12, 56, 121, 25, 94, 8, 30, 43, 63, 55, 13, 0, 59]\n",
            "\n",
            "-- For k = 50 --\n",
            "Selected bands for seed 42: [1, 6, 63, 14, 8, 64, 20, 24, 3, 54, 5, 18, 107, 61, 2, 13, 69, 48, 12, 22, 62, 49, 21, 80, 53, 38, 11, 15, 75, 56, 46, 59, 43, 35, 137, 34, 10, 47, 94, 7, 142, 45, 70, 0, 30, 28, 4, 76, 78, 37]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'correlation_matrix' is defined earlier in our code\n",
        "\n",
        "# Define a function to calculate the distance based on correlation\n",
        "def calculate_distance_from_correlation(correlation_matrix):\n",
        "    # Convert correlation to a distance measure for clustering\n",
        "    distance_matrix = 1 - correlation_matrix\n",
        "    return distance_matrix\n",
        "\n",
        "# Define a seed for K-means for reproducibility\n",
        "seed = 42  # Example seed value\n",
        "# List of different values of k for the number of clusters\n",
        "k_values = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
        "\n",
        "for k in k_values:\n",
        "    print(f\"\\n-- For k = {k} --\")\n",
        "\n",
        "    all_selected_bands = []\n",
        "\n",
        "    # Calculate distance matrix based on the correlation matrix\n",
        "    distance_matrix = calculate_distance_from_correlation(correlation_matrix)\n",
        "\n",
        "    # Apply K-means clustering\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=seed)\n",
        "    kmeans.fit(distance_matrix)\n",
        "    clusters = kmeans.labels_\n",
        "\n",
        "    # Select bands for the current seed\n",
        "    selected_bands = []\n",
        "    for cluster_idx in range(k):\n",
        "        cluster_members = np.where(clusters == cluster_idx)[0]\n",
        "        if cluster_members.size > 0:\n",
        "            # Select a representative band from this cluster\n",
        "            # Here, selecting the first member of each cluster as an example\n",
        "            selected_band = cluster_members[0]\n",
        "            selected_bands.append(selected_band)\n",
        "\n",
        "    # Store and print the selected bands for the current seed\n",
        "    all_selected_bands.append(np.array(selected_bands))\n",
        "    print(f\"Selected bands for seed {seed}: {selected_bands}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BZ8fjFIFMmod",
      "metadata": {
        "id": "BZ8fjFIFMmod"
      },
      "outputs": [],
      "source": [
        "p7_50=[1, 6, 63, 14, 8, 64, 20, 24, 3, 54, 5, 18, 107, 61, 2, 13, 69, 48, 12, 22, 62, 49, 21, 80, 53, 38, 11, 15, 75, 56, 46, 59, 43, 35, 137, 34, 10, 47, 94, 7, 142, 45, 70, 0, 30, 28, 4, 76, 78, 37]\n",
        "p7_45=[69, 18, 14, 11, 2, 20, 70, 1, 34, 26, 5, 60, 49, 10, 3, 48, 22, 15, 54, 23, 107, 128, 80, 24, 4, 21, 46, 92, 61, 6, 7, 78, 12, 56, 121, 25, 94, 8, 30, 43, 63, 55, 13, 0, 59]\n",
        "p7_40=[18, 21, 0, 15, 26, 14, 23, 1, 28, 5, 107, 4, 75, 6, 59, 39, 3, 46, 54, 22, 13, 56, 11, 24, 92, 10, 2, 20, 87, 12, 30, 7, 121, 63, 64, 69, 53, 38, 70, 17]\n",
        "p7_35=[13, 26, 1, 121, 62, 5, 92, 22, 15, 20, 11, 56, 0, 42, 4, 17, 48, 18, 59, 49, 10, 54, 127, 46, 21, 2, 14, 43, 32, 6, 63, 60, 80, 30, 107]\n",
        "p7_30=[63, 10, 22, 8, 24, 4, 34, 1, 20, 3, 56, 5, 49, 11, 15, 0, 30, 28, 13, 55, 48, 6, 18, 107, 14, 59, 26, 80, 2, 21]\n",
        "p7_25=[3, 20, 1, 34, 18, 45, 14, 21, 32, 2, 54, 24, 6, 80, 49, 22, 30, 10, 5, 46, 11, 26, 59, 0, 15]\n",
        "p7_20=[14, 10, 21, 4, 15, 53, 5, 11, 20, 18, 6, 1, 28, 0, 26, 39, 49, 22, 2, 24]\n",
        "p7_15=[20, 23, 1, 0, 14, 39, 11, 4, 15, 26, 21, 10, 5, 41, 2]\n",
        "p7_10=[20, 6, 5, 14, 11, 46, 1, 2, 0, 3]\n",
        "p7_5=[0, 11, 3, 20, 1]\n",
        "p7_1=[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q4ZTDyNXez8o",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4ZTDyNXez8o",
        "outputId": "6c5f7671-f213-46e2-a398-ce62dcea9170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "-- For k = 1 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [34]\n",
            "\n",
            "-- For k = 5 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [9, 34, 97, 1, 3]\n",
            "\n",
            "-- For k = 10 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [141, 50, 97, 113, 1, 119, 34, 9, 6, 133]\n",
            "\n",
            "-- For k = 15 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [90, 34, 79, 0, 119, 98, 123, 1, 72, 139, 30, 133, 97, 96, 75]\n",
            "\n",
            "-- For k = 20 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [89, 137, 9, 123, 53, 131, 34, 133, 88, 75, 119, 121, 113, 29, 20, 97, 30, 54, 1, 111]\n",
            "\n",
            "-- For k = 25 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [88, 54, 30, 123, 20, 111, 67, 72, 119, 97, 133, 1, 113, 89, 137, 34, 121, 0, 6, 107, 81, 50, 57, 14, 42]\n",
            "\n",
            "-- For k = 30 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [1, 64, 30, 123, 67, 42, 72, 121, 54, 79, 119, 97, 14, 74, 113, 27, 138, 6, 81, 0, 34, 107, 50, 137, 85, 9, 40, 111, 133, 129]\n",
            "\n",
            "-- For k = 35 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [67, 138, 97, 85, 81, 121, 119, 27, 42, 50, 1, 6, 123, 79, 113, 89, 0, 72, 60, 111, 54, 107, 66, 133, 76, 10, 14, 9, 40, 34, 86, 137, 30, 94, 82]\n",
            "\n",
            "-- For k = 40 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [35, 138, 40, 123, 0, 107, 121, 72, 119, 97, 139, 42, 79, 94, 27, 1, 67, 60, 90, 6, 133, 30, 66, 64, 54, 9, 29, 34, 111, 137, 85, 36, 14, 131, 82, 113, 95, 89, 33, 8]\n",
            "\n",
            "-- For k = 45 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [72, 97, 137, 64, 23, 119, 30, 133, 68, 139, 20, 123, 60, 113, 67, 40, 6, 96, 1, 9, 88, 36, 66, 42, 95, 27, 121, 76, 34, 107, 89, 75, 54, 79, 33, 0, 90, 74, 12, 14, 85, 131, 29, 140, 111]\n",
            "\n",
            "-- For k = 50 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [132, 89, 20, 119, 99, 67, 123, 3, 40, 111, 42, 12, 97, 137, 121, 9, 98, 36, 23, 34, 139, 133, 113, 1, 76, 66, 62, 54, 75, 27, 74, 129, 79, 85, 82, 131, 72, 0, 6, 78, 13, 14, 30, 94, 140, 107, 81, 41, 86, 37]\n"
          ]
        }
      ],
      "source": [
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'correlation_matrix' and 'A_norm' are defined earlier in our code\n",
        "\n",
        "# Combined distance calculation function\n",
        "# def calculate_combined_distance(A_norm, correlation_matrix, alpha=0.8, beta=0.2):\n",
        "#     attention_distance = 1 - A_norm\n",
        "#     #dissimilarity_distance = 1 - correlation_matrix   #?????\n",
        "#     correlation_matrix =correlation_matrix\n",
        "\n",
        "#     combined_distance = alpha * attention_distance[:, None] + beta * dissimilarity_distance  #vv?????\n",
        "#     return combined_distance\n",
        "\n",
        "# Combined distance calculation function\n",
        "def calculate_combined_distance(A_norm, correlation_matrix, alpha=0.8, beta=0.2):\n",
        "    attention_distance = 1 - A_norm\n",
        "    #dissimilarity_distance = 1 - correlation_matrix   #?????\n",
        "    correlation_matrix =correlation_matrix\n",
        "\n",
        "    combined_distance = alpha * attention_distance[:, None] + beta * correlation_matrix   #vv?????\n",
        "    return combined_distance\n",
        "\n",
        "# Define multiple seeds for K-means\n",
        "#seeds = [42, 0, 123]  # Example seed values  [0.3, 0.4]  -> [0.7, 0,6]\n",
        "seeds = [42]  # Example seed values       [0.1, 0.5] --> [0.9, 0.5]\n",
        "# List of different values of k\n",
        "k_values = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
        "\n",
        "for k in k_values:\n",
        "    print(f\"\\n-- For k = {k} --\")\n",
        "\n",
        "    all_selected_bands = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        combined_distance = calculate_combined_distance(A_norm, correlation_matrix)\n",
        "\n",
        "        # Apply K-means clustering\n",
        "        kmeans = KMeans(n_clusters=k, init='k-means++', random_state=seed)\n",
        "        kmeans.fit(combined_distance)\n",
        "        clusters = kmeans.labels_\n",
        "\n",
        "        # Select bands for the current seed\n",
        "        selected_bands = []\n",
        "        for cluster_idx in range(k):\n",
        "            cluster_members = np.where(clusters == cluster_idx)[0]\n",
        "            if cluster_members.size > 0:\n",
        "                # Select the band with the highest attention within this cluster\n",
        "                selected_band = cluster_members[np.argmax(A_norm[cluster_members])]\n",
        "                selected_bands.append(selected_band)\n",
        "\n",
        "        # Store the selected bands for the current seed\n",
        "        all_selected_bands.append(np.array(selected_bands))\n",
        "\n",
        "    # Print selected bands for each seed\n",
        "    for idx, selected_bands in enumerate(all_selected_bands):\n",
        "        print(f\"Selected bands for seed {seeds[idx]}: {selected_bands.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RXvKTvCNS4ei",
      "metadata": {
        "id": "RXvKTvCNS4ei"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "QQiZSoKyTqec",
      "metadata": {
        "id": "QQiZSoKyTqec"
      },
      "source": [
        "### Jan. 25.2024 Test based on Autoencoder input data fused with HSI+Lidar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x2CVzw_slcQ3",
      "metadata": {
        "id": "x2CVzw_slcQ3"
      },
      "outputs": [],
      "source": [
        "# p=13, n=20000, sgd, lr=0.0001\n",
        "top_1_seed42=  [34]\n",
        "top_5_seed42= [9, 34, 97, 1, 3]\n",
        "top_10_seed42= [141, 50, 97, 113, 1, 119, 34, 9, 6, 133]\n",
        "top_15_seed42=[90, 34, 79, 0, 119, 98, 123, 1, 72, 139, 30, 133, 97, 96, 75]\n",
        "top_20_seed42= [89, 137, 9, 123, 53, 131, 34, 133, 88, 75, 119, 121, 113, 29, 20, 97, 30, 54, 1, 111]\n",
        "top_25_seed42= [88, 54, 30, 123, 20, 111, 67, 72, 119, 97, 133, 1, 113, 89, 137, 34, 121, 0, 6, 107, 81, 50, 57, 14, 42]\n",
        "top_30_seed42= [1, 64, 30, 123, 67, 42, 72, 121, 54, 79, 119, 97, 14, 74, 113, 27, 138, 6, 81, 0, 34, 107, 50, 137, 85, 9, 40, 111, 133, 129]\n",
        "top_35_seed42= [67, 138, 97, 85, 81, 121, 119, 27, 42, 50, 1, 6, 123, 79, 113, 89, 0, 72, 60, 111, 54, 107, 66, 133, 76, 10, 14, 9, 40, 34, 86, 137, 30, 94, 82]\n",
        "top_40_seed123= [35, 138, 40, 123, 0, 107, 121, 72, 119, 97, 139, 42, 79, 94, 27, 1, 67, 60, 90, 6, 133, 30, 66, 64, 54, 9, 29, 34, 111, 137, 85, 36, 14, 131, 82, 113, 95, 89, 33, 8]\n",
        "top_45_seed42= [72, 97, 137, 64, 23, 119, 30, 133, 68, 139, 20, 123, 60, 113, 67, 40, 6, 96, 1, 9, 88, 36, 66, 42, 95, 27, 121, 76, 34, 107, 89, 75, 54, 79, 33, 0, 90, 74, 12, 14, 85, 131, 29, 140, 111]\n",
        "top_50_seed42= [132, 89, 20, 119, 99, 67, 123, 3, 40, 111, 42, 12, 97, 137, 121, 9, 98, 36, 23, 34, 139, 133, 113, 1, 76, 66, 62, 54, 75, 27, 74, 129, 79, 85, 82, 131, 72, 0, 6, 78, 13, 14, 30, 94, 140, 107, 81, 41, 86, 37]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ESUIJduk8qh",
      "metadata": {
        "id": "3ESUIJduk8qh"
      },
      "outputs": [],
      "source": [
        "# p=11, n=20000, sgd, lr=0.0001\n",
        "top_1_seed42=  [69]\n",
        "top_5_seed42= [69, 76, 65, 84, 127]\n",
        "top_10_seed42= [75, 83, 68, 27, 76, 69, 65, 84, 86, 46]\n",
        "top_15_seed42=[132, 52, 85, 76, 83, 84, 69, 92, 28, 86, 7, 12, 1, 126, 27]\n",
        "top_20_seed42= [16, 52, 28, 6, 76, 25, 39, 83, 41, 84, 74, 69, 60, 7, 122, 12, 27, 114, 1, 126]\n",
        "top_25_seed42= [86, 4, 60, 27, 68, 76, 87, 131, 12, 69, 74, 28, 39, 16, 119, 52, 123, 135, 120, 126, 99, 84, 139, 1, 83]\n",
        "top_30_seed42= [69, 122, 131, 16, 74, 76, 119, 54, 132, 1, 126, 8, 27, 139, 99, 86, 52, 84, 87, 4, 79, 96, 101, 39, 105, 83, 65, 7, 28, 123]\n",
        "top_35_seed42= [75, 99, 65, 27, 60, 51, 76, 131, 7, 114, 79, 139, 134, 68, 39, 10, 120, 4, 132, 85, 52, 111, 84, 69, 8, 86, 12, 83, 1, 74, 123, 43, 28, 41, 101]\n",
        "top_40_seed123= [10, 7, 131, 111, 11, 27, 85, 76, 54, 121, 4, 26, 52, 69, 86, 84, 1, 39, 48, 120, 74, 79, 65, 60, 8, 99, 122, 114, 83, 92, 87, 123, 104, 12, 51, 25, 28, 139, 106, 37]\n",
        "top_45_seed42= [120, 143, 131, 139, 10, 76, 95, 54, 52, 86, 74, 42, 8, 103, 27, 25, 63, 26, 84, 39, 99, 22, 7, 28, 83, 132, 11, 4, 79, 65, 105, 1, 47, 109, 114, 104, 12, 122, 41, 51, 134, 69, 123, 48, 29]\n",
        "top_50_seed42= [48, 99, 119, 76, 8, 79, 30, 51, 105, 27, 11, 121, 84, 65, 87, 131, 10, 47, 67, 52, 122, 83, 71, 39, 31, 108, 7, 69, 1, 132, 74, 12, 123, 72, 16, 25, 28, 139, 60, 120, 134, 4, 38, 54, 104, 103, 86, 107, 5, 143]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DGnQy4cXg_Gu",
      "metadata": {
        "id": "DGnQy4cXg_Gu"
      },
      "outputs": [],
      "source": [
        "# p=3, n=20000, sgd, lr=0.0001\n",
        "top_1_seed42=  [69]\n",
        "top_5_seed42= [69, 76, 65, 84, 127]\n",
        "top_10_seed42= [75, 83, 68, 27, 76, 69, 65, 84, 86, 46]\n",
        "top_15_seed42=[132, 52, 85, 76, 83, 84, 69, 92, 28, 86, 7, 12, 1, 126, 27]\n",
        "top_20_seed42= [16, 52, 28, 6, 76, 25, 39, 83, 41, 84, 74, 69, 60, 7, 122, 12, 27, 114, 1, 126]\n",
        "top_25_seed42= [86, 4, 60, 27, 68, 76, 87, 131, 12, 69, 74, 28, 39, 16, 119, 52, 123, 135, 120, 126, 99, 84, 139, 1, 83]\n",
        "top_30_seed42= [69, 122, 131, 16, 74, 76, 119, 54, 132, 1, 126, 8, 27, 139, 99, 86, 52, 84, 87, 4, 79, 96, 101, 39, 105, 83, 65, 7, 28, 123]\n",
        "top_35_seed42= [75, 99, 65, 27, 60, 51, 76, 131, 7, 114, 79, 139, 134, 68, 39, 10, 120, 4, 132, 85, 52, 111, 84, 69, 8, 86, 12, 83, 1, 74, 123, 43, 28, 41, 101]\n",
        "top_40_seed123= [10, 7, 131, 111, 11, 27, 85, 76, 54, 121, 4, 26, 52, 69, 86, 84, 1, 39, 48, 120, 74, 79, 65, 60, 8, 99, 122, 114, 83, 92, 87, 123, 104, 12, 51, 25, 28, 139, 106, 37]\n",
        "top_45_seed42= [120, 143, 131, 139, 10, 76, 95, 54, 52, 86, 74, 42, 8, 103, 27, 25, 63, 26, 84, 39, 99, 22, 7, 28, 83, 132, 11, 4, 79, 65, 105, 1, 47, 109, 114, 104, 12, 122, 41, 51, 134, 69, 123, 48, 29]\n",
        "top_50_seed42= [48, 99, 119, 76, 8, 79, 30, 51, 105, 27, 11, 121, 84, 65, 87, 131, 10, 47, 67, 52, 122, 83, 71, 39, 31, 108, 7, 69, 1, 132, 74, 12, 123, 72, 16, 25, 28, 139, 60, 120, 134, 4, 38, 54, 104, 103, 86, 107, 5, 143]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iwBNEMZtbEPC",
      "metadata": {
        "id": "iwBNEMZtbEPC"
      },
      "outputs": [],
      "source": [
        "# p=5, n=20000, sgd, lr=0.0001\n",
        "top_1_seed42=  [123]\n",
        "top_5_seed42= [123, 47, 26, 64, 30]\n",
        "top_10_seed42=  [75, 127, 26, 64, 112, 3, 10, 141, 123, 69]\n",
        "top_15_seed42=[75, 127, 26, 64, 112, 3, 10, 141, 123, 69]\n",
        "top_20_seed42= [67, 10, 143, 48, 29, 3, 120, 25, 68, 64, 69, 129, 127, 5, 75, 26, 123, 39, 136, 135]\n",
        "top_25_seed42= [129, 87, 127, 30, 3, 136, 46, 42, 98, 118, 123, 64, 48, 35, 25, 68, 135, 13, 75, 26, 2, 120, 5, 107, 34]\n",
        "top_30_seed42= [25, 68, 48, 107, 3, 20, 114, 42, 87, 120, 64, 13, 127, 26, 75, 123, 92, 21, 135, 5, 136, 10, 129, 118, 30, 98, 2, 59, 24, 69]\n",
        "top_35_seed42= [13, 127, 48, 107, 42, 3, 10, 77, 1, 68, 118, 5, 120, 24, 59, 64, 135, 112, 92, 75, 26, 2, 136, 114, 87, 20, 123, 39, 69, 98, 65, 94, 130, 25, 129]\n",
        "top_40_seed123= [10, 77, 135, 75, 118, 3, 39, 130, 26, 122, 88, 24, 87, 108, 48, 123, 25, 69, 136, 140, 129, 64, 7, 5, 2, 49, 105, 59, 15, 98, 20, 94, 126, 46, 68, 112, 127, 132, 139, 120]\n",
        "top_45_seed42= [67, 48, 27, 94, 24, 120, 3, 42, 87, 12, 39, 2, 114, 123, 135, 136, 26, 64, 10, 5, 69, 130, 118, 70, 112, 140, 23, 122, 105, 139, 129, 127, 46, 25, 68, 98, 75, 59, 41, 126, 45, 65, 88, 20, 132]\n",
        "top_50_seed42= [75, 130, 48, 61, 46, 3, 87, 111, 88, 123, 94, 65, 112, 24, 59, 49, 135, 52, 26, 136, 10, 95, 27, 5, 83, 98, 41, 108, 2, 132, 140, 118, 141, 7, 64, 30, 69, 114, 139, 25, 105, 128, 126, 23, 68, 42, 127, 12, 107, 120]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hlD8x36GZ8LR",
      "metadata": {
        "id": "hlD8x36GZ8LR"
      },
      "outputs": [],
      "source": [
        "# p=7, n=20000, sgd, lr=0.0001\n",
        "top_1_seed42=  [28]\n",
        "top_5_seed42= [101, 116, 102, 65, 28]\n",
        "top_10_seed42= [99, 86, 118, 102, 116, 85, 6, 93, 107, 28]\n",
        "top_15_seed42=[51, 136, 102, 42, 6, 5, 98, 99, 116, 28, 31, 86, 132, 107, 118]\n",
        "top_20_seed42= [102, 98, 11, 7, 86, 5, 42, 113, 99, 116, 107, 118, 132, 136, 122, 36, 45, 20, 28, 104]\n",
        "top_25_seed42= [10, 116, 102, 91, 42, 114, 44, 107, 38, 5, 136, 99, 118, 132, 45, 20, 6, 104, 110, 11, 93, 86, 28, 130, 34]\n",
        "top_30_seed42= [38, 106, 20, 102, 116, 31, 36, 58, 10, 132, 118, 133, 86, 84, 11, 5, 42, 95, 45, 28, 136, 85, 107, 104, 48, 26, 122, 53, 112, 99]\n",
        "top_35_seed42= [95, 104, 44, 102, 133, 42, 107, 86, 84, 2, 114, 116, 16, 59, 28, 118, 47, 5, 20, 58, 112, 45, 121, 38, 122, 136, 72, 26, 110, 99, 93, 63, 11, 36, 125]\n",
        "top_40_seed123= [132, 20, 128, 122, 102, 36, 136, 58, 65, 118, 38, 5, 53, 133, 16, 42, 28, 125, 86, 104, 46, 45, 0, 2, 112, 107, 15, 117, 101, 26, 63, 43, 34, 11, 116, 106, 95, 99, 31, 121]\n",
        "top_45_seed42= [38, 11, 102, 81, 5, 42, 99, 86, 65, 118, 10, 112, 128, 57, 58, 132, 20, 36, 122, 28, 45, 104, 123, 107, 106, 95, 26, 113, 16, 43, 133, 44, 121, 63, 84, 101, 125, 47, 116, 136, 15, 93, 34, 89, 114]\n",
        "top_50_seed42= [122, 112, 102, 91, 42, 57, 88, 107, 38, 139, 114, 34, 118, 117, 101, 45, 5, 99, 104, 121, 20, 2, 16, 58, 136, 84, 28, 95, 11, 113, 132, 15, 116, 93, 97, 43, 44, 128, 86, 125, 115, 85, 131, 106, 47, 26, 65, 55, 63, 109]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ILiICLNKTpOr",
      "metadata": {
        "id": "ILiICLNKTpOr"
      },
      "outputs": [],
      "source": [
        "# p=9, n=20000, sgd, lr=0.0001\n",
        "top_1_seed42=  [20]\n",
        "top_5_seed42= [60, 109, 20, 37, 119]\n",
        "top_10_seed42= [85, 30, 92, 37, 20, 2, 77, 49, 109, 108]\n",
        "top_15_seed42=[77, 44, 113, 37, 45, 117, 109, 108, 20, 123, 125, 134, 49, 10, 104]\n",
        "top_20_seed42= [142, 42, 33, 37, 107, 45, 123, 126, 67, 128, 108, 85, 49, 20, 69, 125, 86, 30, 26, 139]\n",
        "top_25_seed42= [36, 142, 30, 20, 33, 37, 85, 56, 108, 26, 77, 49, 139, 57, 123, 83, 125, 42, 126, 13, 51, 91, 45, 64, 96]\n",
        "top_30_seed42= [142, 60, 83, 92, 85, 30, 43, 96, 20, 29, 91, 53, 87, 126, 45, 139, 108, 123, 33, 37, 140, 42, 15, 63, 49, 51, 117, 72, 129, 10]\n",
        "top_35_seed42= [117, 123, 85, 83, 128, 129, 108, 96, 45, 140, 142, 42, 105, 43, 37, 30, 29, 56, 33, 77, 60, 20, 139, 51, 72, 36, 118, 126, 91, 80, 26, 16, 49, 75, 67]\n",
        "top_40_seed123= [104, 42, 90, 83, 45, 15, 49, 51, 140, 56, 60, 77, 30, 139, 108, 37, 123, 129, 128, 64, 43, 57, 29, 79, 95, 73, 20, 85, 142, 78, 16, 91, 36, 119, 26, 44, 117, 10, 126, 109]\n",
        "top_45_seed42= [90, 96, 30, 45, 37, 80, 142, 91, 64, 26, 60, 117, 84, 10, 83, 33, 139, 106, 43, 44, 125, 105, 16, 51, 63, 56, 57, 85, 108, 129, 140, 123, 49, 42, 29, 95, 36, 15, 109, 126, 53, 22, 128, 94, 20]\n",
        "top_50_seed42= [80, 142, 51, 72, 108, 94, 83, 125, 30, 126, 77, 117, 44, 106, 43, 37, 128, 123, 45, 85, 89, 139, 29, 60, 91, 36, 140, 49, 114, 15, 26, 56, 105, 16, 90, 10, 42, 19, 100, 57, 64, 20, 69, 33, 109, 129, 84, 17, 113, 7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ke8uDW6dcRh_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke8uDW6dcRh_",
        "outputId": "7980febf-d0c1-43f6-c78d-d72c4455d8c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected bands for seed 42: [83, 120, 11, 103, 22]\n",
            "Selected bands for seed 0: [11, 103, 120, 83, 22]\n",
            "Selected bands for seed 123: [103, 11, 120, 83, 22]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Number of bands to select\n",
        "k =5\n",
        "# Assuming 'correlation_matrix' is the Pearson correlation matrix computed from the actual band data\n",
        "# and 'A_norm' is the normalized attention for each band.\n",
        "# Step 1: Compute the distance matrix # The distance is inversely related to attention and directly related to dissimilarity (1 - correlation).\n",
        "# Since higher attention should decrease distance, use (1 - A_norm) to convert attention to a \"distance-like\" measure.\n",
        "attention_distance = 1 - A_norm  # is designed so that if a band has a high attention score (close to 1),\n",
        "dissimilarity_distance = 1 - correlation_matrix  # If correlation is high, dissimilarity is low, and vice versa\n",
        "\n",
        "# Combine both measures into a single distance metric # This can be done in several ways, depending on how we want to balance attention and dissimilarity.\n",
        "# Here, we're simply adding them, but this could be a weighted sum or another function of the two distances.\n",
        "# beta controls the influence of dissimilarity\n",
        "alpha, beta = 0.8, 0.2\n",
        "# Combined distance calculation with adjustable parameters\n",
        "combined_distance = alpha * attention_distance[:, None] + beta * dissimilarity_distance\n",
        "# using Different seeds\n",
        "# Define multiple seeds for K-means\n",
        "seeds = [42, 0, 123]  # Example seed values\n",
        "\n",
        "# Store the selected bands for each seed\n",
        "all_selected_bands = []\n",
        "\n",
        "for seed in seeds:\n",
        "    # Apply K-means clustering\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=seed)\n",
        "    kmeans.fit(combined_distance)\n",
        "    clusters = kmeans.labels_\n",
        "\n",
        "    # Select bands for the current seed\n",
        "    selected_bands = []\n",
        "    for cluster_idx in range(k):\n",
        "        cluster_members = np.where(clusters == cluster_idx)[0]\n",
        "        if cluster_members.size > 0:\n",
        "            # Select the band with the highest attention within this cluster\n",
        "            selected_band = cluster_members[np.argmax(A_norm[cluster_members])]\n",
        "            selected_bands.append(selected_band)\n",
        "\n",
        "    # Store the selected bands for the current seed\n",
        "    all_selected_bands.append(np.array(selected_bands))\n",
        "\n",
        "# Print selected bands for each seed\n",
        "for idx, selected_bands in enumerate(all_selected_bands):\n",
        "    print(f\"Selected bands for seed {seeds[idx]}: {selected_bands.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UV4OUI68nra4",
      "metadata": {
        "id": "UV4OUI68nra4"
      },
      "outputs": [],
      "source": [
        "# Samples=20000 P=3 SGD  lr=0.0001, test=0.2\n",
        "\n",
        "top_1_seed42=  [11]\n",
        "top_1_seed0=[11]\n",
        "top_1_seed123= [11]\n",
        "\n",
        "top_5_seed42= [83, 120, 11, 103, 22]\n",
        "top_5_seed0= [11, 103, 120, 83, 22]\n",
        "top_5_seed123= [103, 11, 120, 83, 22]\n",
        "\n",
        "top_10_seed42= [112, 9, 14, 21, 22, 125, 11, 120, 34, 75]\n",
        "top_10_seed0=[14, 9, 112, 21, 22, 37, 120, 11, 125, 75]\n",
        "top_10_seed123=  [11, 75, 21, 120, 14, 37, 112, 40, 22, 34]\n",
        "\n",
        "top_15_seed42=[14, 3, 74, 50, 34, 37, 9, 112, 22, 75, 125, 82, 11, 21, 120]\n",
        "top_15_seed0= [136, 9, 120, 125, 128, 34, 37, 121, 112, 3, 138, 22, 21, 14, 11]\n",
        "top_15_seed123= [50, 11, 120, 14, 34, 112, 125, 138, 37, 9, 22, 74, 21, 82, 101]\n",
        "\n",
        "top_20_seed42=  [95, 120, 84, 128, 37, 113, 112, 34, 103, 82, 74, 80, 138, 11, 125, 49, 22, 21, 63, 42]\n",
        "top_20_seed0= [37, 131, 9, 80, 112, 6, 34, 3, 125, 90, 121, 57, 126, 103, 11, 74, 138, 120, 22, 21]\n",
        "top_20_seed123=  [9, 101, 37, 50, 112, 74, 11, 34, 103, 138, 82, 22, 125, 49, 80, 3, 21, 120, 6, 113]\n",
        "\n",
        "top_25_seed42=  [136, 129, 74, 24, 121, 37, 34, 112, 22, 80, 138, 113, 125, 83, 120, 9, 79, 103, 49, 6, 123, 57, 23, 11, 62]\n",
        "top_25_seed0=  [136, 84, 6, 103, 128, 57, 121, 37, 74, 138, 112, 42, 34, 123, 125, 22, 120, 9, 80, 83, 124, 11, 49, 39, 23]\n",
        "top_25seed123= [113, 138, 74, 21, 11, 80, 37, 136, 112, 22, 62, 49, 135, 103, 82, 6, 123, 125, 57, 9, 34, 14, 120, 24, 23]\n",
        "\n",
        "top_30_seed42=[136, 129, 74, 24, 121, 37, 34, 112, 22, 80, 138, 113, 125, 83, 120, 9, 79, 103, 49, 6, 123, 57, 23, 11, 62]\n",
        "top_30_seed0= [136, 84, 6, 103, 128, 57, 121, 37, 74, 138, 112, 42, 34, 123, 125, 22, 120, 9, 80, 83, 124, 11, 49, 39, 23]\n",
        "top_30_seed123= [113, 138, 74, 21, 11, 80, 37, 136, 112, 22, 62, 49, 135, 103, 82, 6, 123, 125, 57, 9, 34, 14, 120, 24, 23]\n",
        "\n",
        "top_35_seed42=  [80, 121, 120, 115, 42, 34, 112, 7, 90, 37, 103, 43, 96, 125, 21, 138, 57, 11, 126, 49, 6, 69, 54, 74, 18, 14, 9, 47, 123, 22, 19, 23, 113, 75, 83]\n",
        "top_35_seed0=  [80, 89, 6, 93, 37, 34, 129, 90, 19, 7, 120, 18, 74, 75, 112, 138, 21, 62, 49, 23, 57, 108, 103, 11, 125, 96, 14, 9, 79, 22, 143, 123, 121, 126, 83]\n",
        "top_35_seed123= [125, 120, 90, 123, 79, 57, 112, 37, 96, 121, 7, 115, 138, 80, 49, 18, 11, 69, 9, 129, 23, 6, 34, 103, 126, 54, 83, 21, 74, 14, 94, 143, 22, 43, 113]\n",
        "\n",
        "top_40_seed123=  [115, 84, 6, 101, 49, 37, 19, 7, 18, 138, 112, 120, 129, 74, 69, 57, 14, 21, 126, 96, 103, 80, 75, 34, 11, 125, 113, 3, 9, 83, 43, 22, 23, 123, 121, 35, 143, 71, 24, 54]\n",
        "top_40_seed0=[42, 80, 120, 38, 34, 18, 112, 108, 7, 37, 75, 96, 103, 84, 21, 138, 125, 6, 90, 49, 43, 57, 23, 19, 123, 11, 62, 74, 121, 14, 135, 22, 113, 83, 51, 71, 115, 9, 16, 143]\n",
        "top_40_seed123= [22, 3, 54, 74, 123, 125, 37, 112, 34, 43, 35, 126, 121, 103, 75, 11, 49, 6, 108, 57, 120, 21, 18, 80, 96, 23, 143, 90, 7, 14, 83, 16, 115, 129, 113, 19, 71, 84, 138, 9]\n",
        "\n",
        "top_45_seed42= [120, 21, 11, 75, 79, 57, 112, 33, 80, 93, 37, 121, 117, 101, 22, 49, 69, 138, 6, 103, 18, 42, 34, 23, 123, 51, 74, 143, 14, 83, 7, 19, 9, 24, 43, 71, 40, 16, 113, 54, 96, 135, 125, 126, 28]\n",
        "top_45_seed0=  [54, 84, 74, 126, 57, 103, 112, 37, 43, 138, 18, 51, 7, 49, 24, 21, 19, 96, 34, 95, 120, 6, 42, 108, 14, 23, 22, 80, 121, 11, 9, 113, 135, 143, 71, 83, 101, 50, 125, 75, 40, 16, 117, 123, 82]\n",
        "top_45_seed123=  [108, 35, 74, 21, 51, 80, 37, 126, 112, 22, 101, 49, 84, 103, 18, 6, 95, 125, 57, 43, 34, 14, 120, 39, 23, 83, 96, 11, 135, 19, 7, 121, 113, 9, 138, 143, 54, 71, 42, 16, 90, 75, 50, 40, 123]\n",
        "\n",
        "top_50_seed42= [24, 18, 74, 28, 136, 57, 112, 110, 80, 19, 22, 11, 34, 108, 6, 138, 123, 51, 43, 42, 49, 120, 76, 14, 117, 101, 7, 125, 121, 9, 103, 113, 21, 115, 54, 16, 143, 75, 135, 71, 96, 72, 37, 83, 40, 23, 78, 129, 63, 35]\n",
        "top_50_seed0= [135, 23, 112, 24, 37, 71, 74, 49, 95, 22, 43, 103, 80, 34, 125, 27, 57, 51, 6, 14, 120, 101, 117, 79, 7, 136, 21, 19, 69, 11, 121, 83, 16, 143, 113, 75, 42, 123, 96, 40, 54, 78, 50, 138, 110, 33, 63, 18, 28, 9]\n",
        "top_50_seed123= [108, 35, 74, 21, 51, 80, 37, 126, 112, 22, 101, 49, 28, 103, 107, 6, 95, 125, 57, 43, 34, 14, 120, 39, 23, 83, 117, 11, 135, 19, 7, 121, 113, 9, 138, 143, 54, 71, 42, 16, 90, 75, 50, 40, 123, 33, 69, 72, 96, 18]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Glm1jRsiiHi6",
      "metadata": {
        "id": "Glm1jRsiiHi6"
      },
      "outputs": [],
      "source": [
        "# Samples=20000 P=9 SGD  lr=0.0001, test=0.15\n",
        "top_1_seed42=[85]\n",
        "#Selected bands for seed 42:\n",
        "top_50_seed42=[66, 36, 139, 52, 1, 140, 44, 72, 93, 14, 26, 96, 69, 103, 70, 28, 41, 29, 117, 85, 45, 79, 27, 61, 71, 102, 92, 5, 128, 137, 54, 134, 32, 123, 59, 142, 76, 3, 6, 109, 77, 143, 31, 121, 33, 124, 75, 19, 24, 22]\n",
        "#Selected bands for seed 0:\n",
        "top_50_seed0=[54, 41, 134, 121, 142, 3, 5, 29, 140, 18, 72, 51, 137, 117, 27, 93, 31, 69, 26, 14, 59, 22, 85, 2, 119, 61, 102, 139, 32, 6, 126, 76, 1, 115, 124, 28, 128, 66, 123, 143, 36, 45, 109, 75, 44, 103, 38, 33, 79, 116]\n",
        "#Selected bands for seed 123:\n",
        "top_50_seed123=[14, 140, 67, 124, 19, 117, 29, 16, 46, 66, 17, 26, 1, 22, 41, 93, 85, 128, 24, 103, 123, 69, 32, 27, 61, 115, 76, 134, 5, 142, 102, 59, 4, 3, 143, 6, 42, 52, 45, 74, 72, 75, 87, 36, 79, 139, 126, 44, 51, 109]\n",
        "\n",
        "top_45_seed42=[19, 139, 1, 14, 4, 29, 6, 28, 41, 66, 42, 85, 26, 44, 109, 103, 36, 69, 93, 102, 24, 61, 22, 117, 27, 70, 75, 32, 128, 59, 123, 72, 137, 5, 3, 52, 134, 31, 124, 142, 45, 126, 143, 37, 140] #Selected bands for seed 42:\n",
        "top_45_seed0=[109, 29, 0, 61, 80, 103, 102, 26, 142, 117, 31, 140, 54, 107, 121, 41, 66, 22, 85, 17, 1, 93, 46, 106, 124, 69, 7, 27, 74, 59, 3, 33, 45, 143, 56, 37, 32, 139, 123, 126, 44, 128, 6, 36, 72] #Selected bands for seed 0:\n",
        "top_45_seed123=[22, 41, 32, 1, 103, 19, 5, 29, 6, 2, 142, 102, 74, 85, 106, 93, 26, 126, 45, 27, 117, 124, 0, 71, 69, 87, 61, 24, 109, 121, 66, 16, 123, 76, 3, 52, 140, 44, 79, 139, 143, 128, 36, 72, 46]\n",
        "\n",
        "top_40_seed42=[66, 29, 109, 61, 74, 139, 45, 26, 37, 44, 85, 6, 103, 117, 0, 121, 33, 41, 93, 69, 3, 124, 27, 22, 102, 42, 31, 32, 59, 72, 1, 106, 112, 58, 123, 128, 126, 143, 140, 119] #Selected bands for seed 42:\n",
        "top_40_seed0=[93, 80, 45, 5, 6, 3, 142, 72, 22, 126, 41, 103, 46, 29, 106, 26, 70, 85, 117, 27, 69, 31, 61, 33, 109, 121, 74, 75, 124, 32, 102, 66, 42, 37, 14, 143, 1, 140, 128, 44] #Selected bands for seed 0:\n",
        "top_40_seed123=[42, 93, 0, 61, 59, 22, 124, 41, 80, 85, 102, 6, 29, 26, 66, 117, 103, 1, 139, 54, 4, 72, 106, 74, 69, 46, 109, 143, 31, 76, 107, 32, 128, 3, 137, 123, 44, 27, 33, 36]\n",
        "\n",
        "top_35_seed42=[71, 29, 5, 3, 74, 124, 41, 44, 76, 102, 6, 26, 2, 103, 85, 27, 117, 93, 121, 33, 0, 45, 141, 61, 18, 69, 8, 143, 128, 32, 31, 87, 96, 142, 106] #Selected bands for seed 42:\n",
        "top_35_seed0=[109, 128, 0, 61, 52, 26, 45, 93, 103, 3, 42, 22, 6, 27, 29, 121, 41, 117, 66, 85, 19, 134, 69, 28, 126, 124, 102, 32, 5, 87, 1, 139, 72, 24, 31] #Selected bands for seed 0:\n",
        "top_35_seed123=[11, 128, 61, 75, 121, 26, 44, 29, 42, 85, 103, 31, 109, 3, 6, 41, 74, 46, 27, 93, 124, 69, 117, 66, 14, 112, 72, 139, 22, 32, 102, 123, 126, 134, 5]\n",
        "\n",
        "top_30_seed42=[26, 70, 27, 93, 3, 102, 134, 128, 59, 74, 6, 107, 85, 124, 29, 103, 41, 72, 99, 117, 33, 45, 32, 69, 42, 14, 61, 66, 35, 109] #Selected bands for seed 42:\n",
        "top_30_seed0=[32, 124, 106, 3, 52, 6, 29, 36, 27, 92, 35, 26, 109, 85, 41, 66, 19, 103, 93, 117, 31, 123, 96, 102, 69, 61, 38, 74, 75, 128] #Selected bands for seed 0:\n",
        "top_30_seed123=[33, 29, 45, 5, 85, 6, 124, 126, 65, 3, 26, 92, 41, 93, 106, 31, 87, 128, 74, 117, 27, 0, 32, 103, 61, 69, 102, 109, 143, 131]\n",
        "\n",
        "top_25_seed42=[123, 128, 44, 61, 56, 66, 41, 33, 29, 32, 117, 0, 6, 74, 103, 72, 26, 85, 93, 3, 69, 36, 99, 27, 71] #Selected bands for seed 42:\n",
        "top_25_seed0=[26, 74, 45, 66, 103, 3, 72, 29, 106, 128, 38, 6, 85, 41, 32, 69, 93, 35, 88, 27, 33, 117, 31, 59, 61] #Selected bands for seed 0:\n",
        "top_25_seed123= [72, 29, 66, 117, 74, 6, 103, 45, 41, 35, 128, 33, 59, 88, 3, 26, 93, 77, 102, 69, 85, 106, 27, 32, 31]\n",
        "\n",
        "\n",
        "top_20_seed42=[45, 29, 44, 11, 3, 8, 27, 103, 26, 128, 6, 85, 88, 31, 77, 117, 41, 69, 93, 32] #Selected bands for seed 42:\n",
        "top_20_seed0=[33, 128, 3, 58, 45, 6, 29, 48, 22, 41, 124, 69, 32, 27, 28, 26, 93, 77, 106, 117] #Selected bands for seed 0:\n",
        "top_20_seed123=[8, 41, 27, 16, 3, 44, 128, 32, 29, 6, 33, 88, 69, 26, 103, 77, 85, 93, 45, 117]\n",
        "\n",
        "top_15_seed42=[11, 128, 134, 117, 109, 6, 58, 29, 124, 27, 45, 31, 77, 85, 26] #Selected bands for seed 42:\n",
        "top_15_seed0=[75, 26, 32, 3, 128, 28, 45, 29, 6, 65, 27, 72, 103, 112, 85] #Selected bands for seed 0:\n",
        "top_15_seed123= [35, 29, 45, 27, 26, 112, 117, 124, 129, 6, 32, 28, 72, 128, 69]\n",
        "\n",
        "top_10_seed42=[72, 128, 91, 85, 33, 6, 123, 29, 99, 27] #Selected bands for seed 42:\n",
        "top_10_seed0=[33, 128, 0, 85, 45, 6, 79, 29, 48, 27] #Selected bands for seed 0:\n",
        "top_10_seed123= [0, 6, 72, 128, 85, 79, 123, 29, 27, 33]\n",
        "\n",
        "top_5_seed42=[27, 41, 72, 85, 99] #Selected bands for seed 42:\n",
        "top_5_seed0=[99, 41, 27, 85, 72] #Selected bands for seed 0:\n",
        "top_5_seed123=[99, 26, 72, 27, 85]\n",
        "\n",
        "top_1_seed42=[27] #Selected bands for seed 42:\n",
        "top_1_seed0=[27] #Selected bands for seed 0:\n",
        "top_1_seed123=[27]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gaim2pqO6fiX",
      "metadata": {
        "id": "gaim2pqO6fiX"
      },
      "outputs": [],
      "source": [
        "# Samples=20000 P=11 optimizer=SGD\n",
        "#Selected bands for seed 42:\n",
        "top_50_seed42=[39, 88, 62, 23, 76, 109, 97, 72, 34, 98, 133, 78, 130, 110, 117, 46, 30, 54, 17, 70, 4, 87, 66, 64, 118, 120, 21, 13, 115, 12, 63, 49, 121, 95, 25, 48, 53, 18, 28, 61, 96, 79, 20, 22, 92, 141, 50, 14, 73, 136]\n",
        "#Selected bands for seed 0:\n",
        "top_50_seed0=[64, 49, 88, 23, 28, 76, 69, 115, 128, 70, 13, 21, 14, 109, 117, 12, 46, 72, 110, 30, 54, 113, 61, 95, 34, 133, 121, 66, 62, 120, 87, 50, 53, 22, 18, 141, 79, 73, 11, 4, 92, 96, 98, 135, 48, 25, 59, 63, 39, 130]\n",
        "#Selected bands for seed 123:\n",
        "top_50_seed123=[109, 110, 121, 46, 66, 117, 34, 48, 55, 56, 18, 54, 76, 120, 98, 73, 23, 11, 70, 115, 92, 53, 88, 78, 22, 25, 12, 135, 14, 136, 30, 95, 133, 21, 87, 116, 72, 13, 61, 96, 64, 63, 4, 28, 62, 141, 94, 130, 79, 47]\n",
        "\n",
        "top_45_seed42=[54, 69, 136, 23, 28, 115, 98, 110, 46, 66, 70, 62, 76, 83, 55, 109, 72, 117, 92, 12, 88, 21, 61, 48, 22, 53, 130, 95, 30, 120, 126, 135, 91, 49, 113, 64, 141, 14, 4, 133, 18, 96, 121, 63, 34] #Selected bands for seed 42:\n",
        "top_45_seed0=[23, 21, 76, 66, 70, 136, 88, 12, 83, 73, 28, 72, 63, 109, 117, 110, 118, 61, 46, 134, 98, 54, 133, 39, 48, 13, 121, 120, 115, 91, 30, 64, 95, 141, 34, 18, 53, 59, 22, 92, 87, 56, 96, 62, 130] #Selected bands for seed 0:\n",
        "top_45_seed123=[92, 54, 12, 117, 22, 141, 39, 110, 34, 28, 46, 25, 76, 18, 62, 23, 105, 11, 88, 133, 66, 103, 4, 64, 48, 121, 120, 70, 95, 109, 87, 115, 61, 63, 79, 53, 78, 96, 113, 135, 72, 130, 13, 14, 30]\n",
        "\n",
        "top_40_seed42=[98, 46, 61, 23, 76, 118, 28, 22, 70, 72, 83, 54, 37, 109, 117, 48, 110, 14, 63, 136, 64, 92, 115, 66, 69, 88, 55, 12, 120, 30, 95, 96, 121, 18, 62, 78, 133, 49, 53, 34]#Selected bands for seed 42:\n",
        "top_40_seed0=[129, 54, 136, 23, 133, 28, 110, 69, 70, 98, 46, 76, 64, 18, 113, 13, 61, 120, 117, 48, 88, 92, 90, 95, 77, 121, 118, 63, 109, 135, 66, 115, 12, 30, 62, 72, 53, 14, 22, 141] #Selected bands for seed 0:\n",
        "top_40_seed123=[105, 46, 135, 117, 76, 141, 92, 133, 121, 54, 28, 136, 12, 25, 72, 23, 37, 66, 110, 70, 88, 130, 61, 30, 48, 64, 120, 115, 116, 63, 95, 18, 22, 53, 79, 14, 118, 62, 34, 56]\n",
        "\n",
        "top_35_seed42=[61, 46, 85, 117, 76, 141, 133, 91, 98, 28, 92, 54, 110, 18, 23, 121, 14, 64, 12, 66, 88, 22, 79, 70, 48, 53, 63, 95, 120, 115, 49, 118, 135, 72, 129] #Selected bands for seed 42:\n",
        "top_35_seed0= [105, 88, 22, 23, 92, 28, 76, 118, 135, 141, 72, 53, 30, 110, 48, 117, 46, 54, 14, 56, 115, 121, 120, 133, 63, 12, 64, 61, 95, 91, 70, 109, 39, 66, 79] #Selected bands for seed 0:\n",
        "top_35_seed123=[141, 110, 121, 46, 66, 117, 61, 48, 63, 79, 72, 54, 76, 120, 98, 45, 23, 118, 70, 115, 92, 53, 88, 28, 22, 89, 12, 64, 14, 136, 85, 95, 133, 37, 87]\n",
        "\n",
        "top_30_seed42=[61, 88, 98, 120, 23, 76, 72, 83, 22, 37, 70, 117, 48, 118, 110, 14, 28, 46, 54, 64, 92, 63, 121, 95, 71, 115, 69, 12, 141, 53] #Selected bands for seed 42:\n",
        "top_30_seed0=[53, 88, 105, 23, 120, 76, 133, 130, 92, 62, 72, 141, 36, 48, 117, 28, 46, 63, 54, 110, 14, 61, 95, 83, 70, 64, 12, 22, 11, 115] #Selected bands for seed 0:\n",
        "top_30_seed123=[12, 54, 53, 117, 133, 77, 120, 76, 39, 46, 61, 70, 72, 118, 23, 110, 92, 105, 64, 48, 28, 22, 141, 14, 88, 63, 95, 115, 96, 121]\n",
        "\n",
        "top_25_seed42=[62, 98, 117, 76, 54, 28, 118, 22, 14, 46, 70, 72, 63, 61, 92, 23, 109, 48, 95, 64, 110, 133, 88, 36, 83] #Selected bands for seed 42:\n",
        "top_25_seed0=[63, 88, 22, 117, 28, 14, 76, 77, 70, 72, 48, 64, 36, 46, 110, 23, 92, 118, 54, 98, 95, 109, 120, 115, 47] #Selected bands for seed 0:\n",
        "top_25_seed123= [63, 46, 61, 76, 117, 28, 115, 118, 141, 48, 95, 54, 110, 14, 23, 92, 36, 72, 64, 98, 88, 83, 70, 120, 22]\n",
        "\n",
        "\n",
        "top_20_seed42=[110, 36, 23, 14, 70, 46, 115, 95, 98, 118, 109, 76, 88, 79, 20, 28, 117, 48, 63, 54] #Selected bands for seed 42:\n",
        "top_20_seed0=[53, 54, 98, 117, 76, 109, 95, 118, 63, 115, 92, 70, 20, 46, 23, 28, 48, 77, 36, 110] #Selected bands for seed 0:\n",
        "top_20_seed123=[63, 88, 95, 117, 110, 120, 14, 77, 70, 54, 115, 48, 36, 76, 64, 92, 23, 98, 118, 47]\n",
        "\n",
        "top_15_seed42=[95, 14, 117, 50, 54, 70, 48, 110, 115, 11, 88, 120, 20, 113, 98] #Selected bands for seed 42:\n",
        "top_15_seed0= [115, 87, 88, 117, 14, 76, 70, 9, 83, 95, 120, 20, 54, 110, 63] #Selected bands for seed 0:\n",
        "top_15_seed123= [14, 54, 10, 117, 48, 95, 120, 76, 121, 70, 88, 115, 61, 110, 83]\n",
        "\n",
        "top_10_seed42=[70, 110, 87, 45, 117, 128, 54, 9, 120, 115] #Selected bands for seed 42:\n",
        "top_10_seed0=[36, 110, 117, 14, 120, 54, 87, 95, 77, 70] #Selected bands for seed 0:\n",
        "top_10_seed123=  [12, 54, 11, 73, 117, 110, 70, 14, 28, 115]\n",
        "\n",
        "\n",
        "top_5_seed42=[87, 110, 134, 70, 117] #Selected bands for seed 42:\n",
        "top_5_seed0=[134, 110, 70, 87, 117] #Selected bands for seed 0:\n",
        "top_5_seed123=[70, 134, 110, 87, 117]\n",
        "\n",
        "top_1_seed42=[70] #Selected bands for seed 42:\n",
        "top_1_seed0=[70] #Selected bands for seed 0:\n",
        "top_1_seed123=[70]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5tTOi3RHQpnx",
      "metadata": {
        "id": "5tTOi3RHQpnx"
      },
      "outputs": [],
      "source": [
        "# Samples=20000 P=7 optimizer=SGD, lr=0.0001, test=0.2\n",
        "top_1_seed42=[85]\n",
        "top_1_seed0=[85]\n",
        "top_1_seed123=[85]\n",
        "\n",
        "top_5_seed42= [85, 124, 27, 5, 130]\n",
        "top_5_seed0=   [85, 130, 27, 5, 124]\n",
        "top_5_seed123=  [127, 22, 108, 122, 85]\n",
        "\n",
        "top_10_seed42= [85, 124, 122, 9, 70, 22, 35, 96, 30, 108]\n",
        "top_10_seed0=  [4, 124, 122, 130, 108, 85, 96, 35, 70, 72]\n",
        "top_10_seed123= [124, 9, 96, 22, 35, 70, 108, 30, 122, 85]\n",
        "\n",
        "top_15_seed42= [27, 97, 22, 42, 70, 85, 20, 122, 130, 108, 30, 74, 124, 92, 62]\n",
        "top_15_seed0= [30, 20, 27, 130, 97, 70, 62, 74, 85, 122, 108, 124, 92, 42, 22]\n",
        "top_15_seed123= [124, 74, 130, 27, 85, 70, 108, 97, 30, 122, 92, 42, 62, 22, 20]\n",
        "\n",
        "top_20_seed42= [122, 9, 112, 70, 92, 96, 42, 130, 30, 85, 108, 27, 20, 22, 124, 98, 62, 71, 91, 44]\n",
        "top_20_seed0=  [20, 30, 44, 108, 91, 42, 71, 85, 70, 22, 92, 122, 35, 97, 62, 112, 130, 124, 96, 27]\n",
        "top_20_seed123= [92, 71, 130, 85, 42, 70, 20, 44, 9, 30, 108, 124, 35, 22, 105, 62, 96, 98, 122, 27]\n",
        "\n",
        "top_25_seed42= [96, 42, 79, 22, 98, 70, 44, 40, 112, 125, 91, 108, 85, 62, 41, 27, 130, 9, 122, 35, 71, 124, 92, 29, 30]\n",
        "top_25_seed0= [40, 112, 27, 70, 108, 41, 130, 85, 42, 125, 35, 122, 9, 96, 44, 98, 62, 22, 92, 124, 105, 71, 30, 29, 79]\n",
        "top_25_seed123= [98, 112, 44, 70, 71, 105, 62, 79, 40, 30, 22, 42, 85, 108, 9, 27, 96, 122, 72, 92, 35, 124, 130, 29, 125]\n",
        "\n",
        "top_30_seed42= [71, 112, 9, 92, 91, 27, 70, 42, 125, 22, 40, 98, 122, 17, 96, 44, 62, 130, 109, 35, 66, 41, 30, 79, 124, 29, 108, 72, 95, 85]\n",
        "top_30_seed0= [66, 72, 9, 108, 70, 96, 130, 42, 95, 85, 125, 41, 22, 29, 44, 62, 92, 124, 98, 91, 30, 112, 71, 40, 79, 27, 122, 75, 35, 105]\n",
        "top_30_seed123= [9, 112, 122, 70, 105, 79, 71, 42, 85, 125, 22, 96, 17, 27, 44, 40, 98, 92, 62, 30, 124, 41, 72, 130, 95, 29, 66, 91, 108, 35]\n",
        "\n",
        "top_35_seed42= [71, 30, 9, 79, 105, 70, 112, 82, 42, 127, 22, 108, 109, 62, 122, 125, 95, 74, 27, 44, 124, 92, 40, 98, 130, 72, 35, 96, 75, 66, 91, 78, 17, 68, 85]\n",
        "top_35_seed0= [43, 72, 66, 105, 92, 0, 70, 42, 98, 30, 27, 17, 22, 23, 96, 62, 95, 44, 85, 112, 79, 124, 130, 35, 29, 125, 91, 122, 74, 69, 108, 75, 9, 71, 68]\n",
        "top_35_seed123= [23, 30, 122, 92, 91, 70, 46, 42, 22, 98, 124, 29, 108, 7, 62, 112, 130, 27, 85, 35, 43, 75, 79, 125, 72, 96, 66, 9, 41, 17, 44, 111, 105, 95, 71]\n",
        "\n",
        "top_40_seed42=  [23, 72, 7, 70, 42, 105, 71, 139, 32, 30, 92, 22, 66, 29, 35, 62, 86, 125, 124, 112, 27, 74, 79, 130, 91, 20, 68, 85, 98, 122, 44, 9, 75, 95, 78, 102, 108, 17, 96, 82]\n",
        "top_40_seed0= [9, 42, 66, 91, 70, 71, 79, 125, 29, 72, 85, 130, 139, 7, 22, 95, 112, 98, 62, 92, 43, 27, 30, 41, 124, 96, 122, 69, 105, 32, 35, 44, 74, 23, 75, 17, 82, 13, 108, 78]\n",
        "top_40_seed123=  [122, 30, 86, 92, 130, 74, 124, 70, 43, 17, 41, 27, 42, 72, 22, 85, 23, 35, 91, 62, 66, 112, 44, 125, 109, 29, 79, 46, 69, 108, 71, 9, 105, 98, 95, 82, 114, 96, 78, 75]\n",
        "\n",
        "top_45_seed42=  [122, 114, 129, 139, 70, 69, 98, 95, 75, 30, 105, 84, 62, 112, 92, 44, 20, 124, 85, 74, 27, 130, 66, 32, 125, 138, 71, 79, 72, 91, 35, 46, 7, 22, 68, 97, 108, 17, 96, 78, 106, 82, 42, 81, 127]\n",
        "top_45_seed0= [98, 78, 106, 71, 69, 70, 20, 66, 139, 125, 22, 72, 9, 62, 29, 112, 92, 27, 91, 32, 121, 79, 74, 124, 122, 7, 95, 68, 96, 44, 105, 132, 23, 114, 17, 108, 130, 75, 46, 30, 42, 129, 85, 35, 82]\n",
        "top_45_seed123= [66, 69, 20, 105, 79, 74, 70, 98, 125, 112, 17, 22, 27, 9, 62, 75, 44, 121, 85, 46, 124, 35, 92, 78, 68, 29, 72, 91, 95, 139, 122, 23, 130, 96, 111, 106, 7, 82, 52, 42, 30, 108, 71, 48, 40]\n",
        "\n",
        "top_50_seed42= [66, 3, 40, 130, 70, 95, 25, 94, 85, 121, 42, 92, 29, 111, 27, 22, 74, 79, 62, 91, 124, 83, 125, 72, 7, 105, 35, 98, 108, 123, 122, 68, 96, 109, 78, 44, 106, 71, 75, 112, 129, 139, 30, 82, 23, 46, 17, 48, 9, 45]\n",
        "top_50_seed0=  [98, 78, 106, 39, 69, 70, 20, 66, 139, 125, 48, 72, 9, 62, 29, 3, 92, 27, 91, 32, 121, 79, 74, 124, 122, 7, 95, 68, 96, 44, 105, 132, 23, 114, 17, 108, 130, 75, 46, 30, 42, 129, 85, 35, 82, 86, 71, 22, 112, 50]\n",
        "top_50_seed123= [39, 121, 9, 92, 105, 122, 70, 42, 29, 109, 48, 17, 50, 112, 7, 106, 98, 62, 40, 124, 79, 130, 96, 72, 66, 123, 44, 74, 125, 91, 78, 75, 114, 85, 23, 69, 71, 108, 95, 68, 129, 141, 86, 27, 30, 35, 82, 25, 46, 22]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5CQcD0ZtkLfl",
      "metadata": {
        "id": "5CQcD0ZtkLfl"
      },
      "outputs": [],
      "source": [
        "# Samples=20000 P=9 optimizer=Adam, lr=0.00001, test=0.2\n",
        "top_1_seed42=[135]\n",
        "top_1_seed0=[135]\n",
        "top_1_seed123=[135]\n",
        "\n",
        "top_5_seed42= [57, 29, 135, 133, 74]\n",
        "top_5_seed0= [74, 28, 29, 133, 135]\n",
        "top_5_seed123= [133, 57, 135, 29, 74]\n",
        "\n",
        "top_10_seed42= [41, 121, 28, 96, 83, 74, 135, 31, 20, 80]\n",
        "top_10_seed0= [94, 80, 96, 66, 121, 41, 74, 135, 57, 31]\n",
        "top_10_seed123= [94, 80, 9, 74, 21, 11, 135, 87, 133, 59]\n",
        "\n",
        "top_15_seed42= [74, 62, 141, 80, 77, 59, 133, 87, 72, 135, 67, 94, 121, 96, 113]\n",
        "top_15_seed0= [62, 74, 80, 94, 87, 70, 21, 77, 121, 135, 52, 59, 141, 113, 31]\n",
        "top_15_seed123= [77, 80, 67, 96, 113, 74, 41, 59, 135, 57, 62, 121, 133, 72, 94]\n",
        "\n",
        "top_20_seed42= [87, 76, 59, 32, 135, 40, 80, 94, 96, 121, 66, 31, 28, 30, 60, 119, 117, 72, 11, 113]\n",
        "top_20_seed0= [94, 70, 121, 29, 11, 59, 135, 80, 31, 67, 77, 52, 76, 74, 113, 85, 118, 87, 28, 68]\n",
        "top_20_seed123= [118, 31, 21, 11, 77, 38, 135, 113, 91, 70, 59, 94, 76, 41, 67, 121, 80, 30, 68, 52]\n",
        "\n",
        "top_25_seed42=[2, 60, 57, 52, 121, 83, 94, 55, 31, 77, 76, 59, 129, 74, 113, 72, 11, 67, 87, 135, 118, 9, 80, 68, 38]\n",
        "top_25_seed0=[53, 76, 68, 2, 77, 55, 121, 64, 28, 60, 133, 113, 74, 94, 59, 135, 96, 11, 38, 118, 21, 31, 129, 80, 87]\n",
        "top_25_seed123= [94, 80, 21, 72, 53, 11, 91, 106, 135, 121, 68, 76, 113, 45, 59, 74, 96, 119, 141, 60, 31, 87, 129, 55, 38]\n",
        "\n",
        "top_30_seed42= [60, 113, 96, 80, 43, 59, 71, 23, 21, 55, 2, 121, 38, 68, 28, 94, 11, 133, 70, 74, 135, 76, 83, 137, 120, 117, 87, 119, 20, 118]\n",
        "top_30_seed0=[101, 55, 60, 57, 83, 70, 113, 4, 2, 121, 96, 76, 21, 94, 59, 74, 87, 38, 122, 68, 80, 11, 67, 118, 43, 85, 133, 91, 135, 119]\n",
        "top_30_seed123= [79, 88, 67, 28, 70, 135, 59, 60, 113, 43, 133, 11, 80, 68, 83, 76, 74, 142, 96, 94, 118, 38, 121, 31, 87, 27, 117, 141, 2, 21]\n",
        "\n",
        "top_35_seed42=[71, 74, 67, 121, 9, 57, 80, 68, 59, 43, 113, 135, 100, 133, 130, 41, 85, 65, 72, 91, 118, 76, 83, 52, 6, 117, 119, 2, 11, 87, 23, 17, 88, 38, 94]\n",
        "top_35_seed0= [133, 74, 21, 28, 80, 72, 113, 59, 4, 135, 79, 17, 96, 83, 68, 100, 118, 85, 87, 94, 60, 117, 67, 38, 2, 23, 76, 31, 55, 121, 119, 91, 52, 62, 11]\n",
        "top_35_seed123= [52, 11, 83, 17, 117, 2, 60, 64, 55, 59, 113, 91, 79, 120, 76, 133, 96, 21, 23, 135, 68, 118, 38, 71, 43, 74, 100, 87, 94, 80, 119, 32, 57, 121, 30]\n",
        "\n",
        "top_40_seed42=  [43, 130, 9, 76, 97, 135, 133, 91, 41, 68, 59, 109, 100, 113, 121, 71, 38, 74, 137, 23, 80, 96, 72, 118, 40, 87, 2, 119, 37, 88, 79, 85, 11, 28, 124, 17, 117, 94, 30, 20]\n",
        "top_40_seed0= [100, 72, 4, 135, 26, 121, 130, 59, 79, 52, 60, 113, 57, 91, 74, 68, 93, 71, 67, 38, 43, 83, 119, 118, 122, 2, 11, 80, 87, 76, 137, 30, 20, 23, 21, 32, 88, 17, 133, 94]\n",
        "top_40_seed123=  [43, 76, 66, 2, 122, 9, 118, 114, 141, 81, 121, 113, 41, 72, 94, 100, 129, 38, 74, 91, 80, 4, 119, 130, 135, 30, 68, 137, 83, 71, 11, 133, 21, 98, 17, 59, 52, 27, 87, 96]\n",
        "\n",
        "top_45_seed42= [6, 113, 96, 43, 130, 57, 81, 17, 67, 135, 72, 100, 11, 78, 87, 68, 79, 32, 88, 4, 38, 74, 94, 76, 119, 23, 71, 133, 83, 118, 128, 20, 2, 63, 41, 91, 121, 52, 137, 59, 98, 27, 120, 30, 80]\n",
        "top_45_seed0= [72, 57, 32, 102, 117, 80, 67, 59, 135, 87, 100, 133, 113, 96, 41, 30, 118, 40, 74, 43, 38, 65, 23, 2, 129, 83, 137, 119, 130, 71, 121, 76, 78, 68, 11, 42, 98, 17, 91, 20, 3, 27, 94, 88, 29]\n",
        "top_45_seed123= [27, 133, 21, 118, 98, 9, 59, 117, 2, 83, 74, 68, 72, 17, 130, 65, 87, 113, 29, 11, 137, 31, 38, 135, 100, 88, 4, 119, 91, 67, 26, 94, 30, 20, 81, 80, 121, 76, 41, 96, 32, 141, 58, 57, 43]\n",
        "top_50_seed42= [79, 121, 67, 91, 9, 88, 2, 4, 59, 27, 68, 74, 133, 23, 38, 29, 113, 26, 37, 72, 130, 94, 119, 32, 98, 117, 135, 11, 118, 41, 31, 81, 100, 30, 17, 96, 66, 52, 76, 21, 55, 57, 137, 80, 20, 3, 43, 65, 87, 99]\n",
        "top_50_seed0=  [121, 68, 43, 96, 130, 21, 100, 79, 83, 72, 59, 113, 135, 74, 87, 23, 31, 41, 88, 98, 92, 32, 119, 38, 76, 67, 2, 128, 118, 11, 94, 52, 80, 57, 122, 91, 117, 137, 55, 109, 133, 129, 27, 81, 17, 30, 6, 20, 143, 3]\n",
        "top_50_seed123=  [52, 98, 121, 66, 80, 71, 72, 68, 113, 117, 41, 81, 11, 30, 2, 65, 118, 96, 26, 99, 38, 76, 87, 91, 23, 32, 119, 21, 78, 4, 37, 27, 135, 55, 20, 59, 100, 133, 109, 130, 17, 6, 88, 94, 57, 137, 74, 43, 67, 70]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qALBPafCUjg7",
      "metadata": {
        "id": "qALBPafCUjg7"
      },
      "outputs": [],
      "source": [
        "# Samples=20000 P=5 optimizer=SGD, lr=0.0001, test=0.2\n",
        "top_1_seed42=[14]\n",
        "top_1_seed0=[14]\n",
        "top_1_seed123=[14]\n",
        "\n",
        "top_5_seed42= [14, 99, 128, 105, 63]\n",
        "top_5_seed0=  [14, 99, 63, 128, 105]\n",
        "top_5_seed123=  [14, 99, 63, 128, 105]\n",
        "\n",
        "\n",
        "top_10_seed42= [80, 77, 128, 99, 110, 116, 17, 68, 76, 14]\n",
        "top_10_seed0=  [68, 116, 17, 76, 80, 14, 128, 104, 77, 99]\n",
        "top_10_seed123= [110, 99, 77, 17, 68, 128, 76, 116, 14, 80]\n",
        "\n",
        "top_15_seed42= [50, 68, 128, 108, 17, 117, 22, 99, 18, 63, 14, 98, 73, 0, 143]\n",
        "top_15_seed0=[6, 117, 99, 17, 63, 98, 0, 128, 73, 14, 22, 68, 110, 108, 105]\n",
        "top_15_seed123= [98, 68, 17, 6, 0, 99, 128, 117, 80, 108, 18, 14, 73, 105, 126]\n",
        "\n",
        "top_20_seed42= [122, 9, 112, 70, 92, 96, 42, 130, 30, 85, 108, 27, 20, 22, 124, 98, 62, 71, 91, 44]\n",
        "top_20_seed0=  [20, 30, 44, 108, 91, 42, 71, 85, 70, 22, 92, 122, 35, 97, 62, 112, 130, 124, 96, 27]\n",
        "top_20_seed123= [92, 71, 130, 85, 42, 70, 20, 44, 9, 30, 108, 124, 35, 22, 105, 62, 96, 98, 122, 27]\n",
        "\n",
        "top_20_seed42= [116, 13, 17, 68, 85, 22, 0, 128, 18, 63, 49, 73, 6, 143, 3, 14, 99, 51, 108, 50]\n",
        "top_20_seed0=[110, 0, 3, 126, 17, 13, 128, 14, 73, 76, 5, 102, 99, 68, 143, 6, 50, 116, 80, 93]\n",
        "top_20_seed123= [76, 85, 126, 17, 104, 128, 68, 13, 116, 22, 14, 0, 52, 73, 99, 3, 63, 143, 92, 6]\n",
        "\n",
        "\n",
        "\n",
        "top_25_seed42= [116, 68, 128, 76, 63, 7, 17, 104, 93, 0, 73, 52, 105, 62, 126, 14, 81, 99, 143, 25, 83, 22, 124, 6, 13]\n",
        "top_25_seed0=  [116, 13, 17, 101, 63, 128, 52, 14, 62, 49, 50, 99, 0, 73, 104, 127, 22, 51, 77, 76, 143, 93, 68, 126, 6]\n",
        "top_25_seed123=  [116, 76, 17, 112, 117, 8, 128, 52, 0, 93, 14, 81, 22, 103, 143, 73, 99, 68, 6, 62, 63, 83, 104, 50, 13]\n",
        "\n",
        "top_30_seed42= [127, 93, 17, 6, 103, 89, 128, 83, 73, 80, 143, 77, 52, 0, 99, 108, 68, 50, 14, 126, 62, 13, 81, 105, 109, 76, 23, 5, 63, 110]\n",
        "top_30_seed0=  [14, 76, 22, 17, 116, 8, 128, 63, 93, 77, 104, 0, 11, 99, 52, 73, 124, 121, 126, 49, 51, 68, 13, 143, 39, 127, 62, 6, 105, 80]\n",
        "top_30_seed123= [120, 49, 62, 17, 103, 128, 8, 13, 143, 14, 6, 102, 63, 116, 0, 99, 50, 104, 81, 105, 88, 68, 76, 126, 80, 18, 133, 93, 5, 23]\n",
        "\n",
        "top_35_seed42=  [127, 106, 17, 6, 103, 89, 128, 83, 73, 80, 11, 77, 52, 0, 99, 108, 68, 50, 14, 126, 62, 13, 81, 105, 109, 76, 23, 5, 63, 110, 143, 120, 93, 8, 51]\n",
        "top_35_seed0=  [77, 13, 128, 68, 104, 17, 63, 76, 69, 73, 14, 6, 22, 0, 101, 99, 3, 143, 5, 103, 62, 105, 81, 18, 106, 50, 93, 83, 80, 126, 127, 11, 108, 112, 51]\n",
        "top_35_seed123=  [14, 108, 110, 17, 68, 112, 128, 23, 109, 0, 73, 49, 99, 81, 52, 126, 116, 93, 22, 63, 77, 6, 105, 143, 76, 13, 50, 62, 121, 127, 80, 103, 5, 11, 8]\n",
        "\n",
        "top_40_seed42=  [127, 106, 17, 6, 103, 89, 128, 83, 88, 80, 11, 77, 52, 0, 99, 108, 68, 50, 14, 126, 62, 13, 81, 105, 109, 76, 26, 5, 63, 110, 143, 120, 93, 8, 51, 112, 73, 132, 27, 16]\n",
        "top_40_seed0=  [117, 93, 17, 22, 67, 38, 128, 103, 83, 110, 0, 8, 23, 81, 127, 126, 52, 108, 99, 116, 6, 50, 68, 69, 11, 13, 105, 63, 62, 133, 80, 76, 143, 73, 51, 5, 112, 14, 16, 120]\n",
        "top_40_seed123=  [84, 13, 17, 103, 77, 128, 76, 67, 79, 120, 0, 105, 8, 63, 14, 51, 23, 93, 6, 18, 68, 99, 126, 80, 50, 127, 83, 110, 62, 38, 22, 108, 116, 73, 112, 81, 143, 106, 140, 5]\n",
        "\n",
        "\n",
        "top_45_seed42= [127, 106, 17, 6, 103, 89, 128, 83, 88, 80, 11, 25, 52, 0, 4, 108, 131, 50, 14, 126, 62, 13, 81, 105, 109, 76, 26, 5, 63, 110, 143, 120, 93, 8, 51, 112, 73, 132, 27, 16, 67, 99, 117, 68, 116]\n",
        "top_45_seed0= [125, 73, 17, 22, 56, 128, 126, 11, 127, 0, 99, 93, 77, 50, 131, 6, 120, 69, 83, 143, 105, 16, 14, 103, 13, 129, 51, 88, 102, 8, 110, 81, 63, 78, 116, 112, 106, 62, 5, 80, 108, 15, 52, 76, 68]\n",
        "top_45_seed123= [5, 76, 25, 128, 68, 17, 126, 98, 6, 129, 13, 73, 14, 99, 63, 0, 52, 16, 143, 39, 23, 8, 51, 11, 93, 130, 49, 80, 127, 69, 103, 50, 62, 77, 106, 112, 81, 22, 65, 105, 56, 67, 131, 120, 110]\n",
        "\n",
        "top_50_seed42= [102, 106, 17, 6, 103, 69, 128, 83, 88, 80, 11, 25, 52, 0, 4, 108, 131, 50, 24, 126, 62, 13, 81, 105, 109, 76, 26, 22, 63, 110, 143, 120, 93, 8, 51, 112, 73, 132, 27, 16, 67, 99, 117, 68, 116, 14, 130, 98, 5, 127]\n",
        "top_50_seed0=  [78, 131, 128, 44, 143, 93, 17, 22, 76, 126, 73, 14, 130, 50, 52, 69, 81, 27, 102, 99, 15, 10, 80, 83, 6, 8, 77, 103, 98, 63, 108, 51, 0, 11, 105, 120, 112, 24, 106, 62, 5, 13, 109, 67, 116, 110, 127, 55, 16, 68]\n",
        "top_50_seed123= [39, 76, 17, 112, 47, 8, 128, 18, 0, 93, 24, 81, 80, 103, 84, 88, 99, 68, 6, 62, 41, 83, 104, 50, 13, 105, 102, 5, 63, 108, 116, 143, 51, 26, 120, 11, 69, 77, 16, 22, 106, 4, 127, 67, 126, 133, 129, 136, 73, 14]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4QYkKVeZydfq",
      "metadata": {
        "id": "4QYkKVeZydfq"
      },
      "outputs": [],
      "source": [
        "# Samples=20000 P=13 optimizer=Adam, lr=0.00001, train ratio=0.4\n",
        "#Selected bands for seed 42:\n",
        "\n",
        "top_1_seed42=[73]\n",
        "top_1_seed0=[73]\n",
        "top_1_seed123=[73]\n",
        "\n",
        "top_5_seed42=[137, 25, 73, 70, 136]\n",
        "top_5_seed0= [25, 73, 136, 137, 70]\n",
        "top_5_seed123=  [137, 73, 25, 70, 136]\n",
        "\n",
        "top_10_seed42=[113, 52, 82, 59, 16, 86, 78, 138, 84, 88]\n",
        "top_10_seed0=[59, 138, 88, 82, 16, 84, 78, 113, 52, 86]\n",
        "top_10_seed123= [93, 52, 82, 123, 16, 138, 68, 60, 88, 109]\n",
        "\n",
        "top_15_seed42= [16, 73, 103, 133, 117, 18, 137, 129, 42, 70, 19, 78, 17, 111, 13]\n",
        "top_15_seed0= [73, 136, 84, 111, 117, 25, 37, 129, 13, 70, 137, 18, 31, 77, 19]\n",
        "top_15_seed123= [79, 19, 73, 117, 133, 16, 103, 42, 18, 31, 13, 70, 129, 111, 78]\n",
        "\n",
        "top_20_seed42=  [19, 49, 69, 70, 39, 131, 23, 13, 141, 30, 136, 15, 18, 137, 20, 37, 73, 117, 25, 129]\n",
        "top_20_seed0= [103, 39, 117, 25, 56, 37, 18, 137, 87, 73, 61, 19, 13, 70, 23, 20, 129, 111, 79, 133]\n",
        "top_20_seed123=[18, 103, 23, 20, 69, 79, 70, 13, 133, 19, 129, 37, 111, 137, 117, 30, 61, 25, 73, 39]\n",
        "\n",
        "top_25_seed42= [57, 111, 69, 117, 103, 37, 25, 96, 77, 137, 42, 109, 70, 13, 31, 136, 129, 115, 39, 15, 23, 87, 18, 73, 107]\n",
        "top_25_seed0= [109, 31, 69, 136, 117, 18, 86, 13, 20, 37, 70, 57, 137, 39, 108, 106, 73, 23, 16, 42, 87, 115, 129, 49, 103]\n",
        "top_25_seed123= [18, 103, 117, 136, 69, 82, 57, 92, 13, 20, 70, 42, 129, 137, 132, 115, 53, 73, 49, 87, 25, 23, 61, 37, 39]\n",
        "\n",
        "top_30_seed42=[74, 13, 37, 115, 18, 53, 25, 56, 103, 70, 16, 57, 61, 106, 11, 137, 30, 73, 50, 117, 96, 23, 49, 136, 129, 20, 39, 69, 19, 17]\n",
        "top_30_seed0= [39, 13, 19, 70, 79, 69, 115, 107, 50, 53, 96, 106, 103, 20, 137, 61, 18, 136, 117, 73, 49, 57, 16, 132, 23, 129, 111, 25, 37, 30]\n",
        "top_30_seed123=   [19, 15, 117, 13, 30, 17, 96, 136, 56, 129, 37, 70, 16, 74, 23, 49, 103, 137, 73, 25, 115, 18, 42, 53, 87, 27, 20, 61, 69, 78]\n",
        "\n",
        "top_35_seed42=  [86, 103, 23, 37, 56, 38, 13, 19, 70, 61, 79, 18, 20, 39, 53, 106, 73, 115, 57, 50, 137, 136, 117, 69, 141, 49, 96, 132, 111, 25, 47, 30, 33, 16, 129]\n",
        "top_35_seed0= [13, 132, 70, 53, 31, 18, 129, 115, 57, 107, 19, 110, 78, 106, 111, 56, 20, 73, 137, 117, 15, 30, 42, 23, 49, 74, 96, 79, 136, 25, 103, 69, 100, 37, 33]\n",
        "top_35_seed123= [37, 100, 29, 117, 92, 103, 78, 18, 137, 20, 70, 56, 106, 19, 30, 23, 16, 115, 136, 87, 61, 73, 13, 25, 42, 96, 33, 74, 49, 69, 53, 132, 95, 38, 47]\n",
        "\n",
        "\n",
        "top_40_seed42= [132, 69, 103, 38, 70, 57, 115, 137, 78, 136, 141, 109, 107, 89, 42, 96, 56, 20, 106, 117, 23, 86, 73, 37, 19, 47, 111, 18, 53, 61, 79, 25, 33, 49, 16, 30, 74, 13, 100, 129]\n",
        "top_40_seed0= [87, 38, 115, 100, 20, 74, 129, 70, 96, 37, 107, 19, 79, 53, 56, 103, 136, 137, 132, 127, 23, 18, 117, 73, 106, 27, 13, 47, 69, 42, 11, 66, 78, 16, 49, 25, 45, 31, 138, 30]\n",
        "top_40_seed123=  [55, 38, 100, 117, 78, 53, 96, 16, 33, 70, 61, 42, 47, 23, 137, 73, 17, 124, 136, 106, 115, 18, 30, 132, 56, 108, 37, 74, 69, 20, 49, 13, 19, 131, 86, 57, 103, 25, 107, 129]\n",
        "\n",
        "\n",
        "top_45_seed42=  [19, 124, 117, 129, 110, 47, 141, 16, 42, 100, 53, 96, 23, 70, 30, 20, 56, 132, 106, 137, 55, 79, 74, 13, 103, 18, 127, 115, 107, 73, 39, 33, 49, 37, 25, 69, 57, 14, 38, 87, 109, 84, 136, 61, 86]\n",
        "top_45_seed0=[47, 39, 117, 18, 56, 19, 42, 79, 137, 100, 53, 70, 23, 86, 127, 5, 45, 57, 132, 49, 136, 33, 84, 115, 107, 20, 96, 30, 129, 13, 16, 31, 73, 69, 111, 25, 55, 116, 38, 113, 109, 37, 74, 106, 131]\n",
        "top_45_seed123=[31, 137, 42, 117, 74, 14, 100, 131, 53, 96, 57, 70, 56, 23, 20, 30, 37, 107, 110, 47, 115, 129, 18, 49, 132, 73, 92, 13, 11, 87, 33, 99, 78, 69, 106, 25, 127, 103, 38, 45, 16, 19, 111, 136, 124]\n",
        "\n",
        "\n",
        "top_50_seed42= [79, 47, 117, 116, 69, 96, 137, 4, 55, 30, 14, 129, 70, 42, 100, 23, 99, 61, 18, 56, 73, 53, 115, 49, 45, 16, 13, 20, 103, 37, 84, 111, 87, 136, 38, 33, 74, 25, 17, 107, 124, 57, 19, 78, 11, 109, 132, 106, 5, 50]\n",
        "top_50_seed0=[42, 129, 107, 70, 55, 49, 47, 115, 136, 13, 61, 18, 20, 56, 133, 74, 45, 73, 117, 137, 109, 23, 17, 132, 96, 37, 87, 111, 69, 5, 100, 38, 86, 25, 16, 57, 113, 78, 106, 14, 33, 19, 103, 30, 15, 79, 53, 138, 50, 84]\n",
        "top_50_seed123= [15, 129, 30, 23, 38, 37, 78, 31, 70, 96, 57, 13, 131, 115, 137, 73, 132, 18, 53, 99, 117, 69, 33, 107, 56, 111, 109, 86, 61, 20, 47, 100, 87, 49, 5, 103, 113, 106, 25, 92, 19, 74, 42, 124, 136, 133, 89, 16, 84, 55]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qLsjhighrJyZ",
      "metadata": {
        "id": "qLsjhighrJyZ"
      },
      "outputs": [],
      "source": [
        "# Samples=20000 P=13 optimizer=SGD\n",
        "#Selected bands for seed 42:\n",
        "\n",
        "top_1_seed42=[88]\n",
        "top_1_seed0=[88]\n",
        "top_1_seed123=[88]\n",
        "\n",
        "top_5_seed42=[77, 88, 82, 30, 73]\n",
        "top_5_seed0=[88, 77, 82, 30, 115]\n",
        "top_5_seed123= [30, 73, 82, 77, 88]\n",
        "\n",
        "top_10_seed42=[113, 52, 82, 59, 16, 86, 78, 138, 84, 88]\n",
        "top_10_seed0=[59, 138, 88, 82, 16, 84, 78, 113, 52, 86]\n",
        "top_10_seed123= [93, 52, 82, 123, 16, 138, 68, 60, 88, 109]\n",
        "\n",
        "top_15_seed42=[94, 115, 82, 140, 52, 68, 55, 77, 59, 88, 54, 138, 95, 40, 7]\n",
        "top_15_seed0= [88, 58, 82, 54, 74, 100, 7, 59, 95, 108, 55, 138, 52, 98, 115]\n",
        "top_15_seed123= [77, 52, 54, 82, 2, 115, 84, 17, 138, 59, 7, 95, 140, 88, 25]\n",
        "\n",
        "top_20_seed42= [105, 17, 82, 109, 138, 86, 7, 54, 93, 95, 115, 108, 52, 55, 123, 88, 74, 68, 84, 59]\n",
        "top_20_seed0= [123, 7, 82, 93, 88, 95, 138, 55, 54, 105, 52, 115, 109, 108, 59, 86, 74, 17, 68, 116]\n",
        "top_20_seed123= [74, 84, 82, 54, 17, 59, 108, 86, 95, 7, 88, 93, 138, 115, 123, 68, 109, 55, 52, 105]\n",
        "\n",
        "top_25_seed42= [30, 115, 82, 140, 54, 17, 109, 138, 55, 16, 68, 58, 77, 52, 88, 95, 72, 74, 41, 59, 53, 19, 84, 7, 93]\n",
        "top_25_seed0= [33, 16, 82, 113, 59, 17, 68, 138, 84, 19, 54, 52, 115, 95, 137, 55, 140, 69, 74, 109, 7, 58, 77, 88, 94]\n",
        "top_25_seed123= [68, 138, 33, 82, 52, 140, 109, 115, 72, 19, 113, 84, 95, 59, 7, 74, 77, 54, 55, 17, 100, 58, 78, 88, 41]\n",
        "\n",
        "top_30_seed42= [136, 56, 82, 78, 92, 74, 41, 55, 19, 109, 115, 68, 93, 2, 138, 16, 95, 84, 86, 140, 77, 59, 17, 7, 54, 25, 45, 40, 88, 52]\n",
        "top_30_seed0=[40, 56, 82, 59, 61, 68, 30, 115, 93, 19, 55, 78, 74, 16, 92, 136, 95, 77, 17, 140, 109, 54, 41, 10, 84, 88, 138, 123, 7, 52]\n",
        "top_30_seed123=  [140, 56, 82, 59, 25, 74, 95, 19, 41, 54, 115, 2, 68, 84, 77, 16, 17, 86, 136, 138, 109, 87, 93, 52, 78, 40, 7, 88, 55, 61]\n",
        "\n",
        "\n",
        "top_35_seed42= [17, 87, 82, 113, 78, 115, 84, 138, 64, 95, 52, 58, 59, 30, 16, 74, 88, 55, 68, 41, 140, 19, 77, 126, 54, 37, 25, 109, 2, 61, 49, 7, 33, 105, 56]\n",
        "top_35_seed0=[56, 84, 82, 96, 138, 68, 113, 19, 2, 74, 16, 3, 78, 25, 115, 95, 41, 54, 17, 111, 87, 109, 100, 88, 77, 37, 45, 55, 52, 101, 126, 7, 75, 61, 49]\n",
        "top_35_seed123=  [55, 115, 82, 109, 19, 127, 68, 61, 2, 56, 95, 74, 78, 16, 17, 113, 126, 75, 79, 30, 84, 138, 10, 52, 45, 37, 88, 58, 87, 7, 77, 54, 49, 140, 108]\n",
        "\n",
        "top_40_seed42=  [55, 52, 82, 41, 109, 127, 74, 78, 16, 95, 92, 115, 138, 19, 100, 84, 113, 17, 77, 59, 54, 68, 56, 58, 101, 37, 45, 27, 7, 126, 61, 88, 49, 123, 140, 25, 73, 60, 102, 24]\n",
        "top_40_seed0= [126, 52, 82, 59, 74, 68, 108, 33, 19, 73, 140, 109, 78, 49, 123, 95, 113, 138, 55, 17, 7, 96, 84, 94, 77, 88, 56, 58, 92, 64, 54, 61, 37, 30, 76, 16, 25, 60, 115, 127]\n",
        "top_40_seed123=  [126, 56, 82, 102, 138, 68, 115, 94, 88, 77, 55, 140, 95, 17, 87, 74, 16, 78, 79, 33, 108, 84, 19, 52, 113, 49, 127, 7, 73, 54, 123, 93, 61, 25, 58, 30, 75, 109, 104, 37]\n",
        "\n",
        "top_45_seed42=  [82, 126, 24, 54, 74, 33, 96, 37, 19, 95, 7, 61, 68, 123, 49, 60, 127, 102, 77, 121, 17, 55, 73, 41, 76, 94, 138, 58, 115, 88, 56, 30, 140, 84, 16, 52, 15, 109, 104, 45, 59, 113, 25, 137, 78]\n",
        "top_45_seed0=  [113, 76, 56, 82, 2, 16, 74, 109, 84, 19, 61, 95, 58, 115, 25, 92, 15, 104, 79, 140, 108, 54, 77, 30, 138, 24, 45, 126, 7, 55, 137, 88, 49, 127, 73, 27, 17, 60, 94, 37, 52, 78, 68, 75, 101]\n",
        "top_45_seed123=  [58, 49, 82, 109, 15, 41, 94, 76, 55, 95, 56, 113, 16, 74, 75, 127, 88, 138, 68, 33, 126, 79, 19, 84, 54, 45, 72, 52, 37, 115, 25, 77, 7, 30, 24, 108, 73, 140, 17, 27, 61, 78, 104, 102, 92]\n",
        "\n",
        "top_50_seed42=  [123, 49, 82, 77, 52, 104, 126, 27, 55, 138, 19, 7, 78, 95, 140, 33, 74, 41, 45, 56, 16, 75, 88, 125, 30, 17, 113, 92, 58, 115, 54, 109, 61, 37, 108, 73, 24, 127, 68, 25, 79, 11, 76, 81, 102, 137, 60, 94, 15, 84]\n",
        "top_50_seed0= [140, 17, 82, 27, 74, 33, 104, 56, 108, 16, 72, 40, 54, 95, 115, 77, 138, 84, 88, 109, 55, 37, 19, 75, 100, 61, 52, 76, 45, 49, 58, 7, 86, 68, 92, 24, 102, 126, 105, 25, 73, 78, 8, 113, 60, 106, 2, 96, 59, 41]\n",
        "top_50_seed123=  [25, 49, 82, 19, 109, 37, 95, 47, 137, 74, 58, 68, 41, 7, 84, 54, 96, 77, 15, 138, 9, 33, 88, 94, 52, 92, 45, 16, 76, 115, 126, 113, 105, 108, 55, 30, 20, 73, 61, 17, 56, 27, 2, 78, 104, 24, 102, 140, 59, 60]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4irJXNhYfppm",
      "metadata": {
        "id": "4irJXNhYfppm"
      },
      "outputs": [],
      "source": [
        "# Samples=20000 P=11 optimizer=rms\n",
        "#Selected bands for seed 42:\n",
        "top_50_seed42=[51, 81, 136, 35, 56, 123, 68, 141, 37, 86, 12, 3, 42, 21, 57, 22, 0, 96, 33, 29, 41, 39, 90, 142, 67, 64, 62, 54, 119, 129, 102, 99, 88, 108, 138, 95, 4, 45, 93, 58, 32, 8, 131, 107, 5, 110, 14, 23, 111, 135]#Selected bands for seed 0:\n",
        "top_50_seed0=[86, 51, 87, 72, 112, 58, 22, 70, 64, 54, 42, 6, 57, 110, 138, 111, 93, 136, 29, 39, 88, 90, 135, 32, 142, 96, 129, 12, 4, 119, 134, 68, 116, 35, 0, 37, 56, 102, 3, 123, 45, 95, 108, 41, 131, 81, 33, 104, 141, 14]#Selected bands for seed 123:\n",
        "top_50_seed123=[96, 99, 131, 123, 86, 135, 54, 136, 42, 32, 57, 10, 22, 68, 33, 29, 142, 110, 88, 58, 90, 8, 12, 93, 112, 35, 108, 0, 129, 51, 102, 45, 39, 4, 41, 141, 64, 119, 14, 81, 87, 37, 95, 133, 111, 3, 21, 70, 56, 134]\n",
        "\n",
        "top_45_seed42= [88, 3, 39, 111, 86, 12, 64, 108, 135, 57, 68, 42, 93, 110, 51, 90, 29, 22, 0, 56, 95, 142, 138, 136, 99, 33, 35, 54, 129, 104, 32, 41, 4, 37, 119, 81, 14, 102, 70, 58, 131, 45, 141, 8, 123]\n",
        "top_45_seed0=[99, 135, 51, 95, 88, 70, 22, 29, 12, 141, 86, 42, 57, 136, 110, 90, 35, 56, 142, 104, 93, 39, 54, 3, 68, 41, 129, 102, 119, 96, 33, 37, 81, 32, 0, 14, 108, 4, 131, 64, 58, 45, 116, 123, 111]\n",
        "top_45_seed123= [136, 3, 131, 12, 123, 68, 86, 57, 33, 35, 58, 108, 42, 22, 29, 90, 41, 110, 54, 95, 4, 129, 99, 51, 0, 142, 88, 32, 135, 104, 102, 39, 96, 119, 70, 141, 93, 37, 111, 56, 64, 8, 14, 81, 45]\n",
        "\n",
        "top_40_seed42= [35, 131, 4, 88, 12, 64, 14, 135, 68, 93, 22, 108, 57, 0, 29, 42, 81, 95, 90, 110, 58, 54, 142, 119, 136, 116, 33, 51, 104, 141, 41, 111, 102, 3, 32, 129, 39, 45, 37, 123]\n",
        "top_40_seed0=[111, 3, 131, 110, 86, 102, 42, 54, 123, 13, 58, 57, 107, 39, 68, 22, 4, 41, 29, 136, 142, 35, 12, 90, 135, 93, 141, 81, 0, 116, 129, 14, 88, 119, 37, 108, 95, 64, 32, 104]\n",
        "top_40_seed123=  [3, 135, 39, 111, 88, 107, 29, 42, 54, 108, 57, 95, 86, 51, 136, 58, 110, 22, 4, 142, 0, 93, 32, 12, 102, 96, 90, 37, 45, 68, 116, 81, 129, 41, 119, 131, 141, 104, 14, 35]\n",
        "\n",
        "top_35_seed42=[81, 110, 131, 111, 136, 14, 12, 13, 42, 57, 88, 58, 0, 22, 68, 54, 3, 29, 96, 135, 93, 39, 90, 142, 141, 32, 102, 129, 37, 35, 41, 119, 33, 116, 10]\n",
        "top_35_seed0= [90, 81, 39, 136, 111, 110, 10, 14, 42, 58, 57, 123, 93, 22, 29, 68, 54, 141, 3, 135, 142, 0, 12, 8, 102, 35, 41, 51, 107, 95, 129, 88, 32, 119, 45]\n",
        "top_35_seed123= [108, 54, 131, 41, 14, 111, 135, 4, 42, 33, 136, 57, 22, 29, 110, 68, 88, 58, 12, 99, 95, 0, 90, 102, 142, 129, 93, 3, 37, 79, 51, 35, 39, 32, 119]\n",
        "\n",
        "top_30_seed42=[3, 88, 131, 102, 68, 58, 14, 12, 35, 42, 57, 33, 22, 90, 141, 10, 110, 29, 99, 96, 39, 119, 142, 135, 54, 93, 129, 41, 32, 0]\n",
        "top_30_seed0= [119, 106, 39, 41, 96, 135, 45, 14, 42, 12, 93, 57, 90, 110, 131, 29, 141, 35, 70, 102, 58, 22, 142, 68, 3, 10, 129, 54, 32, 88]\n",
        "top_30_seed123= [110, 3, 39, 96, 102, 70, 90, 58, 57, 141, 42, 14, 29, 41, 12, 131, 10, 68, 35, 22, 142, 135, 88, 93, 8, 54, 136, 81, 129, 32]\n",
        "\n",
        "\n",
        "top_25_seed42=[3, 96, 39, 41, 14, 135, 54, 29, 32, 57, 107, 42, 119, 90, 131, 35, 22, 58, 72, 110, 142, 68, 129, 93, 106]\n",
        "top_25_seed0=[119, 72, 131, 135, 112, 22, 70, 110, 54, 41, 14, 93, 57, 142, 35, 42, 32, 106, 29, 90, 3, 58, 31, 129, 39]\n",
        "top_25_seed123=[29, 32, 39, 41, 96, 27, 58, 3, 42, 57, 70, 90, 119, 93, 22, 110, 12, 35, 68, 135, 72, 142, 54, 45, 102]\n",
        "\n",
        "\n",
        "top_20_seed42=[95, 3, 39, 41, 107, 54, 102, 32, 135, 14, 57, 37, 42, 35, 22, 58, 72, 90, 110, 29]\n",
        "top_20_seed0= [39, 70, 41, 10, 95, 54, 29, 110, 35, 27, 42, 57, 93, 99, 58, 32, 22, 90, 102, 142]\n",
        "top_20_seed123=[3, 41, 39, 96, 54, 27, 102, 62, 42, 93, 22, 110, 57, 32, 29, 35, 72, 70, 142, 90]\n",
        "\n",
        "top_15_seed42=[29, 120, 39, 110, 93, 95, 90, 22, 41, 35, 42, 57, 32, 27, 58]\n",
        "top_15_seed0= [27, 39, 41, 32, 35, 90, 58, 22, 93, 29, 110, 57, 42, 101, 95]\n",
        "top_15_seed123= [39, 93, 41, 32, 35, 29, 90, 120, 135, 22, 27, 95, 57, 42, 110]\n",
        "\n",
        "\n",
        "\n",
        "top_10_seed42=[32, 41, 42, 35, 93, 90, 39, 29, 135, 57]\n",
        "top_10_seed0=[32,41,39, 35, 38, 42, 29, 90, 9, 135]\n",
        "top_10_seed123=  [101, 135, 39, 41, 35, 20, 42, 32, 90, 29]\n",
        "\n",
        "top_5_seed42=[29, 32, 42, 35, 93]#Selected bands for seed 42:\n",
        "top_5_seed0=[32, 29, 42, 35, 93] #Selected bands for seed 0:\n",
        "top_5_seed123=[32, 29, 42, 35, 93]\n",
        "\n",
        "top_1_seed42=[32] #Selected bands for seed 42:\n",
        "top_1_seed0=[32] #Selected bands for seed 0:\n",
        "top_1_seed123=[32]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X1LvqbE6WOBZ",
      "metadata": {
        "id": "X1LvqbE6WOBZ"
      },
      "outputs": [],
      "source": [
        "# Samples=20000 P=11 optimizer=adam\n",
        "#Selected bands for seed 42:\n",
        "top_50_seed42=[72, 99, 33, 130, 108, 125, 111, 45, 140, 38, 31, 101, 7, 30, 12, 51, 74, 27, 9, 28, 109, 132, 127, 126, 103, 97, 118, 131, 5, 57, 65, 120, 43, 71, 93, 15, 123, 22, 79, 85, 21, 4, 94, 80, 26, 48, 60, 134, 41, 34]\n",
        "#Selected bands for seed 0:\n",
        "top_50_seed0=[58, 48, 130, 123, 125, 97, 131, 111, 93, 41, 49, 60, 108, 45, 127, 74, 4, 120, 67, 140, 99, 134, 22, 68, 5, 15, 103, 30, 126, 27, 12, 37, 38, 71, 28, 18, 21, 9, 7, 94, 112, 57, 51, 43, 132, 31, 65, 109, 115, 32]\n",
        "#Selected bands for seed 123:\n",
        "top_50_seed123=[60, 78, 43, 127, 41, 108, 31, 21, 132, 140, 112, 37, 111, 72, 103, 101, 109, 7, 65, 4, 130, 9, 5, 126, 61, 45, 30, 12, 99, 15, 22, 94, 76, 125, 123, 58, 97, 74, 27, 93, 28, 131, 117, 57, 134, 71, 32, 49, 73, 18]\n",
        "\n",
        "top_45_seed42=[28, 74, 26, 127, 132, 66, 31, 41, 108, 109, 123, 37, 15, 126, 140, 134, 125, 34, 71, 114, 111, 18, 27, 94, 43, 5, 4, 58, 103, 99, 21, 45, 30, 9, 93, 22, 65, 61, 7, 57, 112, 101, 131, 97, 38]#Selected bands for seed 42:\n",
        "top_45_seed0=[109, 73, 5, 22, 108, 127, 30, 134, 27, 101, 31, 21, 9, 7, 94, 57, 45, 103, 140, 125, 28, 99, 126, 111, 51, 33, 66, 38, 43, 48, 132, 41, 93, 49, 97, 123, 15, 131, 60, 71, 34, 12, 26, 4, 74] #Selected bands for seed 0:\n",
        "top_45_seed123=[108, 73, 131, 48, 60, 140, 9, 127, 90, 30, 99, 101, 49, 33, 43, 126, 12, 111, 103, 93, 65, 130, 28, 15, 134, 132, 31, 74, 22, 38, 21, 66, 64, 94, 123, 27, 97, 57, 109, 7, 41, 125, 45, 4, 34]\n",
        "\n",
        "top_40_seed42=[25, 74, 5, 111, 30, 15, 7, 123, 127, 20, 31, 140, 99, 12, 108, 134, 9, 56, 130, 93, 103, 33, 27, 22, 132, 41, 28, 65, 43, 97, 125, 57, 114, 131, 109, 126, 101, 0, 72, 4]#Selected bands for seed 42:\n",
        "top_40_seed0= [28, 93, 41, 125, 117, 131, 79, 123, 4, 132, 108, 97, 38, 43, 27, 140, 57, 130, 111, 56, 103, 126, 127, 22, 31, 33, 99, 30, 12, 94, 9, 65, 49, 109, 7, 118, 60, 45, 72, 74] #Selected bands for seed 0:\n",
        "top_40_seed123= [131, 9, 15, 94, 126, 28, 127, 22, 123, 108, 30, 109, 33, 140, 60, 134, 57, 111, 103, 132, 125, 12, 7, 41, 45, 49, 64, 4, 65, 99, 130, 93, 43, 74, 38, 97, 31, 21, 112, 27]\n",
        "\n",
        "top_35_seed42=[31, 45, 93, 76, 9, 127, 27, 123, 64, 43, 140, 30, 28, 108, 22, 74, 50, 99, 103, 79, 132, 125, 111, 134, 33, 57, 126, 7, 87, 131, 97, 94, 21, 15, 109] #Selected bands for seed 42:\n",
        "top_35_seed0= [33, 111, 101, 45, 125, 134, 132, 74, 99, 30, 31, 85, 108, 27, 97, 64, 9, 103, 93, 28, 21, 127, 12, 126, 57, 131, 43, 41, 65, 123, 7, 38, 109, 22, 15] #Selected bands for seed 0:\n",
        "top_35_seed123=[45, 7, 51, 123, 127, 114, 22, 131, 27, 140, 99, 30, 108, 74, 125, 111, 41, 126, 103, 120, 58, 66, 93, 31, 43, 28, 130, 5, 57, 132, 4, 9, 97, 134, 37]\n",
        "\n",
        "top_30_seed42=[131, 41, 74, 12, 127, 99, 108, 114, 111, 25, 101, 27, 97, 126, 7, 140, 93, 125, 33, 30, 64, 43, 103, 9, 28, 15, 22, 130, 132, 123] #Selected bands for seed 42:\n",
        "top_30_seed0= [96, 111, 106, 43, 127, 41, 123, 12, 15, 33, 7, 97, 4, 125, 30, 28, 21, 108, 27, 140, 9, 114, 103, 17, 25, 93, 99, 22, 126, 74]#Selected bands for seed 0:\n",
        "top_30_seed123=[33, 93, 30, 127, 114, 123, 7, 12, 96, 28, 27, 74, 41, 140, 125, 111, 108, 126, 103, 132, 43, 130, 57, 99, 25, 134, 17, 22, 97, 9]\n",
        "\n",
        "top_25_seed42=[73, 74, 33, 130, 97, 111, 127, 132, 108, 12, 140, 123, 103, 43, 9, 57, 126, 116, 27, 125, 109, 30, 7, 93, 28] #Selected bands for seed 42:\n",
        "top_25_seed0=[108, 140, 45, 7, 57, 43, 116, 111, 30, 97, 127, 123, 12, 37, 125, 99, 38, 28, 74, 126, 93, 9, 27, 50, 103] #Selected bands for seed 0:\n",
        "top_25_seed123= [103, 12, 123, 28, 99, 30, 127, 22, 33, 104, 73, 27, 74, 9, 140, 131, 57, 108, 125, 111, 97, 43, 93, 7, 50]\n",
        "\n",
        "\n",
        "top_20_seed42=[131, 130, 7, 114, 108, 127, 111, 74, 12, 93, 30, 123, 134, 126, 9, 27, 103, 33, 125, 97] #Selected bands for seed 42:\n",
        "top_20_seed0= [9, 33, 123, 12, 127, 134, 93, 30, 126, 74, 27, 99, 131, 97, 76, 110, 50, 108, 7, 111] #Selected bands for seed 0:\n",
        "top_20_seed123=[93, 57, 130, 131, 125, 123, 134, 9, 27, 74, 25, 127, 126, 108, 33, 99, 103, 111, 7, 97]\n",
        "\n",
        "top_15_seed42=[27, 33, 93, 104, 38, 123, 111, 97, 74, 41, 127, 108, 134, 7, 116] #Selected bands for seed 42:\n",
        "top_15_seed0= [33, 123, 41, 127, 76, 111, 7, 27, 108, 109, 134, 96, 93, 97, 126] #Selected bands for seed 0:\n",
        "top_15_seed123= [38, 7, 27, 131, 108, 127, 134, 104, 123, 118, 93, 97, 33, 109, 111]\n",
        "\n",
        "top_10_seed42=[104, 99, 127, 93, 37, 9, 111, 108, 97, 114] #Selected bands for seed 42:\n",
        "top_10_seed0=[33, 99, 27, 104, 93, 140, 111, 9, 108, 97] #Selected bands for seed 0:\n",
        "top_10_seed123=  [134, 118, 108, 127, 104, 4, 33, 111, 97, 93]\n",
        "\n",
        "top_5_seed42=[140, 111, 108, 15, 93] #Selected bands for seed 42:\n",
        "top_5_seed0=[15, 93, 140, 111, 108] #Selected bands for seed 0:\n",
        "top_5_seed123=[140, 111, 108, 15, 93]\n",
        "\n",
        "top_1_seed42=[108] #Selected bands for seed 42:\n",
        "top_1_seed0=[108] #Selected bands for seed 0:\n",
        "top_1_seed123=[108]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p5bZ3LNL7Htc",
      "metadata": {
        "id": "p5bZ3LNL7Htc"
      },
      "outputs": [],
      "source": [
        "# Sample 10000\n",
        "top_30_seed42=[29, 137, 47, 50, 1, 133, 140, 30, 87, 141, 40, 107, 41, 3, 134, 103, 142, 96, 14, 108, 143, 80, 36, 70, 15, 31, 35, 4, 24, 130] #Selected bands for seed 42:\n",
        "top_30_seed0=[141, 143, 36, 108, 3, 31, 14, 102, 122, 133, 140, 50, 103, 135, 29, 24, 41, 21, 134, 96, 58, 40, 80, 4, 130, 35, 30, 71, 107, 137] #Selected bands for seed 0:\n",
        "top_30_seed123=[35, 133, 108, 122, 3, 47, 107, 50, 58, 140, 142, 41, 143, 29, 103, 137, 141, 134, 30, 36, 96, 40, 31, 4, 130, 14, 80, 70, 17, 24]\n",
        "\n",
        "top_25_seed42=[122, 59, 143, 35, 4, 140, 118, 3, 40, 58, 17, 133, 50, 14, 107, 47, 141, 96, 94, 134, 36, 41, 108, 103, 130] #Selected bands for seed 42:\n",
        "top_25_seed0=[108, 31, 19, 50, 71, 122, 3, 133, 17, 141, 103, 47, 140, 58, 143, 107, 101, 134, 40, 96, 14, 35, 36, 100, 130] #Selected bands for seed 0:\n",
        "top_25_seed123= [111, 133, 87, 3, 41, 30, 35, 50, 107, 96, 44, 103, 134, 40, 19, 140, 95, 36, 143, 31, 14, 122, 135, 108, 130]\n",
        "\n",
        "\n",
        "top_20_seed42=[94, 130, 103, 10, 96, 3, 107, 45, 50, 108, 17, 140, 14, 143, 42, 31, 111, 87, 134, 36] #Selected bands for seed 42:\n",
        "top_20_seed0=[108, 133, 131, 140, 36, 71, 31, 50, 35, 3, 96, 103, 47, 143, 141, 107, 134, 87, 59, 130] #Selected bands for seed 0:\n",
        "top_20_seed123=[141, 134, 31, 108, 96, 3, 131, 130, 49, 17, 103, 50, 35, 38, 140, 107, 40, 87, 92, 36]\n",
        "\n",
        "top_15_seed42=[108, 107, 131, 50, 135, 36, 140, 130, 103, 87, 3, 96, 47, 42, 134] #Selected bands for seed 42:\n",
        "top_15_seed0=[96, 103, 130, 135, 3, 107, 108, 14, 47, 50, 17, 36, 35, 134, 140] #Selected bands for seed 0:\n",
        "top_15_seed123= [111, 50, 107, 87, 103, 96, 130, 29, 140, 10, 141, 36, 3, 134, 108]\n",
        "\n",
        "top_10_seed42=[34, 130, 96, 3, 131, 103, 36, 107, 50, 141] #Selected bands for seed 42:\n",
        "top_10_seed0=[107, 34, 131, 50, 141, 103, 3, 36, 130, 96] #Selected bands for seed 0:\n",
        "top_10_seed123= [36, 34, 50, 131, 103, 3, 130, 96, 107, 141]\n",
        "\n",
        "top_5_seed42=[107, 45, 21, 50, 103] #Selected bands for seed 42:\n",
        "top_5_seed0=[45, 107, 21, 50, 103] #Selected bands for seed 0:\n",
        "top_5_seed123=[50, 45, 107, 103, 21]\n",
        "\n",
        "top_1_seed42=[103] #Selected bands for seed 42:\n",
        "top_1_seed0=[103] #Selected bands for seed 0:\n",
        "top_1_seed123=[103]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67CHGQPs1wI8",
      "metadata": {
        "id": "67CHGQPs1wI8"
      },
      "source": [
        "The k-means++ algorithm addresses the most significant drawback of the standard k-means algorithm: its dependence on the initial random selection of cluster centers. By spreading out the initial centroids, k-means++ reduces the chance of converging to a suboptimal solution and generally leads to better clustering outcomes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OGw0C0AJMEam",
      "metadata": {
        "id": "OGw0C0AJMEam"
      },
      "outputs": [],
      "source": [
        "top_25=[38, 127, 53, 131, 105, 50, 113, 32, 109, 7, 3, 82, 20, 103, 54, 9, 15, 140, 43, 90, 52, 104, 41, 10, 95] #10/12 Running alpha=1, beta=0.5\n",
        "top_25=[13, 20, 53, 27, 42, 10, 109, 104, 113, 41, 7, 50, 131, 138, 103, 140, 22, 32, 127, 90, 47, 89, 65, 82, 45] #10/12 Running alpha=0.5, beta=0.5\n",
        "top_25=[74, 53, 45, 52, 89, 140, 113, 10, 103, 54, 109, 26, 131, 15, 32, 133, 20, 7, 50, 42, 90, 3, 82, 104, 41] #10/12 Running alpha=0.6, beta=0.4\n",
        "top_25=[4, 53, 100, 20, 50, 93, 109, 43, 113, 3, 82, 103, 24, 32, 108, 131, 104, 7, 52, 38, 41, 10, 140, 37, 15] #10/12 Running alpha=0.7, beta=0.3\n",
        "top_25=[15, 17, 106, 103, 131, 116, 50, 113, 105, 41, 3, 53, 133, 109, 10, 43, 101, 52, 95, 90, 82, 0, 93, 104, 74] #10/12 Running alpha=0.8, beta=0.2\n",
        "top_25=[12, 17, 103, 105, 116, 50, 113, 41, 7, 131, 3, 44, 104, 82, 85, 43, 52, 19, 109, 54, 90, 0, 10, 53, 15] #10/12 Running alpha=0.9, beta=0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6RCFthuCKJ8g",
      "metadata": {
        "id": "6RCFthuCKJ8g"
      },
      "outputs": [],
      "source": [
        "top_1=[131] #10/12 Running alpha=0.5, beta=0.5\n",
        "top_1=[131] #10/12 Running alpha=0.6, beta=0.4\n",
        "top_1=[131] #10/12 Running alpha=0.7, beta=0.3\n",
        "top_1=[131] #10/12 Running alpha=0.8, beta=0.2\n",
        "top_1=[131] #10/12 Running alpha=0.9, beta=0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HtL3Etwk_ApV",
      "metadata": {
        "id": "HtL3Etwk_ApV"
      },
      "outputs": [],
      "source": [
        "top_5=[79, 32, 16, 53, 80] #10/12 Running alpha=0.5, beta=0.5  # [3, 53, 105, 41, 131]\n",
        "top_5=[26, 53, 79, 138, 16] #10/12 Running alpha=0.6, beta=0.4\n",
        "top_5=[26, 53, 79, 138, 16] #10/12 Running alpha=0.7, beta=0.3\n",
        "top_5=[79, 138, 16, 26, 53] #10/12 Running alpha=0.8, beta=0.2\n",
        "top_5=[143, 53, 21, 138, 79] #10/12 Running alpha=0.9, beta=0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-rgYjPnzkGLD",
      "metadata": {
        "id": "-rgYjPnzkGLD"
      },
      "outputs": [],
      "source": [
        "top_10=[89, 113, 40, 109, 42, 79, 53, 6, 20, 14] #10/12 Running alpha=0.5, beta=0.5\n",
        "top_10=[14, 20, 53, 101, 79, 138, 6, 109, 40, 113] #10/12 Running alpha=0.6, beta=0.4\n",
        "top_10=[16, 122, 26, 53, 79, 116, 113, 124, 132, 109] #10/12 Running alpha=0.7, beta=0.3\n",
        "top_10=[16, 32, 80, 53, 79, 116, 124, 113, 132, 109] #10/12 Running alpha=0.8, beta=0.2\n",
        "top_10=[16, 138, 53, 26, 79, 113, 116, 124, 20, 132] #10/12 Running alpha=0.9, beta=0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ubNyUQXKmlZ",
      "metadata": {
        "id": "6ubNyUQXKmlZ"
      },
      "outputs": [],
      "source": [
        "top_15=[19, 53, 42, 140, 82, 109, 24, 65, 113, 41, 131, 50, 80, 103, 45] #10/12 Running alpha=0.5, beta=0.5\n",
        "top_15=[127, 53, 54, 50, 89, 140, 113, 109, 82, 65, 90, 41, 131, 103, 45] #10/12 Running alpha=0.6, beta=0.4\n",
        "top_15=[95, 103, 50, 41, 74, 82, 113, 130, 45, 120, 3, 109, 0, 131, 53] #10/12 Running alpha=0.7, beta=0.3\n",
        "top_15=[65, 41, 101, 53, 82, 120, 109, 113, 95, 38, 127, 103, 20, 50, 131] #10/12 Running alpha=0.8, beta=0.2\n",
        "top_15=[120, 113, 50, 41, 53, 84, 56, 82, 7, 0, 103, 95, 131, 5, 43] #10/12 Running alpha=0.9, beta=0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1RT-3Oe_dicl",
      "metadata": {
        "id": "1RT-3Oe_dicl"
      },
      "outputs": [],
      "source": [
        "top_20=[81, 20, 53, 26, 50, 45, 113, 82, 109, 76, 103, 140, 42, 54, 72, 79, 32, 57, 6, 89] #10/12 Running alpha=0.5, beta=0.5\n",
        "top_20=[139, 103, 116, 82, 140, 37, 138, 16, 109, 113, 57, 53, 1, 32, 79, 42, 50, 20, 89, 80] #10/12 Running alpha=0.6, beta=0.4\n",
        "top_20=[82, 42, 53, 63, 140, 57, 26, 109, 113, 32, 81, 89, 79, 6, 143, 138, 50, 116, 20, 103] #10/12 Running alpha=0.7, beta=0.3\n",
        "top_20=[37, 53, 138, 50, 14, 113, 116, 109, 79, 102, 20, 101, 57, 82, 80, 1, 143, 4, 42, 122] #10/12 Running alpha=0.8, beta=0.2\n",
        "top_20=[85, 113, 127, 82, 138, 109, 132, 53, 20, 27, 116, 79, 16, 119, 1, 42, 101, 63, 122, 50] #10/12 Running alpha=0.9, beta=0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m_Tp7P5vzR8T",
      "metadata": {
        "id": "m_Tp7P5vzR8T"
      },
      "source": [
        "# 7.0 Additional Band Selection based on Fused Mask Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CRlo9FQGjgY0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRlo9FQGjgY0",
        "outputId": "873cecea-ef38-4aeb-d967-801278f0b1b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[79, 131, 82, 111, 142, 10, 50, 55, 78, 68, 132, 11, 52, 40, 57, 39, 119, 59, 47, 3]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming A_norm is already computed and is a 1D numpy array of length 144\n",
        "A_norm = A_norm  # Assuming A_norm is the normalized attention score for each band\n",
        "\n",
        "# Get the indices of the top 20 bands based on attention scores\n",
        "top_20_band_indices = np.argsort(-A_norm)[:20]\n",
        "top_20_band_indices=top_20_band_indices.tolist()\n",
        "print(top_20_band_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tIC5XZugnxA3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIC5XZugnxA3",
        "outputId": "f101eede-f49e-41f2-e611-6d8614d5fe6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Band Index: 79, Attention Value: 1.0000\n",
            "Band Index: 131, Attention Value: 0.9981\n",
            "Band Index: 82, Attention Value: 0.9509\n",
            "Band Index: 111, Attention Value: 0.9328\n",
            "Band Index: 142, Attention Value: 0.9322\n",
            "Band Index: 10, Attention Value: 0.9311\n",
            "Band Index: 50, Attention Value: 0.9127\n",
            "Band Index: 55, Attention Value: 0.9103\n",
            "Band Index: 78, Attention Value: 0.9083\n",
            "Band Index: 68, Attention Value: 0.9034\n",
            "Band Index: 132, Attention Value: 0.8920\n",
            "Band Index: 11, Attention Value: 0.8912\n",
            "Band Index: 52, Attention Value: 0.8878\n",
            "Band Index: 40, Attention Value: 0.8784\n",
            "Band Index: 57, Attention Value: 0.8710\n",
            "Band Index: 39, Attention Value: 0.8686\n",
            "Band Index: 119, Attention Value: 0.8619\n",
            "Band Index: 59, Attention Value: 0.8569\n",
            "Band Index: 47, Attention Value: 0.8568\n",
            "Band Index: 3, Attention Value: 0.8562\n",
            "Band Index: 94, Attention Value: 0.8524\n",
            "Band Index: 87, Attention Value: 0.8507\n",
            "Band Index: 31, Attention Value: 0.8476\n",
            "Band Index: 129, Attention Value: 0.8452\n",
            "Band Index: 72, Attention Value: 0.8432\n",
            "Band Index: 5, Attention Value: 0.8419\n",
            "Band Index: 143, Attention Value: 0.8362\n",
            "Band Index: 16, Attention Value: 0.8311\n",
            "Band Index: 65, Attention Value: 0.8304\n",
            "Band Index: 98, Attention Value: 0.8279\n",
            "Band Index: 73, Attention Value: 0.8273\n",
            "Band Index: 48, Attention Value: 0.8247\n",
            "Band Index: 15, Attention Value: 0.8244\n",
            "Band Index: 108, Attention Value: 0.8196\n",
            "Band Index: 62, Attention Value: 0.8187\n",
            "Band Index: 70, Attention Value: 0.8186\n",
            "Band Index: 13, Attention Value: 0.8158\n",
            "Band Index: 14, Attention Value: 0.8103\n",
            "Band Index: 81, Attention Value: 0.8095\n",
            "Band Index: 88, Attention Value: 0.8093\n",
            "Band Index: 127, Attention Value: 0.8062\n",
            "Band Index: 115, Attention Value: 0.8040\n",
            "Band Index: 139, Attention Value: 0.8026\n",
            "Band Index: 46, Attention Value: 0.8014\n",
            "Band Index: 34, Attention Value: 0.8014\n",
            "Band Index: 33, Attention Value: 0.7979\n",
            "Band Index: 84, Attention Value: 0.7977\n",
            "Band Index: 133, Attention Value: 0.7960\n",
            "Band Index: 74, Attention Value: 0.7952\n",
            "Band Index: 104, Attention Value: 0.7938\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming A_norm is already computed and is a 1D numpy array of length 144\n",
        "# A_norm = A_norm  # Assuming A_norm is the normalized attention score for each band\n",
        "\n",
        "# Get the indices of the top 50 bands based on attention scores\n",
        "top_50_band_indices = np.argsort(-A_norm)[:50]\n",
        "top_50_attention_values = A_norm[top_50_band_indices]\n",
        "\n",
        "# Printing the top 50 band indices and their corresponding attention values\n",
        "top_50_band_indices = top_50_band_indices.tolist()\n",
        "top_50_attention_values = top_50_attention_values.tolist()\n",
        "\n",
        "# Display the results\n",
        "for i in range(len(top_50_band_indices)):\n",
        "    print(f\"Band Index: {top_50_band_indices[i]}, Attention Value: {top_50_attention_values[i]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jWIzHF7ymWcz",
      "metadata": {
        "id": "jWIzHF7ymWcz"
      },
      "outputs": [],
      "source": [
        "Top_20_mask=[79, 131, 82, 111, 142, 10, 50, 55, 78, 68, 132, 11, 52, 40, 57, 39, 119, 59, 47, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NEWaV9MQodyH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEWaV9MQodyH",
        "outputId": "66e6727d-e1f6-4469-a839-0201a1c609b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Band Index  Attention Value\n",
            "0           79         1.000000\n",
            "1          131         0.998115\n",
            "2           82         0.950901\n",
            "3          111         0.932821\n",
            "4          142         0.932206\n",
            "5           10         0.931149\n",
            "6           50         0.912697\n",
            "7           55         0.910282\n",
            "8           78         0.908303\n",
            "9           68         0.903450\n",
            "10         132         0.892028\n",
            "11          11         0.891240\n",
            "12          52         0.887845\n",
            "13          40         0.878398\n",
            "14          57         0.871010\n",
            "15          39         0.868579\n",
            "16         119         0.861897\n",
            "17          59         0.856937\n",
            "18          47         0.856777\n",
            "19           3         0.856229\n",
            "20          94         0.852416\n",
            "21          87         0.850696\n",
            "22          31         0.847613\n",
            "23         129         0.845169\n",
            "24          72         0.843173\n",
            "25           5         0.841884\n",
            "26         143         0.836224\n",
            "27          16         0.831068\n",
            "28          65         0.830421\n",
            "29          98         0.827883\n",
            "30          73         0.827299\n",
            "31          48         0.824725\n",
            "32          15         0.824380\n",
            "33         108         0.819584\n",
            "34          62         0.818724\n",
            "35          70         0.818617\n",
            "36          13         0.815815\n",
            "37          14         0.810299\n",
            "38          81         0.809539\n",
            "39          88         0.809345\n",
            "40         127         0.806171\n",
            "41         115         0.804027\n",
            "42         139         0.802553\n",
            "43          46         0.801448\n",
            "44          34         0.801350\n",
            "45          33         0.797936\n",
            "46          84         0.797655\n",
            "47         133         0.795989\n",
            "48          74         0.795159\n",
            "49         104         0.793763\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming A_norm is already computed and is a 1D numpy array of length 144\n",
        "A_norm = A_norm  # Assuming A_norm is the normalized attention score for each band\n",
        "\n",
        "# Get the indices of the top 50 bands based on attention scores\n",
        "top_50_band_indices = np.argsort(-A_norm)[:50]\n",
        "\n",
        "# Extract corresponding attention values\n",
        "top_50_attention_values = A_norm[top_50_band_indices]\n",
        "\n",
        "# Create a list of tuples (band index, attention value)\n",
        "top_50_bands = [(band_index, attention_value) for band_index, attention_value in zip(top_50_band_indices, top_50_attention_values)]\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "top_50_df = pd.DataFrame(top_50_bands, columns=['Band Index', 'Attention Value'])\n",
        "\n",
        "print(top_50_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OxGx0HoRoh1R",
      "metadata": {
        "id": "OxGx0HoRoh1R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}